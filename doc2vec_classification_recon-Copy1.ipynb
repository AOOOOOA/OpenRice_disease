{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "tqdm.pandas(desc=\"progress-bar\")\n",
    "from gensim.models import Doc2Vec\n",
    "from sklearn import utils,svm\n",
    "from sklearn.model_selection import train_test_split\n",
    "import gensim\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from gensim.models.doc2vec import TaggedDocument\n",
    "import re\n",
    "import json\n",
    "import matplotlib.pyplot as plt\n",
    "import multiprocessing\n",
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "from gensim.test.test_doc2vec import ConcatenatedDoc2Vec\n",
    "import jieba\n",
    "import langdetect\n",
    "import hanzidentifier\n",
    "import cantoseg\n",
    "from nltk.tokenize import word_tokenize\n",
    "from sklearn import metrics\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, cross_val_score, RepeatedStratifiedKFold, StratifiedKFold\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix,roc_curve, roc_auc_score, precision_score, recall_score, precision_recall_curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 399,
   "metadata": {},
   "outputs": [],
   "source": [
    "from json import JSONDecoder\n",
    "from functools import partial\n",
    "aa=[]\n",
    "\n",
    "def json_parse(fileobj, decoder=JSONDecoder(), buffersize=50000):\n",
    "    buffer = ''\n",
    "    for chunk in iter(partial(fileobj.read, buffersize), ''):\n",
    "         buffer += chunk\n",
    "         while buffer:\n",
    "             try:\n",
    "                 result, index = decoder.raw_decode(buffer)\n",
    "                 yield result\n",
    "                 buffer = buffer[index:].lstrip()\n",
    "             except ValueError:\n",
    "                 # Not enough data to decode, read more\n",
    "                 break\n",
    "                \n",
    "with open('yelp_academic_dataset_review.json', 'r') as infh:\n",
    "    for data in json_parse(infh):\n",
    "        aa.append(data)\n",
    "        #print(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'review_id': 'UmFMZ8PyXZTY2QcwzsfQYA', 'user_id': 'nIJD_7ZXHq-FX8byPMOkMQ', 'business_id': 'lbrU8StCq3yDfr-QMnGrmQ', 'stars': 1.0, 'useful': 1, 'funny': 1, 'cool': 0, 'text': 'I am actually horrified this place is still in business. My 3 year old son needed a haircut this past summer and the lure of the $7 kids cut signs got me in the door. We had to wait a few minutes as both stylists were working on people. The decor in this place is total garbage. It is so tacky. The sofa they had at the time was a pleather sofa with giant holes in it. And my son noticed ants crawling all over the floor and the furniture. It was disgusting and I should have walked out then. Actually, I should have turned around and walked out upon entering but I didn\\'t. So the older black male stylist finishes the haircut he was doing and it\\'s our turn. I tell him I want a #2 clipper around the back and sides and then hand cut the top into a standard boys cut. Really freaking simple, right? WRONG! Rather than use the clippers and go up to actually cut the hair, he went down. Using it moving downward doesn\\'t cut hair, it just rubs against it. How does this man who has an alleged cosmetology license not know how to use a set of freaking clippers??? I realized almost immediately that he had no idea what he was doing. No idea at all. After about 10 minutes of watching this guy stumble through it, I said \"you know what? That\\'s fine.\", paid and left. All I wanted to do was get out of that scummy joint and take my son to a real haircut place.\\n\\nBottom line: DO NOT GO HERE. RUN THE OTHER WAY!!!!!', 'date': '2013-12-07 03:16:52'}\n"
     ]
    }
   ],
   "source": [
    "print(aa[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 400,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "108449"
      ]
     },
     "execution_count": 400,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(aa)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 401,
   "metadata": {},
   "outputs": [],
   "source": [
    "aa_df = pd.DataFrame(columns = ['star','text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 402,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>star</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [star, text]\n",
       "Index: []"
      ]
     },
     "execution_count": 402,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "aa_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 403,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(aa)):\n",
    "    #aa_df = aa_df.append([{'star':aa[i]['stars']}],[{'text':aa[i]['text']}])#, ignore_index=True\n",
    "    #aa_df[i]={'star':aa[i]['stars'],{'text':aa[i]['text']}\n",
    "           \n",
    "    aa_df=aa_df.append(pd.DataFrame({'star':[aa[i]['stars']],'text':[aa[i]['text']]}))\n",
    "    #aa[i]['stars']\n",
    "    #aa[i]['text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {},
   "outputs": [],
   "source": [
    "aa_df.index=range(len(aa_df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 404,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(108449, 2)"
      ]
     },
     "execution_count": 404,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "aa_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>star</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2.0</td>\n",
       "      <td>As someone who has worked with many museums, I...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.0</td>\n",
       "      <td>I am actually horrified this place is still in...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5.0</td>\n",
       "      <td>I love Deagan's. I do. I really do. The atmosp...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.0</td>\n",
       "      <td>Dismal, lukewarm, defrosted-tasting \"TexMex\" g...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4.0</td>\n",
       "      <td>Oh happy day, finally have a Canes near my cas...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5.0</td>\n",
       "      <td>This is definitely my favorite fast food sub s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>5.0</td>\n",
       "      <td>Really good place with simple decor, amazing f...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>5.0</td>\n",
       "      <td>Awesome office and staff, very professional an...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>5.0</td>\n",
       "      <td>Most delicious authentic Italian I've had in t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>4.0</td>\n",
       "      <td>I have been here twice. Very nice and laid bac...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   star                                               text\n",
       "0   2.0  As someone who has worked with many museums, I...\n",
       "1   1.0  I am actually horrified this place is still in...\n",
       "2   5.0  I love Deagan's. I do. I really do. The atmosp...\n",
       "3   1.0  Dismal, lukewarm, defrosted-tasting \"TexMex\" g...\n",
       "4   4.0  Oh happy day, finally have a Canes near my cas...\n",
       "5   5.0  This is definitely my favorite fast food sub s...\n",
       "6   5.0  Really good place with simple decor, amazing f...\n",
       "7   5.0  Awesome office and staff, very professional an...\n",
       "8   5.0  Most delicious authentic Italian I've had in t...\n",
       "9   4.0  I have been here twice. Very nice and laid bac..."
      ]
     },
     "execution_count": 233,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "aa_df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 405,
   "metadata": {},
   "outputs": [],
   "source": [
    "#search eng symptom\n",
    "def search_symptom_words(x):\n",
    "    collect_word = 0\n",
    "    \"\"\"\n",
    "    old_symptom_words = ['肚屙', '拉肚子', '屙肚', '兜屙', '屙啡啡', '屙瀡瀡', '肚瀉','屙肚仔', '拉稀', '又屙又呕', '嘔心', '痙攣', '嘔吐',\n",
    "                     '腹瀉', '肚子疼', '肚子痛', '胃痛', '病菌', '病痛', '病徵', '病入膏肓', '生病', 'sick', '肠胃炎', 'got sick', \n",
    "                     'stomachache']\n",
    "    \n",
    "    new_symptom_words = ['昏厥','中毒','腸胃炎','發燒','腹痛','瀉肚','瀉腹','泄瀉','下痢','嘔嘔','潰瘍','肚柯','柯水',\n",
    "                     '發炎','过敏','頭暈','抽筋','肠炎','溃疡','腹泻','肚泻','泻肚','发炎','肚痛','痾'] ## no 过敏 发炎 抽筋 中毒 昏厥\n",
    "    ## add  呕左 又柯又呕 急症室 疴咗 厠所 医院 疴左 肚疴 清肠胃 又疴又呕 泻咗 柯左 左呕 上吐下泻 肚疴 发烧 落肚 大泻特泻\n",
    "    \n",
    "    symptom_words=['bacteria','virus','parasite','toxin','allergens','allergen','physical hazard','food poisoning','abdominal cramp','abdominal pain','nausea',\n",
    "                  'watery diarrhea','diarrhea','severe diarrhea','fever','slight fever','vomit','blurred vision','difficulty swallowing','double vision',\n",
    "                   'muscle weakness','intense abdominal cramp','fatigue','loss of appetite','substantial weight loss','dark urine','headache','jaundice',\n",
    "                   'muscle ache','decreased apptite','right upper-quadrant abdominal pain','left lower-quadrant pain','chronic diarrhea','occasional bloody diarrhea','weight loss',\n",
    "                  'hematochezia','melena','weight loss','anorexia','upset stomach','stomach cramp','dropping eyelids','slurred speech','diffculty swallowing','breathing and dry mouth',\n",
    "                  'paralysis','loss of balance','joint ache','back ache','chest pain','gastroenteritis','stomach flu','food poisoning','foodborne illness','foodborne disease',\n",
    "                  'clinic','microorganisms','gastroenteritis','germ','pathogen','illness','poison','symptom','disease','doctor','infect','throwing up', 'throw up']# ,'sick'\n",
    "   #,'chill','chills' number decrease from 7200 to 870 after remove chill\n",
    "   \"\"\"\n",
    "    symptom_words=['food poisoning','nausea',\n",
    "                   'diarrhea','vomit','foodborne illness','foodborne disease','poison','throwing up', 'throw up']# ,'sick'\n",
    "    #,'chill','chills' number decrease from 7200 to 870 after remove chill\n",
    "    collect_word = 0\n",
    "    for en in symptom_words:\n",
    "        if en in str(x):\n",
    "            collect_word = en\n",
    "    return collect_word\n",
    "\n",
    "aa_df['symptom'] = aa_df['text'].apply(search_symptom_words)\n",
    "eng_symptom=aa_df[aa_df['symptom']!=0]\n",
    "eng_symptom=eng_symptom.reset_index(drop=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 406,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(332, 3)"
      ]
     },
     "execution_count": 406,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eng_symptom.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 603,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "What an absolute waste !!! My wife got food poisoning the first day. First meal upon arrival, no alcohol, 6 hours later she became violently ill. Was sick the whole trip. Room was filthy, the sink backed up, the hot water ran out on one day, The bed was gross. If they just simply move the bed when cleaning and did a thorough job it could be better. Stay at motel 6........it would be an upgrade !!!!  Managers take no responsibility for my wife's illness so far, Just kick the can down the road. Oh and the 30 bucks to check in early...WTH...... if the rooms open give the customer the key. Just another way to rip you off.\n"
     ]
    }
   ],
   "source": [
    "#11,19,32,55\n",
    "#need to exclude,not restaurant 1,2, 3 ,4,5,6,7,8,9,10,12,13,14\n",
    "#new id :18,22,28, 34?, 35, 36,38,42,48,49,54,58,59,61,62,67,70,74,76,78,79,88,89,90,96,99,103,105,108,109,114,116\n",
    "#118,121,135,139,141\n",
    "#new-third file 143,144,151,152,157,158,159,163,164,166,167,169,171,181,182,184,198,204,205,207,213,214,218,221,225\n",
    "#229,232,236,238,239,241,242,245,251,254,255,257,259,261,262,264,267,274,275,278,279,280,283,285,287,291,292,293,295\n",
    "#296,297,301,307,310,311,312,316,317,319,321,328,331\n",
    "n=331\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "print(eng_symptom['text'].tolist()[n])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 453,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>star</th>\n",
       "      <th>text</th>\n",
       "      <th>symptom</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>1.0</td>\n",
       "      <td>Hmm.. I never write reviews on here, but I fel...</td>\n",
       "      <td>poison</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>2.0</td>\n",
       "      <td>sadly I have to write a bad review, I got food...</td>\n",
       "      <td>poison</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>1.0</td>\n",
       "      <td>The b7 I ordered looks/tastes nothing like nig...</td>\n",
       "      <td>diarrhea</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55</th>\n",
       "      <td>2.0</td>\n",
       "      <td>The food was pretty good! Went there for dinne...</td>\n",
       "      <td>diarrhea</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    star                                               text   symptom\n",
       "11   1.0  Hmm.. I never write reviews on here, but I fel...    poison\n",
       "19   2.0  sadly I have to write a bad review, I got food...    poison\n",
       "32   1.0  The b7 I ordered looks/tastes nothing like nig...  diarrhea\n",
       "55   2.0  The food was pretty good! Went there for dinne...  diarrhea"
      ]
     },
     "execution_count": 453,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "real_symptom_yelp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 382,
   "metadata": {},
   "outputs": [],
   "source": [
    "real_symptom_yelp_2=eng_symptom.loc[[18,22,28, 34,35,36,38,42,48,49,54,58,59,61,62,67,70,74,76,78,79,88,89,90,96,99,103,105,108,109,114,116,\n",
    "                                     118,121,135,139,141]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 604,
   "metadata": {},
   "outputs": [],
   "source": [
    "real_symptom_yelp_3 = eng_symptom.loc[[143,144,151,152,157,158,159,163,164,166,167,169,171,181,182,184,198,204,205,207,213,214,218,221,225\n",
    ",229,232,236,238,239,241,242,245,251,254,255,257,259,261,262,264,267,274,275,278,279,280,283,285,287,291,292,293,295\n",
    ",296,297,301,307,310,311,312,316,317,319,321,328,331]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 605,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(67, 3)"
      ]
     },
     "execution_count": 605,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "real_symptom_yelp_3.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 609,
   "metadata": {},
   "outputs": [],
   "source": [
    "real_symptom_yelp_final =pd.concat([real_symptom_yelp,real_symptom_yelp_2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 611,
   "metadata": {},
   "outputs": [],
   "source": [
    "real_symptom_yelp_final =pd.concat([real_symptom_yelp_final,real_symptom_yelp_3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 614,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(108, 3)"
      ]
     },
     "execution_count": 614,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "real_symptom_yelp_final.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 615,
   "metadata": {},
   "outputs": [],
   "source": [
    "real_symptom_yelp_final.index=range(108)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 617,
   "metadata": {},
   "outputs": [],
   "source": [
    "real_symptom_yelp_final.to_csv(\"real_symptom_yelp_final.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "############################Doc2Vec model part ####################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1298,
   "metadata": {},
   "outputs": [],
   "source": [
    "def vec_for_learning(model, tagged_docs):\n",
    "    sents = tagged_docs.values\n",
    "    targets, regressors = zip(*[(doc.tags[0], model.infer_vector(doc.words, steps=40)) for doc in sents])\n",
    "    #targets, regressors = zip(*[(doc.tags[0], model.infer_vector(doc.words, steps=20)) for doc in sents])\n",
    "    #print(\"targets:\",targets)\n",
    "    #print(\"regressors:\",regressors)\n",
    "    return targets, regressors\n",
    "\n",
    "\n",
    "def get_vectors(model, tagged_docs):\n",
    "    sents = tagged_docs.values\n",
    "    targets, regressors = zip(*[(doc.tags[0], model.infer_vector(doc.words, steps=40)) for doc in sents])\n",
    "    return targets, regressors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1299,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_dbow(tagged_data):  \n",
    "    \"\"\"\n",
    "    cores = multiprocessing.cpu_count()\n",
    "\n",
    "    model_dbow = Doc2Vec(dm=0, vector_size=200, negative=5, hs=0, min_count=2, sample = 0, workers=cores, epoches = 30)\n",
    "    model_dbow.build_vocab([x for x in tqdm(train_tagged.values)])\n",
    "\n",
    "    for epoch in range(30):\n",
    "        model_dbow.train(utils.shuffle([x for x in tqdm(train_tagged.values)]), total_examples=len(train_tagged.values), epochs=1)\n",
    "        model_dbow.alpha -= 0.002\n",
    "        model_dbow.min_alpha = model_dbow.alpha\n",
    "    model_dbow.delete_temporary_training_data(keep_doctags_vectors=True, keep_inference=True)\n",
    "    \n",
    "    return model_dbow\n",
    "    #model_dbow.save('model_dbow')\n",
    "    \"\"\"\n",
    "    max_epochs = 40\n",
    "    model = Doc2Vec(dm=0,vector_size=5)\n",
    "    #model = Doc2Vec(dm=0,vector_size=5)  # of course, if non-default parameters needed, use them here\n",
    "                       # but most users won't need to change alpha/min_alpha at all\n",
    "    #model = Doc2Vec(dm=0,min_count=1,window=5,sample=1e-3,negative=5,workers=3,vector_size=5)\n",
    "    model.build_vocab([x for x in tqdm(train_tagged.values)])\n",
    "    model.train(utils.shuffle([x for x in tqdm(train_tagged.values)]), total_examples=model.corpus_count, epochs=max_epochs)\n",
    "    return model\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1300,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_dmm(train_tagged):\n",
    "    \"\"\"\n",
    "    model_dmm = Doc2Vec(dm=1, dm_mean=1, vector_size=200, window=10, negative=5, min_count=1, workers=5, alpha=0.065, min_alpha=0.065,epoches = 30)\n",
    "    model_dmm.build_vocab([x for x in tqdm(train_tagged.values)])\n",
    "    \n",
    "    \n",
    "    for epoch in range(30):\n",
    "        model_dmm.train(utils.shuffle([x for x in tqdm(train_tagged.values)]), total_examples=len(train_tagged.values), epochs=1)\n",
    "        model_dmm.alpha -= 0.002\n",
    "        model_dmm.min_alpha = model_dmm.alpha\n",
    "        \n",
    "    model_dmm.delete_temporary_training_data(keep_doctags_vectors=True, keep_inference=True)\n",
    "    return model_dmm\n",
    "\n",
    "    #model_dmm.save('model_dmm')\n",
    "    \"\"\"\n",
    "    max_epochs = 40\n",
    "    model = Doc2Vec(dm=1,vector_size=5)  # of course, if non-default parameters needed, use them here\n",
    "                       # but most users won't need to change alpha/min_alpha at all\n",
    "\n",
    "    model.build_vocab([x for x in tqdm(train_tagged.values)])\n",
    "    model.train(utils.shuffle([x for x in tqdm(train_tagged.values)]), total_examples=model.corpus_count, epochs=max_epochs)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def concat_model(model_dbow,model_dmm):   \n",
    "    new_model = ConcatenatedDoc2Vec([model_dbow, model_dmm])\n",
    "    return new_model\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "############################Logistic Regression part ####################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1225,
   "metadata": {},
   "outputs": [],
   "source": [
    "def logreg_weight(X_train,y_train,X_test,y_test):\n",
    "    logreg = LogisticRegression(n_jobs=1, C=1e5, max_iter=10000,class_weight='balanced')#??? \n",
    "    logreg.fit(X_train, y_train)\n",
    "    y_pred = logreg.predict(X_test)\n",
    " \n",
    "\n",
    "    print('Testing accuracy %s' % accuracy_score(y_test, y_pred))\n",
    "    print('Testing F1 score: {}'.format(f1_score(y_test, y_pred, average='weighted')))\n",
    "    print(f'Area Under Curve: {roc_auc_score(y_test, y_pred)}')\n",
    "    print(f'Recall score: {recall_score(y_test,y_pred,average=None)}')\n",
    "    #return y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1226,
   "metadata": {},
   "outputs": [],
   "source": [
    "def logreg(X_train,y_train,X_test,y_test):\n",
    "    logreg = LogisticRegression(n_jobs=1, C=1e5, max_iter=10000)#??? \n",
    "    logreg.fit(X_train, y_train)\n",
    "    y_pred = logreg.predict(X_test)\n",
    " \n",
    "\n",
    "    print('Testing accuracy %s' % accuracy_score(y_test, y_pred))\n",
    "    print('Testing F1 score: {}'.format(f1_score(y_test, y_pred, average='weighted')))\n",
    "    print(f'Area Under Curve: {roc_auc_score(y_test, y_pred)}')\n",
    "    print(f'Recall score: {recall_score(y_test,y_pred,average=None)}')\n",
    "    #return y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "############################Text Preprocessing #################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "def tokenize_text(text):\n",
    "    tokens = []\n",
    "    for sent in nltk.sent_tokenize(text):\n",
    "        for word in nltk.word_tokenize(sent):\n",
    "            if len(word) < 1:\n",
    "                continue\n",
    "            tokens.append(word.lower())\n",
    "    return tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 972,
   "metadata": {},
   "outputs": [],
   "source": [
    "##### read from csv\n",
    "df = pd.read_csv('all_real_fake_symptom_train.csv')\n",
    "#df = df[['cut_review','label']]\n",
    "df = df[['cut_review','label','sympt_count','m_usr_score_hygiene','m_usr_score_value','score_hygiene_diff','score_value_diff']]\n",
    "df = df[pd.notnull(df['cut_review'])]\n",
    "df = df[pd.notnull(df['label'])]\n",
    "df['label']=df['label'].astype('int')\n",
    "\n",
    "df_test = pd.read_csv('all_real_fake_symptom_test.csv')\n",
    "df_test = df_test[['cut_review','label','sympt_count','m_usr_score_hygiene','m_usr_score_value','score_hygiene_diff','score_value_diff']]\n",
    "#df_test = df_test[pd.notnull(df['cut_review'])]\n",
    "#df_test = df_test[pd.notnull(df['label'])]\n",
    "\n",
    "df.index=range((df.shape)[0])\n",
    "df_test.index=range((df_test.shape)[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 973,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cut_review</th>\n",
       "      <th>label</th>\n",
       "      <th>sympt_count</th>\n",
       "      <th>m_usr_score_hygiene</th>\n",
       "      <th>m_usr_score_value</th>\n",
       "      <th>score_hygiene_diff</th>\n",
       "      <th>score_value_diff</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>又 来到 我们 最爱 的 平价 饭堂 哈哈 这次 点 了 两款 没有 吃 过 的 菜式 试试...</td>\n",
       "      <td>0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.617021</td>\n",
       "      <td>3.659574</td>\n",
       "      <td>-2.617021</td>\n",
       "      <td>0.340426</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>见 佢 张 poster 写 26810 再有 85 折 咁 平 既 自助 晚餐 一 於 同...</td>\n",
       "      <td>0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>-2.000000</td>\n",
       "      <td>-2.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          cut_review  label  sympt_count  \\\n",
       "0  又 来到 我们 最爱 的 平价 饭堂 哈哈 这次 点 了 两款 没有 吃 过 的 菜式 试试...      0          3.0   \n",
       "1  见 佢 张 poster 写 26810 再有 85 折 咁 平 既 自助 晚餐 一 於 同...      0          3.0   \n",
       "\n",
       "   m_usr_score_hygiene  m_usr_score_value  score_hygiene_diff  \\\n",
       "0             3.617021           3.659574           -2.617021   \n",
       "1             3.000000           3.000000           -2.000000   \n",
       "\n",
       "   score_value_diff  \n",
       "0          0.340426  \n",
       "1         -2.000000  "
      ]
     },
     "execution_count": 973,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_new=[]\n",
    "y_train_new=[]\n",
    "y_test_new=[]\n",
    "X_test_new=[]\n",
    "\n",
    "\n",
    "for i in range(len(df)):\n",
    "    aa=(np.append([],float(df.loc[i]['sympt_count'])))\n",
    "    aa=(np.append(aa,float(df.loc[i]['m_usr_score_hygiene'])))\n",
    "    aa=(np.append(aa,float(df.loc[i]['m_usr_score_value'])))\n",
    "    aa=(np.append(aa,float(df.loc[i]['score_hygiene_diff'])))        \n",
    "    aa=(np.append(aa,float(df.loc[i]['score_value_diff'])))\n",
    "\n",
    "    X_train_new.append(aa)\n",
    "    y_train_new.append(float(df.loc[i]['label']))\n",
    "X_train_new=tuple(X_train_new)\n",
    "y_train_new=tuple(y_train_new)\n",
    "\n",
    "\n",
    "for i in range(len(df_test)):\n",
    "    bb=(np.append([],float(df_test.loc[i]['sympt_count'])))\n",
    "    bb=(np.append(bb,float(df_test.loc[i]['m_usr_score_hygiene'])))\n",
    "    bb=(np.append(bb,float(df_test.loc[i]['m_usr_score_value'])))\n",
    "    bb=(np.append(bb,float(df_test.loc[i]['score_hygiene_diff'])))        \n",
    "    bb=(np.append(bb,float(df_test.loc[i]['score_value_diff'])))\n",
    "    X_test_new.append(bb)\n",
    "    y_test_new.appned(float(df_test.loc[i]['label']))\n",
    "    \n",
    "X_test_new=tuple(X_test_new)\n",
    "y_test_new=tuple(y_test_new)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 674,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('all_real_fake_symptom_train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 675,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review_id</th>\n",
       "      <th>rtr_id</th>\n",
       "      <th>usr_id</th>\n",
       "      <th>usr_name</th>\n",
       "      <th>usr_num_cmt</th>\n",
       "      <th>usr_date_publish</th>\n",
       "      <th>usr_score_taste</th>\n",
       "      <th>usr_score_decor</th>\n",
       "      <th>usr_score_service</th>\n",
       "      <th>usr_score_hygiene</th>\n",
       "      <th>...</th>\n",
       "      <th>language</th>\n",
       "      <th>clean_rev_cmt</th>\n",
       "      <th>cut_review</th>\n",
       "      <th>label</th>\n",
       "      <th>sympt_count</th>\n",
       "      <th>tend_count</th>\n",
       "      <th>m_usr_score_hygiene</th>\n",
       "      <th>m_usr_score_value</th>\n",
       "      <th>score_hygiene_diff</th>\n",
       "      <th>score_value_diff</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2233930</td>\n",
       "      <td>37556</td>\n",
       "      <td>98626</td>\n",
       "      <td>VIANNAKIT</td>\n",
       "      <td>222</td>\n",
       "      <td>2012-05-04</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>s_cn</td>\n",
       "      <td>又来到我们最爱的平价饭堂哈哈这次点了两款没有吃过的菜式试试看第一款卡邦尼杂菌烩饭浓浓的卡邦尼...</td>\n",
       "      <td>又 来到 我们 最爱 的 平价 饭堂 哈哈 这次 点 了 两款 没有 吃 过 的 菜式 试试...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.617021</td>\n",
       "      <td>3.659574</td>\n",
       "      <td>-2.617021</td>\n",
       "      <td>0.340426</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2282733</td>\n",
       "      <td>211</td>\n",
       "      <td>593313</td>\n",
       "      <td>water姐</td>\n",
       "      <td>2</td>\n",
       "      <td>2013-02-05</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>s_cn</td>\n",
       "      <td>见佢张poster写26810再有85折咁平既自助晚餐一於同朋友试试其实咁既价钱预左唔会有太...</td>\n",
       "      <td>见 佢 张 poster 写 26810 再有 85 折 咁 平 既 自助 晚餐 一 於 同...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>-2.000000</td>\n",
       "      <td>-2.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows × 29 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  review_id rtr_id  usr_id   usr_name usr_num_cmt usr_date_publish  \\\n",
       "0   2233930  37556   98626  VIANNAKIT         222       2012-05-04   \n",
       "1   2282733    211  593313     water姐           2       2013-02-05   \n",
       "\n",
       "  usr_score_taste usr_score_decor  usr_score_service  usr_score_hygiene  ...  \\\n",
       "0               4               3                  4                  1  ...   \n",
       "1               1               1                  3                  1  ...   \n",
       "\n",
       "   language                                      clean_rev_cmt  \\\n",
       "0      s_cn  又来到我们最爱的平价饭堂哈哈这次点了两款没有吃过的菜式试试看第一款卡邦尼杂菌烩饭浓浓的卡邦尼...   \n",
       "1      s_cn  见佢张poster写26810再有85折咁平既自助晚餐一於同朋友试试其实咁既价钱预左唔会有太...   \n",
       "\n",
       "                                          cut_review label sympt_count  \\\n",
       "0  又 来到 我们 最爱 的 平价 饭堂 哈哈 这次 点 了 两款 没有 吃 过 的 菜式 试试...   0.0         3.0   \n",
       "1  见 佢 张 poster 写 26810 再有 85 折 咁 平 既 自助 晚餐 一 於 同...   0.0         3.0   \n",
       "\n",
       "  tend_count m_usr_score_hygiene m_usr_score_value  score_hygiene_diff  \\\n",
       "0        0.0            3.617021          3.659574           -2.617021   \n",
       "1        3.0            3.000000          3.000000           -2.000000   \n",
       "\n",
       "  score_value_diff  \n",
       "0         0.340426  \n",
       "1        -2.000000  \n",
       "\n",
       "[2 rows x 29 columns]"
      ]
     },
     "execution_count": 675,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 545,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\nen_r = en_r[['cut_review']]\\nen_r = en_r[pd.notnull(en_r['cut_review'])]\\n#en_r = en_r[pd.notnull(en_r['label'])]\\n\\nen_f = pd.read_csv('eng_fake_symptom_final.csv')\\nen_f = en_f[['cut_review']]\\nen_f = en_f[pd.notnull(en_f['cut_review'])]\\n#en_f = en_f[pd.notnull(en_f['label'])]\\n\\n\""
      ]
     },
     "execution_count": 545,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "####read in english sympotom reviews\n",
    "en_r = pd.read_csv('eng_real_symptom_final.csv')\n",
    "\n",
    "\n",
    "en_f = pd.read_csv('eng_fake_symptom_final.csv')\n",
    "\n",
    "\"\"\"\n",
    "en_r = en_r[['cut_review']]\n",
    "en_r = en_r[pd.notnull(en_r['cut_review'])]\n",
    "#en_r = en_r[pd.notnull(en_r['label'])]\n",
    "\n",
    "en_f = pd.read_csv('eng_fake_symptom_final.csv')\n",
    "en_f = en_f[['cut_review']]\n",
    "en_f = en_f[pd.notnull(en_f['cut_review'])]\n",
    "#en_f = en_f[pd.notnull(en_f['label'])]\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 546,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review_id</th>\n",
       "      <th>rtr_id</th>\n",
       "      <th>usr_id</th>\n",
       "      <th>usr_name</th>\n",
       "      <th>usr_num_cmt</th>\n",
       "      <th>usr_date_publish</th>\n",
       "      <th>usr_score_taste</th>\n",
       "      <th>usr_score_decor</th>\n",
       "      <th>usr_score_service</th>\n",
       "      <th>usr_score_hygiene</th>\n",
       "      <th>usr_score_value</th>\n",
       "      <th>usr_date_visit</th>\n",
       "      <th>usr_eat_way</th>\n",
       "      <th>usr_per_price</th>\n",
       "      <th>rev_cmt</th>\n",
       "      <th>symptom</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1966200</td>\n",
       "      <td>90</td>\n",
       "      <td>102827</td>\n",
       "      <td>foodchick</td>\n",
       "      <td>4</td>\n",
       "      <td>2009-01-12</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>$25</td>\n",
       "      <td>for someone living on hk side the biggest head...</td>\n",
       "      <td>headache</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2166891</td>\n",
       "      <td>35459</td>\n",
       "      <td>24346</td>\n",
       "      <td>tabero</td>\n",
       "      <td>275</td>\n",
       "      <td>2011-05-03</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>None</td>\n",
       "      <td>堂食</td>\n",
       "      <td>$500</td>\n",
       "      <td>It is a pre mother day buffet ....even there d...</td>\n",
       "      <td>sick</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   review_id  rtr_id  usr_id   usr_name usr_num_cmt usr_date_publish  \\\n",
       "0    1966200      90  102827  foodchick           4       2009-01-12   \n",
       "1    2166891   35459   24346     tabero         275       2011-05-03   \n",
       "\n",
       "  usr_score_taste usr_score_decor usr_score_service usr_score_hygiene  \\\n",
       "0               5               3                 4                 3   \n",
       "1               4               4                 4                 4   \n",
       "\n",
       "  usr_score_value usr_date_visit usr_eat_way usr_per_price  \\\n",
       "0               4           None        None          $25    \n",
       "1               3           None          堂食         $500    \n",
       "\n",
       "                                             rev_cmt   symptom  \n",
       "0  for someone living on hk side the biggest head...  headache  \n",
       "1  It is a pre mother day buffet ....even there d...      sick  "
      ]
     },
     "execution_count": 546,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "en_f.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 547,
   "metadata": {},
   "outputs": [],
   "source": [
    "en_r['clean_rev_cmt'] = en_r['rev_cmt'].apply(eng_remove_punctuation)\n",
    "en_r['cut_review'] = en_r['clean_rev_cmt'].apply(lambda x: \" \".join([w for w in list(word_tokenize(x))]))\n",
    "en_r['label']= 0\n",
    "\n",
    "en_f['clean_rev_cmt'] = en_f['rev_cmt'].apply(eng_remove_punctuation)\n",
    "en_f['cut_review'] = en_f['clean_rev_cmt'].apply(lambda x: \" \".join([w for w in list(word_tokenize(x))]))\n",
    "en_f['label']= 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 548,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review_id</th>\n",
       "      <th>rtr_id</th>\n",
       "      <th>usr_id</th>\n",
       "      <th>usr_name</th>\n",
       "      <th>usr_num_cmt</th>\n",
       "      <th>usr_date_publish</th>\n",
       "      <th>usr_score_taste</th>\n",
       "      <th>usr_score_decor</th>\n",
       "      <th>usr_score_service</th>\n",
       "      <th>usr_score_hygiene</th>\n",
       "      <th>usr_score_value</th>\n",
       "      <th>usr_date_visit</th>\n",
       "      <th>usr_eat_way</th>\n",
       "      <th>usr_per_price</th>\n",
       "      <th>rev_cmt</th>\n",
       "      <th>symptom</th>\n",
       "      <th>clean_rev_cmt</th>\n",
       "      <th>cut_review</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1966200</td>\n",
       "      <td>90</td>\n",
       "      <td>102827</td>\n",
       "      <td>foodchick</td>\n",
       "      <td>4</td>\n",
       "      <td>2009-01-12</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>$25</td>\n",
       "      <td>for someone living on hk side the biggest head...</td>\n",
       "      <td>headache</td>\n",
       "      <td>for someone living on hk side the biggest head...</td>\n",
       "      <td>for someone living on hk side the biggest head...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2166891</td>\n",
       "      <td>35459</td>\n",
       "      <td>24346</td>\n",
       "      <td>tabero</td>\n",
       "      <td>275</td>\n",
       "      <td>2011-05-03</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>None</td>\n",
       "      <td>堂食</td>\n",
       "      <td>$500</td>\n",
       "      <td>It is a pre mother day buffet ....even there d...</td>\n",
       "      <td>sick</td>\n",
       "      <td>It is a pre mother day buffet even there dont ...</td>\n",
       "      <td>It is a pre mother day buffet even there dont ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   review_id  rtr_id  usr_id   usr_name usr_num_cmt usr_date_publish  \\\n",
       "0    1966200      90  102827  foodchick           4       2009-01-12   \n",
       "1    2166891   35459   24346     tabero         275       2011-05-03   \n",
       "\n",
       "  usr_score_taste usr_score_decor usr_score_service usr_score_hygiene  \\\n",
       "0               5               3                 4                 3   \n",
       "1               4               4                 4                 4   \n",
       "\n",
       "  usr_score_value usr_date_visit usr_eat_way usr_per_price  \\\n",
       "0               4           None        None          $25    \n",
       "1               3           None          堂食         $500    \n",
       "\n",
       "                                             rev_cmt   symptom  \\\n",
       "0  for someone living on hk side the biggest head...  headache   \n",
       "1  It is a pre mother day buffet ....even there d...      sick   \n",
       "\n",
       "                                       clean_rev_cmt  \\\n",
       "0  for someone living on hk side the biggest head...   \n",
       "1  It is a pre mother day buffet even there dont ...   \n",
       "\n",
       "                                          cut_review  label  \n",
       "0  for someone living on hk side the biggest head...      1  \n",
       "1  It is a pre mother day buffet even there dont ...      1  "
      ]
     },
     "execution_count": 548,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "en_f.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 555,
   "metadata": {},
   "outputs": [],
   "source": [
    "en_r = en_r[['cut_review','label']]\n",
    "en_r = en_r[pd.notnull(en_r['cut_review'])]\n",
    "en_r = en_r[pd.notnull(en_r['label'])]\n",
    "\n",
    "en_f = en_f[['cut_review','label']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 556,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(24, 2)"
      ]
     },
     "execution_count": 556,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "en_r.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 557,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(267, 2)"
      ]
     },
     "execution_count": 557,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "en_f.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 562,
   "metadata": {},
   "outputs": [],
   "source": [
    "en_r_train = en_r.head(12)\n",
    "en_r_test = en_r.tail(12)\n",
    "en_f_train = en_f.head(134)\n",
    "en_f_test = en_f.tail(134)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 568,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_en = df.append(en_r_train)\n",
    "df_en=df_en.append(en_f_train)\n",
    "df_test_en = df_test.append(en_r_test)\n",
    "df_test_en=df_test_en.append(en_f_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 505,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_0=df.loc[df['label']==0]\n",
    "df_1=df.loc[df['label']==1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 335,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_cn_symptom = df.append(df_test)\n",
    "all_cn_symptom.index=range((all_cn_symptom.shape)[0])\n",
    "all_cn_symptom['cut_review'].apply(lambda x: len(x.split(' '))).sum()\n",
    "all_cn_symptom_tagged = all_cn_symptom.apply(\n",
    "    lambda r: TaggedDocument(words=tokenize_text(r['cut_review']), tags=[r.label]), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 679,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "49659"
      ]
     },
     "execution_count": 679,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['cut_review'].apply(lambda x: len(x.split(' '))).sum()\n",
    "df_test['cut_review'].apply(lambda x: len(x.split(' '))).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 680,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cut_review</th>\n",
       "      <th>label</th>\n",
       "      <th>sympt_count</th>\n",
       "      <th>m_usr_score_hygiene</th>\n",
       "      <th>m_usr_score_value</th>\n",
       "      <th>score_hygiene_diff</th>\n",
       "      <th>score_value_diff</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>又 来到 我们 最爱 的 平价 饭堂 哈哈 这次 点 了 两款 没有 吃 过 的 菜式 试试...</td>\n",
       "      <td>0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.617021</td>\n",
       "      <td>3.659574</td>\n",
       "      <td>-2.617021</td>\n",
       "      <td>0.340426</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>见 佢 张 poster 写 26810 再有 85 折 咁 平 既 自助 晚餐 一 於 同...</td>\n",
       "      <td>0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>-2.000000</td>\n",
       "      <td>-2.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          cut_review  label  sympt_count  \\\n",
       "0  又 来到 我们 最爱 的 平价 饭堂 哈哈 这次 点 了 两款 没有 吃 过 的 菜式 试试...      0          3.0   \n",
       "1  见 佢 张 poster 写 26810 再有 85 折 咁 平 既 自助 晚餐 一 於 同...      0          3.0   \n",
       "\n",
       "   m_usr_score_hygiene  m_usr_score_value  score_hygiene_diff  \\\n",
       "0             3.617021           3.659574           -2.617021   \n",
       "1             3.000000           3.000000           -2.000000   \n",
       "\n",
       "   score_value_diff  \n",
       "0          0.340426  \n",
       "1         -2.000000  "
      ]
     },
     "execution_count": 680,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 573,
   "metadata": {},
   "outputs": [],
   "source": [
    "###for two csv data with eng reviews\n",
    "df_en['cut_review'].apply(lambda x: len(x.split(' '))).sum()\n",
    "df_test_en['cut_review'].apply(lambda x: len(x.split(' '))).sum()\n",
    "\n",
    "df_en_tagged = df_en.apply(\n",
    "    lambda r: TaggedDocument(words=tokenize_text(r['cut_review']), tags=[r.label]), axis=1)\n",
    "df_test_en_tagged = df_test_en.apply(\n",
    "    lambda r: TaggedDocument(words=tokenize_text(r['cut_review']), tags=[r.label]), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 681,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_tagged = df.apply(\n",
    "    lambda r: TaggedDocument(words=tokenize_text(r['cut_review']), tags=[r.label]), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 682,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TaggedDocument(words=['又', '来到', '我们', '最爱', '的', '平价', '饭堂', '哈哈', '这次', '点', '了', '两款', '没有', '吃', '过', '的', '菜式', '试试看', '第一款', '卡', '邦尼', '杂菌', '烩饭', '浓浓的', '卡', '邦尼', '汁', '有', '浓浓的', '芝士', '和', '奶', '油香', '配上', '杂菌', '淡淡', '又', '浓浓的', '酱汁', '包住', '每颗', '饭粒', '不会', '很乾湿', '湿滑', '滑', '的', '口感', '真的', '不错', '第二款', '铁板', '羊', '扒', '两件', '小小的', '羊架', '闻起来', '很香', '可是', '吃', '起来', '味道', '很', 'so', '肉质', '很', '熟', '而且', '好多', '油', '喔', '不', '好吃', '整体', '上', '是', '可以', '接受', '的', '但', '最', '可恶', '的', '是', '第二天', '起来', '就', '开始', '肚子痛', '我们', '两人', '都', '肚泻', '了', '真的', '不', '知道', '是', '那个', '菜式', '出', '了', '味道', '最近'], tags=[0])"
      ]
     },
     "execution_count": 682,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_tagged.values[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 509,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_tagged = df.apply(\n",
    "    lambda r: TaggedDocument(words=tokenize_text(r['cut_review']), tags=[r.label]), axis=1)\n",
    "test_tagged = df_test.apply(\n",
    "    lambda r: TaggedDocument(words=tokenize_text(r['cut_review']), tags=[r.label]), axis=1)\n",
    "#train_tagged.values[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 910,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1399/1399 [00:00<00:00, 947800.24it/s]\n",
      "100%|██████████| 1399/1399 [00:00<00:00, 3153052.82it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing accuracy 0.8210526315789474\n",
      "Testing F1 score: 0.8177977785505349\n",
      "Area Under Curve: 0.7653490328006729\n",
      "Recall score: [0.63414634 0.89655172]\n",
      "Testing accuracy 0.8175438596491228\n",
      "Testing F1 score: 0.8161531878476679\n",
      "Area Under Curve: 0.770154992190316\n",
      "Recall score: [0.65853659 0.8817734 ]\n"
     ]
    }
   ],
   "source": [
    "####dbow\n",
    "model_dbow=train_dbow(train_tagged)\n",
    "model_dbow.save('model_dbow')\n",
    "y_train, X_train = vec_for_learning(model_dbow, train_tagged)\n",
    "y_test, X_test = vec_for_learning(model_dbow, test_tagged)\n",
    "logreg(X_train,y_train,X_test,y_test)\n",
    "logreg_weight(X_train,y_train,X_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 912,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1399/1399 [00:00<00:00, 835397.39it/s]\n",
      "100%|██████████| 1399/1399 [00:00<00:00, 3227629.98it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing accuracy 0.7473684210526316\n",
      "Testing F1 score: 0.7540011805882668\n",
      "Area Under Curve: 0.7245284152348912\n",
      "Recall score: [0.67073171 0.77832512]\n",
      "Testing accuracy 0.7473684210526316\n",
      "Testing F1 score: 0.7540011805882668\n",
      "Area Under Curve: 0.7245284152348912\n",
      "Recall score: [0.67073171 0.77832512]\n"
     ]
    }
   ],
   "source": [
    "####dmm\n",
    "model_dmm=train_dmm(train_tagged)\n",
    "model_dmm.save('model_dmm')\n",
    "y_train, X_train = vec_for_learning(model_dmm, train_tagged)\n",
    "y_test, X_test = vec_for_learning(model_dmm, test_tagged)\n",
    "logreg(X_train,y_train,X_test,y_test)\n",
    "logreg_weight(X_train,y_train,X_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 913,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing accuracy 0.7789473684210526\n",
      "Testing F1 score: 0.7863148685361697\n",
      "Area Under Curve: 0.7757719572269615\n",
      "Recall score: [0.76829268 0.78325123]\n",
      "-----\n",
      "Testing accuracy 0.775438596491228\n",
      "Testing F1 score: 0.7831209602954754\n",
      "Area Under Curve: 0.7733089030397694\n",
      "Recall score: [0.76829268 0.77832512]\n"
     ]
    }
   ],
   "source": [
    "####dbow+dmm\n",
    "new_model=concat_model(model_dbow,model_dmm)\n",
    "y_train, X_train = get_vectors(new_model, train_tagged)\n",
    "y_test, X_test = get_vectors(new_model, test_tagged)\n",
    "logreg(X_train,y_train,X_test,y_test)\n",
    "print(\"-----\")\n",
    "logreg_weight(X_train,y_train,X_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 918,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing accuracy 0.8350877192982457\n",
      "Testing F1 score: 0.833497874972516\n",
      "Area Under Curve: 0.7897392767031118\n",
      "Recall score: [0.68292683 0.89655172]\n",
      "----\n",
      "Testing accuracy 0.8421052631578947\n",
      "Testing F1 score: 0.8452921668902493\n",
      "Area Under Curve: 0.8310104529616725\n",
      "Recall score: [0.80487805 0.85714286]\n",
      "============end=============\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/yanniyang/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "X_train_new=[]\n",
    "X_test_new=[]\n",
    "\n",
    "y_train, X_train = vec_for_learning(model_dbow, train_tagged)\n",
    "y_test, X_test = vec_for_learning(model_dbow,test_tagged)\n",
    "\n",
    "for i in range(len(X_train)):\n",
    "    aa=(np.append(X_train[i],float(df.loc[i]['sympt_count']*100)))\n",
    "    aa=(np.append(aa,float(df.loc[i]['m_usr_score_hygiene']*100)))\n",
    "    aa=(np.append(aa,float(df.loc[i]['m_usr_score_value']*100)))\n",
    "    aa=(np.append(aa,float(df.loc[i]['score_hygiene_diff']*100)))        \n",
    "    aa=(np.append(aa,float(df.loc[i]['score_value_diff']*100)))\n",
    "    X_train_new.append(aa)\n",
    "X_train_new=tuple(X_train_new)\n",
    "\n",
    "for i in range(len(X_test)):\n",
    "    bb=(np.append(X_test[i],float(df.loc[i]['sympt_count']*100)))\n",
    "    bb=(np.append(bb,float(df.loc[i]['m_usr_score_hygiene']*100)))\n",
    "    bb=(np.append(bb,float(df.loc[i]['m_usr_score_value']*100)))\n",
    "    bb=(np.append(bb,float(df.loc[i]['score_hygiene_diff']*100)))        \n",
    "    bb=(np.append(bb,float(df.loc[i]['score_value_diff']*100)))\n",
    "    X_test_new.append(bb)\n",
    "X_test_new=tuple(X_test_new)\n",
    "\n",
    "logreg(X_train_new,y_train,X_test_new,y_test)\n",
    "print(\"----\")\n",
    "logreg_weight(X_train_new,y_train,X_test_new,y_test)\n",
    "print(\"============end=============\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 919,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/yanniyang/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing accuracy 0.7157894736842105\n",
      "Testing F1 score: 0.727376704775117\n",
      "Area Under Curve: 0.7168989547038328\n",
      "Recall score: [0.7195122  0.71428571]\n",
      "----\n",
      "Testing accuracy 0.7192982456140351\n",
      "Testing F1 score: 0.7309056424845898\n",
      "Area Under Curve: 0.7229965156794426\n",
      "Recall score: [0.73170732 0.71428571]\n",
      "============end=============\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/yanniyang/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "X_train_new=[]\n",
    "X_test_new=[]\n",
    "\n",
    "y_train, X_train = vec_for_learning(model_dmm, train_tagged)\n",
    "y_test, X_test = vec_for_learning(model_dmm,test_tagged)\n",
    "\n",
    "for i in range(len(X_train)):\n",
    "    aa=(np.append(X_train[i],float(df.loc[i]['sympt_count']*100)))\n",
    "    aa=(np.append(aa,float(df.loc[i]['m_usr_score_hygiene']*100)))\n",
    "    aa=(np.append(aa,float(df.loc[i]['m_usr_score_value']*100)))\n",
    "    aa=(np.append(aa,float(df.loc[i]['score_hygiene_diff']*100)))        \n",
    "    aa=(np.append(aa,float(df.loc[i]['score_value_diff']*100)))\n",
    "    X_train_new.append(aa)\n",
    "X_train_new=tuple(X_train_new)\n",
    "\n",
    "for i in range(len(X_test)):\n",
    "    bb=(np.append(X_test[i],float(df.loc[i]['sympt_count']*100)))\n",
    "    bb=(np.append(bb,float(df.loc[i]['m_usr_score_hygiene']*100)))\n",
    "    bb=(np.append(bb,float(df.loc[i]['m_usr_score_value']*100)))\n",
    "    bb=(np.append(bb,float(df.loc[i]['score_hygiene_diff']*100)))        \n",
    "    bb=(np.append(bb,float(df.loc[i]['score_value_diff']*100)))\n",
    "    X_test_new.append(bb)\n",
    "X_test_new=tuple(X_test_new)\n",
    "\n",
    "logreg(X_train_new,y_train,X_test_new,y_test)\n",
    "print(\"----\")\n",
    "logreg_weight(X_train_new,y_train,X_test_new,y_test)\n",
    "print(\"============end=============\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 917,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing accuracy 0.7368421052631579\n",
      "Testing F1 score: 0.7464915776887416\n",
      "Area Under Curve: 0.7316772798269854\n",
      "Recall score: [0.7195122  0.74384236]\n",
      "----\n",
      "Testing accuracy 0.7368421052631579\n",
      "Testing F1 score: 0.7464915776887416\n",
      "Area Under Curve: 0.7316772798269854\n",
      "Recall score: [0.7195122  0.74384236]\n",
      "============end=============\n"
     ]
    }
   ],
   "source": [
    "X_train_new=[]\n",
    "X_test_new=[]\n",
    "\n",
    "y_train, X_train = get_vectors(new_model, train_tagged)\n",
    "y_test, X_test = get_vectors(new_model, test_tagged)\n",
    "\n",
    "for i in range(len(X_train)):\n",
    "    aa=(np.append(X_train[i],float(df.loc[i]['sympt_count'])))\n",
    "    aa=(np.append(aa,float(df.loc[i]['m_usr_score_hygiene'])))\n",
    "    aa=(np.append(aa,float(df.loc[i]['m_usr_score_value'])))\n",
    "    aa=(np.append(aa,float(df.loc[i]['score_hygiene_diff'])))        \n",
    "    aa=(np.append(aa,float(df.loc[i]['score_value_diff'])))\n",
    "    X_train_new.append(aa)\n",
    "X_train_new=tuple(X_train_new)\n",
    "\n",
    "for i in range(len(X_test)):\n",
    "    bb=(np.append(X_test[i],float(df.loc[i]['sympt_count'])))\n",
    "    bb=(np.append(bb,float(df.loc[i]['m_usr_score_hygiene'])))\n",
    "    bb=(np.append(bb,float(df.loc[i]['m_usr_score_value'])))\n",
    "    bb=(np.append(bb,float(df.loc[i]['score_hygiene_diff'])))        \n",
    "    bb=(np.append(bb,float(df.loc[i]['score_value_diff'])))\n",
    "    X_test_new.append(bb)\n",
    "X_test_new=tuple(X_test_new)\n",
    "\n",
    "logreg(X_train_new,y_train,X_test_new,y_test)\n",
    "print(\"----\")\n",
    "logreg_weight(X_train_new,y_train,X_test_new,y_test)\n",
    "print(\"============end=============\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 922,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1399/1399 [00:00<00:00, 919290.51it/s]\n",
      "100%|██████████| 1399/1399 [00:00<00:00, 3195986.54it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing accuracy 0.8491228070175438\n",
      "Testing F1 score: 0.8482704582227334\n",
      "Area Under Curve: 0.8104950138171333\n",
      "Recall score: [0.7195122  0.90147783]\n",
      "Testing accuracy 0.8385964912280702\n",
      "Testing F1 score: 0.8435183220147142\n",
      "Area Under Curve: 0.8430854259281509\n",
      "Recall score: [0.85365854 0.83251232]\n"
     ]
    }
   ],
   "source": [
    "####dbow--only chinese-vector size=25\n",
    "model_dbow_chi_25=train_dbow(train_tagged)\n",
    "model_dbow_chi_25.save('model_dbow_chi_25')\n",
    "y_train, X_train = vec_for_learning(model_dbow_chi_25, train_tagged)\n",
    "y_test, X_test = vec_for_learning(model_dbow_chi_25, test_tagged)\n",
    "logreg(X_train,y_train,X_test,y_test)\n",
    "logreg_weight(X_train,y_train,X_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1031,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1399/1399 [00:00<00:00, 900941.39it/s]\n",
      "100%|██████████| 1399/1399 [00:00<00:00, 3153052.82it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing accuracy 0.8456140350877193\n",
      "Testing F1 score: 0.8471805985552116\n",
      "Area Under Curve: 0.8225699867836117\n",
      "Recall score: [0.76829268 0.87684729]\n",
      "Testing accuracy 0.8315789473684211\n",
      "Testing F1 score: 0.8378822687339098\n",
      "Area Under Curve: 0.8490628379190195\n",
      "Recall score: [0.8902439  0.80788177]\n"
     ]
    }
   ],
   "source": [
    "model_dbow_chi_10=train_dbow(train_tagged)\n",
    "model_dbow_chi_10.save('model_dbow_chi_10')\n",
    "y_train, X_train = vec_for_learning(model_dbow_chi_10, train_tagged)\n",
    "y_test, X_test = vec_for_learning(model_dbow_chi_10, test_tagged)\n",
    "logreg(X_train,y_train,X_test,y_test)\n",
    "logreg_weight(X_train,y_train,X_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1034,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1399/1399 [00:00<00:00, 992193.32it/s]\n",
      "100%|██████████| 1399/1399 [00:00<00:00, 3049808.37it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing accuracy 0.856140350877193\n",
      "Testing F1 score: 0.85352370432494\n",
      "Area Under Curve: 0.8081521086146821\n",
      "Recall score: [0.69512195 0.92118227]\n",
      "Testing accuracy 0.8491228070175438\n",
      "Testing F1 score: 0.8529113976408019\n",
      "Area Under Curve: 0.8468400817013095\n",
      "Recall score: [0.84146341 0.85221675]\n"
     ]
    }
   ],
   "source": [
    "model_dbow_chi_4=train_dbow(train_tagged)\n",
    "model_dbow_chi_4.save('model_dbow_chi_4')\n",
    "y_train, X_train = vec_for_learning(model_dbow_chi_4, train_tagged)\n",
    "y_test, X_test = vec_for_learning(model_dbow_chi_4, test_tagged)\n",
    "logreg(X_train,y_train,X_test,y_test)\n",
    "logreg_weight(X_train,y_train,X_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1140,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1399/1399 [00:00<00:00, 1379692.29it/s]\n",
      "100%|██████████| 1399/1399 [00:00<00:00, 3222312.63it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing accuracy 0.8701754385964913\n",
      "Testing F1 score: 0.869936693378734\n",
      "Area Under Curve: 0.8398113660939565\n",
      "Recall score: [0.76829268 0.91133005]\n",
      "Testing accuracy 0.8631578947368421\n",
      "Testing F1 score: 0.8665940583253784\n",
      "Area Under Curve: 0.8639613120269133\n",
      "Recall score: [0.86585366 0.86206897]\n"
     ]
    }
   ],
   "source": [
    "model_dbow_chi_5=train_dbow(train_tagged)\n",
    "model_dbow_chi_5.save('model_dbow_chi_5')\n",
    "y_train, X_train = vec_for_learning(model_dbow_chi_5, train_tagged)\n",
    "y_test, X_test = vec_for_learning(model_dbow_chi_5, test_tagged)\n",
    "logreg(X_train,y_train,X_test,y_test)\n",
    "logreg_weight(X_train,y_train,X_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1301,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1399/1399 [00:00<00:00, 878286.38it/s]\n",
      "100%|██████████| 1399/1399 [00:00<00:00, 3258096.22it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing accuracy 0.8596491228070176\n",
      "Testing F1 score: 0.8596491228070176\n",
      "Area Under Curve: 0.8287876967439626\n",
      "Recall score: [0.75609756 0.90147783]\n",
      "Testing accuracy 0.8631578947368421\n",
      "Testing F1 score: 0.8671925514030778\n",
      "Area Under Curve: 0.8712303256037487\n",
      "Recall score: [0.8902439  0.85221675]\n"
     ]
    }
   ],
   "source": [
    "model_dbow_chi_5_a=train_dbow(train_tagged)\n",
    "model_dbow_chi_5_a.save('model_dbow_chi_5_a')\n",
    "y_train, X_train = vec_for_learning(model_dbow_chi_5_a, train_tagged)\n",
    "y_test, X_test = vec_for_learning(model_dbow_chi_5_a, test_tagged)\n",
    "logreg(X_train,y_train,X_test,y_test)\n",
    "logreg_weight(X_train,y_train,X_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1176,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1399/1399 [00:00<00:00, 915704.01it/s]\n",
      "100%|██████████| 1399/1399 [00:00<00:00, 3153052.82it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing accuracy 0.775438596491228\n",
      "Testing F1 score: 0.7624573060558373\n",
      "Area Under Curve: 0.6824462333293284\n",
      "Recall score: [0.46341463 0.90147783]\n",
      "Testing accuracy 0.7649122807017544\n",
      "Testing F1 score: 0.7702529695769235\n",
      "Area Under Curve: 0.7404781929592695\n",
      "Recall score: [0.68292683 0.79802956]\n"
     ]
    }
   ],
   "source": [
    "model_dmm_chi_5=train_dmm(train_tagged)\n",
    "model_dmm_chi_5.save('model_dmm_chi_5')\n",
    "y_train, X_train = vec_for_learning(model_dmm_chi_5, train_tagged)\n",
    "y_test, X_test = vec_for_learning(model_dmm_chi_5, test_tagged)\n",
    "logreg(X_train,y_train,X_test,y_test)\n",
    "logreg_weight(X_train,y_train,X_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1177,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing accuracy 0.8385964912280702\n",
      "Testing F1 score: 0.8352960635855373\n",
      "Area Under Curve: 0.7849333173134686\n",
      "Recall score: [0.65853659 0.91133005]\n",
      "Testing accuracy 0.8491228070175438\n",
      "Testing F1 score: 0.8504140872773945\n",
      "Area Under Curve: 0.8250330409708039\n",
      "Recall score: [0.76829268 0.8817734 ]\n",
      "---------\n",
      "Testing accuracy 0.8105263157894737\n",
      "Testing F1 score: 0.8028682782168656\n",
      "Area Under Curve: 0.7361528295085906\n",
      "Recall score: [0.56097561 0.91133005]\n"
     ]
    }
   ],
   "source": [
    "model_dbow_dmm_chi_5 = concat_model(model_dbow_chi_5,model_dmm_chi_5)\n",
    "\n",
    "y_train, X_train = get_vectors(model_dbow_dmm_chi_5, train_tagged)\n",
    "y_test, X_test = get_vectors(model_dbow_dmm_chi_5, test_tagged)\n",
    "logreg(X_train,y_train,X_test,y_test)\n",
    "logreg_weight(X_train,y_train,X_test,y_test)\n",
    "\n",
    "print(\"---------\")\n",
    "clf = svm.SVC(kernel='rbf')\n",
    "clf.fit(X_train,y_train)\n",
    "\n",
    "y_pred = clf.predict(X_test)\n",
    " \n",
    "print('Testing accuracy %s' % accuracy_score(y_test, y_pred))\n",
    "print('Testing F1 score: {}'.format(f1_score(y_test, y_pred, average='weighted')))\n",
    "print(f'Area Under Curve: {roc_auc_score(y_test, y_pred)}')\n",
    "print(f'Recall score: {recall_score(y_test,y_pred,average=None)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1179,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing accuracy 0.8842105263157894\n",
      "Testing F1 score: 0.8839975913918439\n",
      "Area Under Curve: 0.8569325964195603\n",
      "Recall score: [0.79268293 0.92118227]\n",
      "----\n",
      "Testing accuracy 0.8912280701754386\n",
      "Testing F1 score: 0.8936991351773825\n",
      "Area Under Curve: 0.8945692658897033\n",
      "Recall score: [0.90243902 0.88669951]\n",
      "============end=============\n",
      "Testing accuracy 0.8175438596491228\n",
      "Testing F1 score: 0.8111402497533702\n",
      "Area Under Curve: 0.7483479514598101\n",
      "Recall score: [0.58536585 0.91133005]\n",
      "------ RF:________\n",
      "Testing accuracy 0.7824561403508772\n",
      "Testing F1 score: 0.7909081335883636\n",
      "Area Under Curve: 0.7927730385678241\n",
      "Recall score: [0.81707317 0.76847291]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "X_train_new=[]\n",
    "X_test_new=[]\n",
    "\n",
    "\n",
    "y_train, X_train = get_vectors(model_dbow_dmm_chi_5, train_tagged)\n",
    "y_test, X_test = get_vectors(model_dbow_dmm_chi_5, test_tagged)\n",
    "\n",
    "#y_train, X_train = vec_for_learning(model_dbow_chi_5, train_tagged)\n",
    "#y_test, X_test = vec_for_learning(model_dbow_chi_5,test_tagged)\n",
    "\n",
    "for i in range(len(X_train)):\n",
    "    aa=(np.append(X_train[i],float(df.loc[i]['sympt_count']*10000)))\n",
    "    aa=(np.append(aa,float(df.loc[i]['m_usr_score_hygiene']*10000)))\n",
    "    aa=(np.append(aa,float(df.loc[i]['m_usr_score_value']*10000)))\n",
    "    aa=(np.append(aa,float(df.loc[i]['score_hygiene_diff']*10000)))        \n",
    "    aa=(np.append(aa,float(df.loc[i]['score_value_diff']*10000)))\n",
    "    aa=normalize(aa)\n",
    "    X_train_new.append(aa)\n",
    "X_train_new=tuple(X_train_new)\n",
    "\n",
    "for i in range(len(X_test)):\n",
    "    bb=(np.append(X_test[i],float(df_test.loc[i]['sympt_count']*10000)))\n",
    "    bb=(np.append(bb,float(df_test.loc[i]['m_usr_score_hygiene']*10000)))\n",
    "    bb=(np.append(bb,float(df_test.loc[i]['m_usr_score_value']*10000)))\n",
    "    bb=(np.append(bb,float(df_test.loc[i]['score_hygiene_diff']*10000)))        \n",
    "    bb=(np.append(bb,float(df_test.loc[i]['score_value_diff']*10000)))\n",
    "    bb=normalize(bb)\n",
    "    X_test_new.append(bb)\n",
    "X_test_new=tuple(X_test_new)\n",
    "\n",
    "\n",
    "logreg(X_train_new,y_train,X_test_new,y_test)\n",
    "print(\"----\")\n",
    "logreg_weight(X_train_new,y_train,X_test_new,y_test)\n",
    "print(\"============end=============\")\n",
    "\n",
    "\n",
    "clf = svm.SVC(kernel='rbf')\n",
    "clf.fit(X_train,y_train)\n",
    "\n",
    "y_pred = clf.predict(X_test)\n",
    " \n",
    "print('Testing accuracy %s' % accuracy_score(y_test, y_pred))\n",
    "print('Testing F1 score: {}'.format(f1_score(y_test, y_pred, average='weighted')))\n",
    "print(f'Area Under Curve: {roc_auc_score(y_test, y_pred)}')\n",
    "print(f'Recall score: {recall_score(y_test,y_pred,average=None)}')\n",
    "\n",
    "#90%\n",
    "print(\"------ RF:________\")\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "RF=KNeighborsClassifier(n_neighbors=4,algorithm='brute',metric='cosine')\n",
    "\n",
    "RF.fit(X_train,y_train)\n",
    "\n",
    "y_pred = RF.predict(X_test)\n",
    " \n",
    "print('Testing accuracy %s' % accuracy_score(y_test, y_pred))\n",
    "print('Testing F1 score: {}'.format(f1_score(y_test, y_pred, average='weighted')))\n",
    "print(f'Area Under Curve: {roc_auc_score(y_test, y_pred)}')\n",
    "print(f'Recall score: {recall_score(y_test,y_pred,average=None)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1036,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1399/1399 [00:00<00:00, 1228093.62it/s]\n",
      "100%|██████████| 1399/1399 [00:00<00:00, 3056162.13it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing accuracy 0.856140350877193\n",
      "Testing F1 score: 0.8547534654015564\n",
      "Area Under Curve: 0.8154211221915175\n",
      "Recall score: [0.7195122  0.91133005]\n",
      "Testing accuracy 0.856140350877193\n",
      "Testing F1 score: 0.8600770363236001\n",
      "Area Under Curve: 0.8590352036525291\n",
      "Recall score: [0.86585366 0.85221675]\n"
     ]
    }
   ],
   "source": [
    "model_dbow_chi_6=train_dbow(train_tagged)\n",
    "model_dbow_chi_6.save('model_dbow_chi_6')\n",
    "y_train, X_train = vec_for_learning(model_dbow_chi_6, train_tagged)\n",
    "y_test, X_test = vec_for_learning(model_dbow_chi_6, test_tagged)\n",
    "logreg(X_train,y_train,X_test,y_test)\n",
    "logreg_weight(X_train,y_train,X_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1038,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1399/1399 [00:00<00:00, 1493847.07it/s]\n",
      "100%|██████████| 1399/1399 [00:00<00:00, 3076995.96it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing accuracy 0.8526315789473684\n",
      "Testing F1 score: 0.8531545672005375\n",
      "Area Under Curve: 0.8238615883695782\n",
      "Recall score: [0.75609756 0.89162562]\n",
      "Testing accuracy 0.8596491228070176\n",
      "Testing F1 score: 0.8636408547839525\n",
      "Area Under Curve: 0.8651327646281388\n",
      "Recall score: [0.87804878 0.85221675]\n"
     ]
    }
   ],
   "source": [
    "model_dbow_chi_7=train_dbow(train_tagged)\n",
    "model_dbow_chi_7.save('model_dbow_chi_7')\n",
    "y_train, X_train = vec_for_learning(model_dbow_chi_7, train_tagged)\n",
    "y_test, X_test = vec_for_learning(model_dbow_chi_7, test_tagged)\n",
    "logreg(X_train,y_train,X_test,y_test)\n",
    "logreg_weight(X_train,y_train,X_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1040,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1399/1399 [00:00<00:00, 914990.07it/s]\n",
      "100%|██████████| 1399/1399 [00:00<00:00, 2933915.65it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing accuracy 0.8315789473684211\n",
      "Testing F1 score: 0.8321766482291856\n",
      "Area Under Curve: 0.7981797428811727\n",
      "Recall score: [0.7195122  0.87684729]\n",
      "Testing accuracy 0.8491228070175438\n",
      "Testing F1 score: 0.8532515259003611\n",
      "Area Under Curve: 0.8504745884897271\n",
      "Recall score: [0.85365854 0.84729064]\n"
     ]
    }
   ],
   "source": [
    "model_dbow_chi_8=train_dbow(train_tagged)\n",
    "model_dbow_chi_8.save('model_dbow_chi_8')\n",
    "y_train, X_train = vec_for_learning(model_dbow_chi_8, train_tagged)\n",
    "y_test, X_test = vec_for_learning(model_dbow_chi_8, test_tagged)\n",
    "logreg(X_train,y_train,X_test,y_test)\n",
    "logreg_weight(X_train,y_train,X_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1027,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1399/1399 [00:00<00:00, 936754.68it/s]\n",
      "100%|██████████| 1399/1399 [00:00<00:00, 3091586.56it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing accuracy 0.8140350877192982\n",
      "Testing F1 score: 0.8114653469472017\n",
      "Area Under Curve: 0.7604229244262886\n",
      "Recall score: [0.63414634 0.88669951]\n",
      "Testing accuracy 0.8210526315789474\n",
      "Testing F1 score: 0.8246644558089492\n",
      "Area Under Curve: 0.8053286074732668\n",
      "Recall score: [0.76829268 0.84236453]\n"
     ]
    }
   ],
   "source": [
    "model_dbow_chi_50=train_dbow(train_tagged)\n",
    "model_dbow_chi_50.save('model_dbow_chi_50')\n",
    "y_train, X_train = vec_for_learning(model_dbow_chi_50, train_tagged)\n",
    "y_test, X_test = vec_for_learning(model_dbow_chi_50, test_tagged)\n",
    "logreg(X_train,y_train,X_test,y_test)\n",
    "logreg_weight(X_train,y_train,X_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1097,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing accuracy 0.8807017543859649\n",
      "Testing F1 score: 0.8793052743694064\n",
      "Area Under Curve: 0.8435660218671152\n",
      "Recall score: [0.75609756 0.93103448]\n",
      "----\n",
      "Testing accuracy 0.9192982456140351\n",
      "Testing F1 score: 0.9209271075216832\n",
      "Area Under Curve: 0.925177219752493\n",
      "Recall score: [0.93902439 0.91133005]\n",
      "============end=============\n"
     ]
    }
   ],
   "source": [
    "##test vector size=7\n",
    "X_train_new=[]\n",
    "X_test_new=[]\n",
    "\n",
    "\n",
    "#y_train, X_train = get_vectors(model_dbow_dmm_chi_5, train_tagged)\n",
    "#y_test, X_test = get_vectors(model_dbow_dmm_chi_5, test_tagged)\n",
    "\n",
    "y_train, X_train = vec_for_learning(model_dbow_chi_7, train_tagged)\n",
    "y_test, X_test = vec_for_learning(model_dbow_chi_7,test_tagged)\n",
    "\n",
    "for i in range(len(X_train)):\n",
    "    aa=(np.append(X_train[i],float(df.loc[i]['sympt_count']*10000)))\n",
    "    aa=(np.append(aa,float(df.loc[i]['m_usr_score_hygiene']*10000)))\n",
    "    aa=(np.append(aa,float(df.loc[i]['m_usr_score_value']*10000)))\n",
    "    aa=(np.append(aa,float(df.loc[i]['score_hygiene_diff']*10000)))        \n",
    "    aa=(np.append(aa,float(df.loc[i]['score_value_diff']*10000)))\n",
    "    X_train_new.append(aa)\n",
    "X_train_new=tuple(X_train_new)\n",
    "\n",
    "for i in range(len(X_test)):\n",
    "    bb=(np.append(X_test[i],float(df_test.loc[i]['sympt_count']*10000)))\n",
    "    bb=(np.append(bb,float(df_test.loc[i]['m_usr_score_hygiene']*10000)))\n",
    "    bb=(np.append(bb,float(df_test.loc[i]['m_usr_score_value']*10000)))\n",
    "    bb=(np.append(bb,float(df_test.loc[i]['score_hygiene_diff']*10000)))        \n",
    "    bb=(np.append(bb,float(df_test.loc[i]['score_value_diff']*10000)))\n",
    "    X_test_new.append(bb)\n",
    "X_test_new=tuple(X_test_new)\n",
    "\n",
    "\n",
    "logreg(X_train_new,y_train,X_test_new,y_test)\n",
    "print(\"----\")\n",
    "logreg_weight(X_train_new,y_train,X_test_new,y_test)\n",
    "print(\"============end=============\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1144,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing accuracy 0.8807017543859649\n",
      "Testing F1 score: 0.8826235739121402\n",
      "Area Under Curve: 0.8726420761744562\n",
      "Recall score: [0.85365854 0.89162562]\n",
      "----\n",
      "Testing accuracy 0.8736842105263158\n",
      "Testing F1 score: 0.8780055401662049\n",
      "Area Under Curve: 0.8931575153189955\n",
      "Recall score: [0.93902439 0.84729064]\n",
      "============end=============\n"
     ]
    }
   ],
   "source": [
    "##test vector size=7\n",
    "X_train_new=[]\n",
    "X_test_new=[]\n",
    "\n",
    "\n",
    "#y_train, X_train = get_vectors(model_dbow_dmm_chi_5, train_tagged)\n",
    "#y_test, X_test = get_vectors(model_dbow_dmm_chi_5, test_tagged)\n",
    "\n",
    "y_train, X_train = vec_for_learning(model_dbow_chi_7, train_tagged)\n",
    "y_test, X_test = vec_for_learning(model_dbow_chi_7,test_tagged)\n",
    "\n",
    "for i in range(len(X_train)):\n",
    "    aa=(np.append(X_train[i],float(df.loc[i]['sympt_count'])))\n",
    "    aa=(np.append(aa,float(df.loc[i]['m_usr_score_hygiene'])))\n",
    "    aa=(np.append(aa,float(df.loc[i]['m_usr_score_value'])))\n",
    "    aa=(np.append(aa,float(df.loc[i]['score_hygiene_diff'])))        \n",
    "    aa=(np.append(aa,float(df.loc[i]['score_value_diff'])))\n",
    "    X_train_new.append(aa)\n",
    "X_train_new=tuple(X_train_new)\n",
    "\n",
    "for i in range(len(X_test)):\n",
    "    bb=(np.append(X_test[i],float(df_test.loc[i]['sympt_count'])))\n",
    "    bb=(np.append(bb,float(df_test.loc[i]['m_usr_score_hygiene'])))\n",
    "    bb=(np.append(bb,float(df_test.loc[i]['m_usr_score_value'])))\n",
    "    bb=(np.append(bb,float(df_test.loc[i]['score_hygiene_diff'])))        \n",
    "    bb=(np.append(bb,float(df_test.loc[i]['score_value_diff'])))\n",
    "    X_test_new.append(bb)\n",
    "X_test_new=tuple(X_test_new)\n",
    "\n",
    "\n",
    "logreg(X_train_new,y_train,X_test_new,y_test)\n",
    "print(\"----\")\n",
    "logreg_weight(X_train_new,y_train,X_test_new,y_test)\n",
    "print(\"============end=============\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1141,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing accuracy 0.8842105263157894\n",
      "Testing F1 score: 0.8839975913918439\n",
      "Area Under Curve: 0.8569325964195603\n",
      "Recall score: [0.79268293 0.92118227]\n",
      "----\n",
      "Testing accuracy 0.9228070175438596\n",
      "Testing F1 score: 0.9242630688396117\n",
      "Area Under Curve: 0.9276402739396852\n",
      "Recall score: [0.93902439 0.91625616]\n",
      "============end=============\n",
      "Testing accuracy 0.8526315789473684\n",
      "Testing F1 score: 0.850906515397502\n",
      "Area Under Curve: 0.8093235612159075\n",
      "Recall score: [0.70731707 0.91133005]\n",
      "------ RF:________\n",
      "Testing accuracy 0.8140350877192982\n",
      "Testing F1 score: 0.8198876297430162\n",
      "Area Under Curve: 0.8149405262525532\n",
      "Recall score: [0.81707317 0.81280788]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "X_train_new=[]\n",
    "X_test_new=[]\n",
    "\n",
    "\n",
    "#y_train, X_train = get_vectors(model_dbow_dmm_chi_5, train_tagged)\n",
    "#y_test, X_test = get_vectors(model_dbow_dmm_chi_5, test_tagged)\n",
    "\n",
    "y_train, X_train = vec_for_learning(model_dbow_chi_5, train_tagged)\n",
    "y_test, X_test = vec_for_learning(model_dbow_chi_5,test_tagged)\n",
    "\n",
    "for i in range(len(X_train)):\n",
    "    aa=(np.append(X_train[i],float(df.loc[i]['sympt_count']*10000)))\n",
    "    aa=(np.append(aa,float(df.loc[i]['m_usr_score_hygiene']*10000)))\n",
    "    aa=(np.append(aa,float(df.loc[i]['m_usr_score_value']*10000)))\n",
    "    aa=(np.append(aa,float(df.loc[i]['score_hygiene_diff']*10000)))        \n",
    "    aa=(np.append(aa,float(df.loc[i]['score_value_diff']*10000)))\n",
    "    aa=normalize(aa)\n",
    "    X_train_new.append(aa)\n",
    "X_train_new=tuple(X_train_new)\n",
    "\n",
    "for i in range(len(X_test)):\n",
    "    bb=(np.append(X_test[i],float(df_test.loc[i]['sympt_count']*10000)))\n",
    "    bb=(np.append(bb,float(df_test.loc[i]['m_usr_score_hygiene']*10000)))\n",
    "    bb=(np.append(bb,float(df_test.loc[i]['m_usr_score_value']*10000)))\n",
    "    bb=(np.append(bb,float(df_test.loc[i]['score_hygiene_diff']*10000)))        \n",
    "    bb=(np.append(bb,float(df_test.loc[i]['score_value_diff']*10000)))\n",
    "    bb=normalize(bb)\n",
    "    X_test_new.append(bb)\n",
    "X_test_new=tuple(X_test_new)\n",
    "\n",
    "\n",
    "logreg(X_train_new,y_train,X_test_new,y_test)\n",
    "print(\"----\")\n",
    "logreg_weight(X_train_new,y_train,X_test_new,y_test)\n",
    "print(\"============end=============\")\n",
    "\n",
    "\n",
    "clf = svm.SVC(kernel='rbf')\n",
    "clf.fit(X_train,y_train)\n",
    "\n",
    "y_pred = clf.predict(X_test)\n",
    " \n",
    "print('Testing accuracy %s' % accuracy_score(y_test, y_pred))\n",
    "print('Testing F1 score: {}'.format(f1_score(y_test, y_pred, average='weighted')))\n",
    "print(f'Area Under Curve: {roc_auc_score(y_test, y_pred)}')\n",
    "print(f'Recall score: {recall_score(y_test,y_pred,average=None)}')\n",
    "\n",
    "#90%\n",
    "print(\"------ RF:________\")\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "RF=KNeighborsClassifier(n_neighbors=4,algorithm='brute',metric='cosine')\n",
    "\n",
    "RF.fit(X_train,y_train)\n",
    "\n",
    "y_pred = RF.predict(X_test)\n",
    " \n",
    "print('Testing accuracy %s' % accuracy_score(y_test, y_pred))\n",
    "print('Testing F1 score: {}'.format(f1_score(y_test, y_pred, average='weighted')))\n",
    "print(f'Area Under Curve: {roc_auc_score(y_test, y_pred)}')\n",
    "print(f'Recall score: {recall_score(y_test,y_pred,average=None)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1302,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing accuracy 0.8842105263157894\n",
      "Testing F1 score: 0.8839975913918439\n",
      "Area Under Curve: 0.8569325964195603\n",
      "Recall score: [0.79268293 0.92118227]\n",
      "----\n",
      "Testing accuracy 0.9122807017543859\n",
      "Testing F1 score: 0.9142734961107922\n",
      "Area Under Curve: 0.9202511113781088\n",
      "Recall score: [0.93902439 0.90147783]\n",
      "============end=============\n",
      "Testing accuracy 0.8596491228070176\n",
      "Testing F1 score: 0.8596491228070176\n",
      "Area Under Curve: 0.8287876967439626\n",
      "Recall score: [0.75609756 0.90147783]\n",
      "------ RF:________\n",
      "Testing accuracy 0.8210526315789474\n",
      "Testing F1 score: 0.8270167983388041\n",
      "Area Under Curve: 0.8271356482037726\n",
      "Recall score: [0.84146341 0.81280788]\n"
     ]
    }
   ],
   "source": [
    "##for weiwei check \n",
    "X_train_new=[]\n",
    "X_test_new=[]\n",
    "\n",
    "\n",
    "#y_train, X_train = get_vectors(model_dbow_dmm_chi_5, train_tagged)\n",
    "#y_test, X_test = get_vectors(model_dbow_dmm_chi_5, test_tagged)\n",
    "\n",
    "y_train, X_train = vec_for_learning(model_dbow_chi_5_a, train_tagged)\n",
    "y_test, X_test = vec_for_learning(model_dbow_chi_5_a,test_tagged)\n",
    "\n",
    "for i in range(len(X_train)):\n",
    "    aa=(np.append(X_train[i],float(df.loc[i]['sympt_count'])))\n",
    "    aa=(np.append(aa,float(df.loc[i]['m_usr_score_hygiene']*10000)))\n",
    "    aa=(np.append(aa,float(df.loc[i]['m_usr_score_value']*10000)))\n",
    "    aa=(np.append(aa,float(df.loc[i]['score_hygiene_diff']*10000)))        \n",
    "    aa=(np.append(aa,float(df.loc[i]['score_value_diff']*10000)))\n",
    "    aa=normalize(aa)\n",
    "    X_train_new.append(aa)\n",
    "X_train_new=tuple(X_train_new)\n",
    "\n",
    "for i in range(len(X_test)):\n",
    "    bb=(np.append(X_test[i],float(df_test.loc[i]['sympt_count']*10000)))\n",
    "    bb=(np.append(bb,float(df_test.loc[i]['m_usr_score_hygiene']*10000)))\n",
    "    bb=(np.append(bb,float(df_test.loc[i]['m_usr_score_value']*10000)))\n",
    "    bb=(np.append(bb,float(df_test.loc[i]['score_hygiene_diff']*10000)))        \n",
    "    bb=(np.append(bb,float(df_test.loc[i]['score_value_diff']*10000)))\n",
    "    bb=normalize(bb)\n",
    "    X_test_new.append(bb)\n",
    "X_test_new=tuple(X_test_new)\n",
    "\n",
    "\n",
    "logreg(X_train_new,y_train,X_test_new,y_test)\n",
    "print(\"----\")\n",
    "logreg_weight(X_train_new,y_train,X_test_new,y_test)\n",
    "print(\"============end=============\")\n",
    "\n",
    "\n",
    "clf = svm.SVC(kernel='rbf')\n",
    "clf.fit(X_train,y_train)\n",
    "\n",
    "y_pred = clf.predict(X_test)\n",
    " \n",
    "print('Testing accuracy %s' % accuracy_score(y_test, y_pred))\n",
    "print('Testing F1 score: {}'.format(f1_score(y_test, y_pred, average='weighted')))\n",
    "print(f'Area Under Curve: {roc_auc_score(y_test, y_pred)}')\n",
    "print(f'Recall score: {recall_score(y_test,y_pred,average=None)}')\n",
    "\n",
    "#90%\n",
    "print(\"------ RF:________\")\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "RF=KNeighborsClassifier(n_neighbors=4,algorithm='brute',metric='cosine')\n",
    "\n",
    "RF.fit(X_train,y_train)\n",
    "\n",
    "y_pred = RF.predict(X_test)\n",
    " \n",
    "print('Testing accuracy %s' % accuracy_score(y_test, y_pred))\n",
    "print('Testing F1 score: {}'.format(f1_score(y_test, y_pred, average='weighted')))\n",
    "print(f'Area Under Curve: {roc_auc_score(y_test, y_pred)}')\n",
    "print(f'Recall score: {recall_score(y_test,y_pred,average=None)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1142,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing accuracy 0.887719298245614\n",
      "Testing F1 score: 0.8884973628100101\n",
      "Area Under Curve: 0.8702991709720052\n",
      "Recall score: [0.82926829 0.91133005]\n",
      "----\n",
      "Testing accuracy 0.9052631578947369\n",
      "Testing F1 score: 0.9080563817405921\n",
      "Area Under Curve: 0.92259401658056\n",
      "Recall score: [0.96341463 0.8817734 ]\n",
      "============end=============\n",
      "Testing accuracy 0.856140350877193\n",
      "Testing F1 score: 0.8553276462123738\n",
      "Area Under Curve: 0.8190556289799351\n",
      "Recall score: [0.73170732 0.90640394]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "X_train_new=[]\n",
    "X_test_new=[]\n",
    "\n",
    "\n",
    "#y_train, X_train = get_vectors(model_dbow_dmm_chi_5, train_tagged)\n",
    "#y_test, X_test = get_vectors(model_dbow_dmm_chi_5, test_tagged)\n",
    "\n",
    "y_train, X_train = vec_for_learning(model_dbow_chi_5, train_tagged)\n",
    "y_test, X_test = vec_for_learning(model_dbow_chi_5,test_tagged)\n",
    "\n",
    "for i in range(len(X_train)):\n",
    "    aa=(np.append(X_train[i],float(df.loc[i]['sympt_count'])))\n",
    "    aa=(np.append(aa,float(df.loc[i]['m_usr_score_hygiene'])))\n",
    "    aa=(np.append(aa,float(df.loc[i]['m_usr_score_value'])))\n",
    "    aa=(np.append(aa,float(df.loc[i]['score_hygiene_diff'])))        \n",
    "    aa=(np.append(aa,float(df.loc[i]['score_value_diff'])))\n",
    "    X_train_new.append(aa)\n",
    "X_train_new=tuple(X_train_new)\n",
    "\n",
    "for i in range(len(X_test)):\n",
    "    bb=(np.append(X_test[i],float(df_test.loc[i]['sympt_count'])))\n",
    "    bb=(np.append(bb,float(df_test.loc[i]['m_usr_score_hygiene'])))\n",
    "    bb=(np.append(bb,float(df_test.loc[i]['m_usr_score_value'])))\n",
    "    bb=(np.append(bb,float(df_test.loc[i]['score_hygiene_diff'])))        \n",
    "    bb=(np.append(bb,float(df_test.loc[i]['score_value_diff'])))\n",
    "    X_test_new.append(bb)\n",
    "X_test_new=tuple(X_test_new)\n",
    "\n",
    "\n",
    "logreg(X_train_new,y_train,X_test_new,y_test)\n",
    "print(\"----\")\n",
    "logreg_weight(X_train_new,y_train,X_test_new,y_test)\n",
    "print(\"============end=============\")\n",
    "\n",
    "\n",
    "clf = svm.SVC(kernel='rbf')\n",
    "clf.fit(X_train,y_train)\n",
    "\n",
    "y_pred = clf.predict(X_test)\n",
    " \n",
    "print('Testing accuracy %s' % accuracy_score(y_test, y_pred))\n",
    "print('Testing F1 score: {}'.format(f1_score(y_test, y_pred, average='weighted')))\n",
    "print(f'Area Under Curve: {roc_auc_score(y_test, y_pred)}')\n",
    "print(f'Recall score: {recall_score(y_test,y_pred,average=None)}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1145,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing accuracy 0.8666666666666667\n",
      "Testing F1 score: 0.8639402264402265\n",
      "Area Under Curve: 0.8191757779646761\n",
      "Recall score: [0.70731707 0.93103448]\n",
      "----\n",
      "Testing accuracy 0.9052631578947369\n",
      "Testing F1 score: 0.9074153757996557\n",
      "Area Under Curve: 0.9116904962153071\n",
      "Recall score: [0.92682927 0.89655172]\n",
      "============end=============\n",
      "Testing accuracy 0.8526315789473684\n",
      "Testing F1 score: 0.850906515397502\n",
      "Area Under Curve: 0.8093235612159075\n",
      "Recall score: [0.70731707 0.91133005]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "X_train_new=[]\n",
    "X_test_new=[]\n",
    "\n",
    "\n",
    "#y_train, X_train = get_vectors(model_dbow_dmm_chi_5, train_tagged)\n",
    "#y_test, X_test = get_vectors(model_dbow_dmm_chi_5, test_tagged)\n",
    "\n",
    "y_train, X_train = vec_for_learning(model_dbow_chi_5, train_tagged)\n",
    "y_test, X_test = vec_for_learning(model_dbow_chi_5,test_tagged)\n",
    "\n",
    "for i in range(len(X_train)):\n",
    "    aa=(np.append(X_train[i],float(df.loc[i]['sympt_count'])))\n",
    "    aa=(np.append(aa,float(df.loc[i]['m_usr_score_hygiene'])))\n",
    "    aa=(np.append(aa,float(df.loc[i]['m_usr_score_value'])))\n",
    "    aa=(np.append(aa,float(df.loc[i]['score_hygiene_diff'])))        \n",
    "    aa=(np.append(aa,float(df.loc[i]['score_value_diff'])))\n",
    "    aa=normalize(aa)\n",
    "    X_train_new.append(aa)\n",
    "X_train_new=tuple(X_train_new)\n",
    "\n",
    "for i in range(len(X_test)):\n",
    "    bb=(np.append(X_test[i],float(df_test.loc[i]['sympt_count'])))\n",
    "    bb=(np.append(bb,float(df_test.loc[i]['m_usr_score_hygiene'])))\n",
    "    bb=(np.append(bb,float(df_test.loc[i]['m_usr_score_value'])))\n",
    "    bb=(np.append(bb,float(df_test.loc[i]['score_hygiene_diff'])))        \n",
    "    bb=(np.append(bb,float(df_test.loc[i]['score_value_diff'])))\n",
    "    bb=normalize(bb)\n",
    "    X_test_new.append(bb)\n",
    "X_test_new=tuple(X_test_new)\n",
    "\n",
    "\n",
    "logreg(X_train_new,y_train,X_test_new,y_test)\n",
    "print(\"----\")\n",
    "logreg_weight(X_train_new,y_train,X_test_new,y_test)\n",
    "print(\"============end=============\")\n",
    "\n",
    "\n",
    "clf = svm.SVC(kernel='rbf')\n",
    "clf.fit(X_train,y_train)\n",
    "\n",
    "y_pred = clf.predict(X_test)\n",
    " \n",
    "print('Testing accuracy %s' % accuracy_score(y_test, y_pred))\n",
    "print('Testing F1 score: {}'.format(f1_score(y_test, y_pred, average='weighted')))\n",
    "print(f'Area Under Curve: {roc_auc_score(y_test, y_pred)}')\n",
    "print(f'Recall score: {recall_score(y_test,y_pred,average=None)}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1146,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing accuracy 0.8842105263157894\n",
      "Testing F1 score: 0.883556398170935\n",
      "Area Under Curve: 0.8532980896311426\n",
      "Recall score: [0.7804878  0.92610837]\n",
      "----\n",
      "Testing accuracy 0.9157894736842105\n",
      "Testing F1 score: 0.9173778932795764\n",
      "Area Under Curve: 0.9190796587768834\n",
      "Recall score: [0.92682927 0.91133005]\n",
      "============end=============\n",
      "Testing accuracy 0.8526315789473684\n",
      "Testing F1 score: 0.850906515397502\n",
      "Area Under Curve: 0.8093235612159075\n",
      "Recall score: [0.70731707 0.91133005]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "X_train_new=[]\n",
    "X_test_new=[]\n",
    "\n",
    "\n",
    "#y_train, X_train = get_vectors(model_dbow_dmm_chi_5, train_tagged)\n",
    "#y_test, X_test = get_vectors(model_dbow_dmm_chi_5, test_tagged)\n",
    "\n",
    "y_train, X_train = vec_for_learning(model_dbow_chi_5, train_tagged)\n",
    "y_test, X_test = vec_for_learning(model_dbow_chi_5,test_tagged)\n",
    "\n",
    "for i in range(len(X_train)):\n",
    "    aa=(np.append(X_train[i],float(df.loc[i]['sympt_count']*10000)))\n",
    "    aa=(np.append(aa,float(df.loc[i]['m_usr_score_hygiene']*10000)))\n",
    "    aa=(np.append(aa,float(df.loc[i]['m_usr_score_value']*10000)))\n",
    "    aa=(np.append(aa,float(df.loc[i]['score_hygiene_diff']*10000)))        \n",
    "    aa=(np.append(aa,float(df.loc[i]['score_value_diff']*10000)))\n",
    "    X_train_new.append(aa)\n",
    "X_train_new=tuple(X_train_new)\n",
    "\n",
    "for i in range(len(X_test)):\n",
    "    bb=(np.append(X_test[i],float(df_test.loc[i]['sympt_count']*10000)))\n",
    "    bb=(np.append(bb,float(df_test.loc[i]['m_usr_score_hygiene']*10000)))\n",
    "    bb=(np.append(bb,float(df_test.loc[i]['m_usr_score_value']*10000)))\n",
    "    bb=(np.append(bb,float(df_test.loc[i]['score_hygiene_diff']*10000)))        \n",
    "    bb=(np.append(bb,float(df_test.loc[i]['score_value_diff']*10000)))\n",
    "    X_test_new.append(bb)\n",
    "X_test_new=tuple(X_test_new)\n",
    "\n",
    "\n",
    "logreg(X_train_new,y_train,X_test_new,y_test)\n",
    "print(\"----\")\n",
    "logreg_weight(X_train_new,y_train,X_test_new,y_test)\n",
    "print(\"============end=============\")\n",
    "\n",
    "\n",
    "clf = svm.SVC(kernel='rbf')\n",
    "clf.fit(X_train,y_train)\n",
    "\n",
    "y_pred = clf.predict(X_test)\n",
    " \n",
    "print('Testing accuracy %s' % accuracy_score(y_test, y_pred))\n",
    "print('Testing F1 score: {}'.format(f1_score(y_test, y_pred, average='weighted')))\n",
    "print(f'Area Under Curve: {roc_auc_score(y_test, y_pred)}')\n",
    "print(f'Recall score: {recall_score(y_test,y_pred,average=None)}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1128,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing accuracy 0.8280701754385965\n",
      "Testing F1 score: 0.8295416343393567\n",
      "Area Under Curve: 0.7993511954823982\n",
      "Recall score: [0.73170732 0.86699507]\n",
      "----\n",
      "Testing accuracy 0.8210526315789474\n",
      "Testing F1 score: 0.8259494842074051\n",
      "Area Under Curve: 0.8162321278385198\n",
      "Recall score: [0.80487805 0.82758621]\n",
      "============end=============\n"
     ]
    }
   ],
   "source": [
    "\n",
    "X_train_new=[]\n",
    "X_test_new=[]\n",
    "\n",
    "y_train, X_train = vec_for_learning(model_dbow_chi_50, train_tagged)\n",
    "y_test, X_test = vec_for_learning(model_dbow_chi_50,test_tagged)\n",
    "\n",
    "for i in range(len(X_train)):\n",
    "    aa=(np.append(X_train[i],float(df.loc[i]['sympt_count'])))\n",
    "    aa=(np.append(aa,float(df.loc[i]['m_usr_score_hygiene'])))\n",
    "    aa=(np.append(aa,float(df.loc[i]['m_usr_score_value'])))\n",
    "    aa=(np.append(aa,float(df.loc[i]['score_hygiene_diff'])))        \n",
    "    aa=(np.append(aa,float(df.loc[i]['score_value_diff'])))\n",
    "    X_train_new.append(aa)\n",
    "X_train_new=tuple(X_train_new)\n",
    "\n",
    "for i in range(len(X_test)):\n",
    "    bb=(np.append(X_test[i],float(df_test.loc[i]['sympt_count'])))\n",
    "    bb=(np.append(bb,float(df_test.loc[i]['m_usr_score_hygiene'])))\n",
    "    bb=(np.append(bb,float(df_test.loc[i]['m_usr_score_value'])))\n",
    "    bb=(np.append(bb,float(df_test.loc[i]['score_hygiene_diff'])))        \n",
    "    bb=(np.append(bb,float(df_test.loc[i]['score_value_diff'])))\n",
    "    X_test_new.append(bb)\n",
    "X_test_new=tuple(X_test_new)\n",
    "\n",
    "\n",
    "logreg(X_train_new,y_train,X_test_new,y_test)\n",
    "print(\"----\")\n",
    "logreg_weight(X_train_new,y_train,X_test_new,y_test)\n",
    "print(\"============end=============\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 944,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing accuracy 0.8701754385964913\n",
      "Testing F1 score: 0.869936693378734\n",
      "Area Under Curve: 0.8398113660939565\n",
      "Recall score: [0.76829268 0.91133005]\n"
     ]
    }
   ],
   "source": [
    "#try to use SVM model\n",
    "#test_data_label = pd.to_numeric(all_real_fake_symptom_test['label']).tolist()\n",
    "y_train, X_train = vec_for_learning(model_dbow_chi_5, train_tagged)\n",
    "y_test, X_test = vec_for_learning(model_dbow_chi_5, test_tagged)\n",
    "\n",
    "\n",
    "clf = svm.SVC(kernel='rbf')\n",
    "clf.fit(X_train,y_train)\n",
    "\n",
    "y_pred = clf.predict(X_test)\n",
    " \n",
    "print('Testing accuracy %s' % accuracy_score(y_test, y_pred))\n",
    "print('Testing F1 score: {}'.format(f1_score(y_test, y_pred, average='weighted')))\n",
    "print(f'Area Under Curve: {roc_auc_score(y_test, y_pred)}')\n",
    "print(f'Recall score: {recall_score(y_test,y_pred,average=None)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 945,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing accuracy 0.8385964912280702\n",
      "Testing F1 score: 0.8329317593972121\n",
      "Area Under Curve: 0.7740297969482158\n",
      "Recall score: [0.62195122 0.92610837]\n"
     ]
    }
   ],
   "source": [
    "#try to use SVM model\n",
    "#test_data_label = pd.to_numeric(all_real_fake_symptom_test['label']).tolist()\n",
    "y_train, X_train = vec_for_learning(model_dbow_chi_5, train_tagged)\n",
    "y_test, X_test = vec_for_learning(model_dbow_chi_5, test_tagged)\n",
    "\n",
    "\n",
    "clf = svm.SVC(kernel='linear')\n",
    "clf.fit(X_train,y_train)\n",
    "\n",
    "y_pred = clf.predict(X_test)\n",
    " \n",
    "print('Testing accuracy %s' % accuracy_score(y_test, y_pred))\n",
    "print('Testing F1 score: {}'.format(f1_score(y_test, y_pred, average='weighted')))\n",
    "print(f'Area Under Curve: {roc_auc_score(y_test, y_pred)}')\n",
    "print(f'Recall score: {recall_score(y_test,y_pred,average=None)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 950,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing accuracy 0.8666666666666667\n",
      "Testing F1 score: 0.866170418784798\n",
      "Area Under Curve: 0.8337138051183467\n",
      "Recall score: [0.75609756 0.91133005]\n"
     ]
    }
   ],
   "source": [
    "#try to use SVM model\n",
    "#test_data_label = pd.to_numeric(all_real_fake_symptom_test['label']).tolist()\n",
    "y_train, X_train = vec_for_learning(model_dbow_chi_5, train_tagged)\n",
    "y_test, X_test = vec_for_learning(model_dbow_chi_5, test_tagged)\n",
    "\n",
    "\n",
    "clf = svm.SVC(kernel='rbf')\n",
    "clf.fit(X_train,y_train)\n",
    "\n",
    "y_pred = clf.predict(X_test)\n",
    " \n",
    "print('Testing accuracy %s' % accuracy_score(y_test, y_pred))\n",
    "print('Testing F1 score: {}'.format(f1_score(y_test, y_pred, average='weighted')))\n",
    "print(f'Area Under Curve: {roc_auc_score(y_test, y_pred)}')\n",
    "print(f'Recall score: {recall_score(y_test,y_pred,average=None)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1082,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize(x):\n",
    "    \"\"\"\n",
    "        argument\n",
    "            - x: input image data in numpy array [32, 32, 3]\n",
    "        return\n",
    "            - normalized x \n",
    "    \"\"\"\n",
    "    mean_val=np.mean(x)\n",
    "    \"\"\"\n",
    "    min_val = np.min(x)\n",
    "    max_val = np.max(x)\n",
    "    x = (x-min_val) / (max_val-min_val)\n",
    "    \"\"\"\n",
    "    x=x-mean_val\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 985,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing accuracy 0.8912280701754386\n",
      "Testing F1 score: 0.8906135861605752\n",
      "Area Under Curve: 0.8618587047939444\n",
      "Recall score: [0.79268293 0.93103448]\n",
      "----\n",
      "Testing accuracy 0.9157894736842105\n",
      "Testing F1 score: 0.9178047683310842\n",
      "Area Under Curve: 0.9263486723537186\n",
      "Recall score: [0.95121951 0.90147783]\n",
      "============end=============\n"
     ]
    }
   ],
   "source": [
    "\n",
    "X_train_new=[]\n",
    "X_test_new=[]\n",
    "\n",
    "y_train, X_train = vec_for_learning(model_dbow_chi_5, train_tagged)\n",
    "y_test, X_test = vec_for_learning(model_dbow_chi_5,test_tagged)\n",
    "\n",
    "for i in range(len(X_train)):\n",
    "    aa=(np.append(X_train[i],float(df.loc[i]['sympt_count']*10000)))\n",
    "    aa=(np.append(aa,float(df.loc[i]['m_usr_score_hygiene']*10000)))\n",
    "    aa=(np.append(aa,float(df.loc[i]['m_usr_score_value']*10000)))\n",
    "    aa=(np.append(aa,float(df.loc[i]['score_hygiene_diff']*10000)))        \n",
    "    aa=(np.append(aa,float(df.loc[i]['score_value_diff']*10000)))\n",
    "    X_train_new.append(aa)\n",
    "X_train_new=tuple(X_train_new)\n",
    "\n",
    "for i in range(len(X_test)):\n",
    "    bb=(np.append(X_test[i],float(df_test.loc[i]['sympt_count']*10000)))\n",
    "    bb=(np.append(bb,float(df_test.loc[i]['m_usr_score_hygiene']*10000)))\n",
    "    bb=(np.append(bb,float(df_test.loc[i]['m_usr_score_value']*10000)))\n",
    "    bb=(np.append(bb,float(df_test.loc[i]['score_hygiene_diff']*10000)))        \n",
    "    bb=(np.append(bb,float(df_test.loc[i]['score_value_diff']*10000)))\n",
    "    X_test_new.append(bb)\n",
    "X_test_new=tuple(X_test_new)\n",
    "\n",
    "\n",
    "logreg(X_train_new,y_train,X_test_new,y_test)\n",
    "print(\"----\")\n",
    "logreg_weight(X_train_new,y_train,X_test_new,y_test)\n",
    "print(\"============end=============\")\n",
    "\n",
    "# vector size=5 and weight =10000 has the best performance now\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1061,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing accuracy 0.8912280701754386\n",
      "Testing F1 score: 0.8906135861605752\n",
      "Area Under Curve: 0.8618587047939444\n",
      "Recall score: [0.79268293 0.93103448]\n",
      "----\n",
      "Testing accuracy 0.9087719298245615\n",
      "Testing F1 score: 0.9107304778800934\n",
      "Area Under Curve: 0.9141535504024992\n",
      "Recall score: [0.92682927 0.90147783]\n",
      "============end=============\n"
     ]
    }
   ],
   "source": [
    "\n",
    "X_train_new=[]\n",
    "X_test_new=[]\n",
    "\n",
    "y_train, X_train = vec_for_learning(model_dbow_chi_5, train_tagged)\n",
    "y_test, X_test = vec_for_learning(model_dbow_chi_5,test_tagged)\n",
    "\n",
    "for i in range(len(X_train)):\n",
    "    aa=(np.append(X_train[i],float(df.loc[i]['sympt_count']*10010)))\n",
    "    aa=(np.append(aa,float(df.loc[i]['m_usr_score_hygiene']*10010)))\n",
    "    aa=(np.append(aa,float(df.loc[i]['m_usr_score_value']*10010)))\n",
    "    aa=(np.append(aa,float(df.loc[i]['score_hygiene_diff']*10010)))        \n",
    "    aa=(np.append(aa,float(df.loc[i]['score_value_diff']*10010)))\n",
    "    X_train_new.append(aa)\n",
    "X_train_new=tuple(X_train_new)\n",
    "\n",
    "for i in range(len(X_test)):\n",
    "    bb=(np.append(X_test[i],float(df_test.loc[i]['sympt_count']*10010)))\n",
    "    bb=(np.append(bb,float(df_test.loc[i]['m_usr_score_hygiene']*10010)))\n",
    "    bb=(np.append(bb,float(df_test.loc[i]['m_usr_score_value']*10010)))\n",
    "    bb=(np.append(bb,float(df_test.loc[i]['score_hygiene_diff']*10010)))        \n",
    "    bb=(np.append(bb,float(df_test.loc[i]['score_value_diff']*10010)))\n",
    "    X_test_new.append(bb)\n",
    "X_test_new=tuple(X_test_new)\n",
    "\n",
    "\n",
    "logreg(X_train_new,y_train,X_test_new,y_test)\n",
    "print(\"----\")\n",
    "logreg_weight(X_train_new,y_train,X_test_new,y_test)\n",
    "print(\"============end=============\")\n",
    "\n",
    "# vector size=5 and weight =10000 has the best performance now\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1066,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing accuracy 0.8912280701754386\n",
      "Testing F1 score: 0.8906135861605752\n",
      "Area Under Curve: 0.8618587047939444\n",
      "Recall score: [0.79268293 0.93103448]\n",
      "----\n",
      "Testing accuracy 0.9157894736842105\n",
      "Testing F1 score: 0.9175973641970093\n",
      "Area Under Curve: 0.922714165565301\n",
      "Recall score: [0.93902439 0.90640394]\n",
      "============end=============\n",
      "Testing accuracy 0.8982456140350877\n",
      "Testing F1 score: 0.8997390171750046\n",
      "Area Under Curve: 0.8922263606872521\n",
      "Recall score: [0.87804878 0.90640394]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "X_train_new=[]\n",
    "X_test_new=[]\n",
    "\n",
    "y_train, X_train = vec_for_learning(model_dbow_chi_5, train_tagged)\n",
    "y_test, X_test = vec_for_learning(model_dbow_chi_5,test_tagged)\n",
    "\n",
    "for i in range(len(X_train)):\n",
    "    aa=(np.append(X_train[i],float(df.loc[i]['sympt_count']*10005)))\n",
    "    aa=(np.append(aa,float(df.loc[i]['m_usr_score_hygiene']*10005)))\n",
    "    aa=(np.append(aa,float(df.loc[i]['m_usr_score_value']*10005)))\n",
    "    aa=(np.append(aa,float(df.loc[i]['score_hygiene_diff']*10005)))        \n",
    "    aa=(np.append(aa,float(df.loc[i]['score_value_diff']*10005)))\n",
    "    X_train_new.append(aa)\n",
    "X_train_new=tuple(X_train_new)\n",
    "\n",
    "for i in range(len(X_test)):\n",
    "    bb=(np.append(X_test[i],float(df_test.loc[i]['sympt_count']*10005)))\n",
    "    bb=(np.append(bb,float(df_test.loc[i]['m_usr_score_hygiene']*10005)))\n",
    "    bb=(np.append(bb,float(df_test.loc[i]['m_usr_score_value']*10005)))\n",
    "    bb=(np.append(bb,float(df_test.loc[i]['score_hygiene_diff']*10005)))        \n",
    "    bb=(np.append(bb,float(df_test.loc[i]['score_value_diff']*10005)))\n",
    "    X_test_new.append(bb)\n",
    "X_test_new=tuple(X_test_new)\n",
    "\n",
    "\n",
    "logreg(X_train_new,y_train,X_test_new,y_test)\n",
    "print(\"----\")\n",
    "logreg_weight(X_train_new,y_train,X_test_new,y_test)\n",
    "print(\"============end=============\")\n",
    "\n",
    "# vector size=5 and weight =10005 has the best performance now\n",
    "\n",
    "clf = svm.SVC(kernel='rbf')\n",
    "clf.fit(X_train_new,y_train)\n",
    "\n",
    "y_pred = clf.predict(X_test_new)\n",
    " \n",
    "print('Testing accuracy %s' % accuracy_score(y_test, y_pred))\n",
    "print('Testing F1 score: {}'.format(f1_score(y_test, y_pred, average='weighted')))\n",
    "print(f'Area Under Curve: {roc_auc_score(y_test, y_pred)}')\n",
    "print(f'Recall score: {recall_score(y_test,y_pred,average=None)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing accuracy 0.8385964912280702\n",
      "Testing F1 score: 0.8337543859649122\n",
      "Area Under Curve: 0.7776643037366335\n",
      "Recall score: [0.63414634 0.92118227]\n",
      "----\n",
      "Testing accuracy 0.8491228070175438\n",
      "Testing F1 score: 0.8508874525495025\n",
      "Area Under Curve: 0.8286675477592215\n",
      "Recall score: [0.7804878  0.87684729]\n",
      "============end=============\n",
      "==========svm===============\n",
      "Testing accuracy 0.8982456140350877\n",
      "Testing F1 score: 0.898780837176372\n",
      "Area Under Curve: 0.8813228403219993\n",
      "Recall score: [0.84146341 0.92118227]\n"
     ]
    }
   ],
   "source": [
    "#try to normalize the input feature\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "X_train_new=[]\n",
    "X_test_new=[]\n",
    "\n",
    "#y_train, X_train = vec_for_learning(model_dbow_chi_5, train_tagged)\n",
    "#y_test, X_test = vec_for_learning(model_dbow_chi_5,test_tagged)\n",
    "y_train, X_train = get_vectors(model_dbow_dmm_chi_5, train_tagged)\n",
    "y_test, X_test = get_vectors(model_dbow_dmm_chi_5, test_tagged)\n",
    "\n",
    "#y_train, X_train = vec_for_learning(model_dbow_chi_7, train_tagged)\n",
    "#y_test, X_test = vec_for_learning(model_dbow_chi_7,test_tagged)\n",
    "\n",
    "for i in range(len(X_train)):\n",
    "    aa=(np.append(X_train[i],float(df.loc[i]['sympt_count'])))\n",
    "    aa=(np.append(aa,float(df.loc[i]['m_usr_score_hygiene'])))\n",
    "    aa=(np.append(aa,float(df.loc[i]['m_usr_score_value'])))\n",
    "    aa=(np.append(aa,float(df.loc[i]['score_hygiene_diff'])))        \n",
    "    aa=(np.append(aa,float(df.loc[i]['score_value_diff'])))\n",
    "    \"\"\"\n",
    "    aa=(np.append(X_train[i],float(df.loc[i]['sympt_count']*10005)))\n",
    "    aa=(np.append(aa,float(df.loc[i]['m_usr_score_hygiene']*10005)))\n",
    "    aa=(np.append(aa,float(df.loc[i]['m_usr_score_value']*10005)))\n",
    "    aa=(np.append(aa,float(df.loc[i]['score_hygiene_diff']*10005)))        \n",
    "    aa=(np.append(aa,float(df.loc[i]['score_value_diff']*10005)))\n",
    "    \"\"\"\n",
    "    aa=normalize(aa)\n",
    "    #scaler = StandardScaler().fit(aa)\n",
    "    #aa=scaler.transform(aa)\n",
    "    X_train_new.append(aa)\n",
    "    \n",
    "#X_train_new=np.array(X_train_new)\n",
    "#X_train_new_scaler=StandardScaler().fit(X_train_new)\n",
    "#X_train_new=X_train_new_scaler.transform(X_train_new)\n",
    "X_train_new=tuple(X_train_new)\n",
    "\n",
    "\n",
    "for i in range(len(X_test)):\n",
    "    bb=(np.append(X_test[i],float(df_test.loc[i]['sympt_count'])))\n",
    "    bb=(np.append(bb,float(df_test.loc[i]['m_usr_score_hygiene'])))\n",
    "    bb=(np.append(bb,float(df_test.loc[i]['m_usr_score_value'])))\n",
    "    bb=(np.append(bb,float(df_test.loc[i]['score_hygiene_diff'])))        \n",
    "    bb=(np.append(bb,float(df_test.loc[i]['score_value_diff'])))\n",
    "    \"\"\"\n",
    "    bb=(np.append(X_test[i],float(df_test.loc[i]['sympt_count']*10005)))\n",
    "    bb=(np.append(bb,float(df_test.loc[i]['m_usr_score_hygiene']*10005)))\n",
    "    bb=(np.append(bb,float(df_test.loc[i]['m_usr_score_value']*10005)))\n",
    "    bb=(np.append(bb,float(df_test.loc[i]['score_hygiene_diff']*10005)))        \n",
    "    bb=(np.append(bb,float(df_test.loc[i]['score_value_diff']*10005)))\n",
    "    \"\"\"\n",
    "    #bb=scaler.transform(bb)\n",
    "    bb=normalize(bb)\n",
    "    X_test_new.append(bb)\n",
    "    #\n",
    "    \n",
    "    #bb=scaler.fit(bb)\n",
    "#X_test_new=np.array(X_test_new)\n",
    "#X_test_new_scaler=StandardScaler().fit(X_test_new)\n",
    "#X_test_new=X_test_new_scaler.transform(X_test_new)\n",
    "X_test_new=tuple(X_test_new)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "logreg(X_train_new,y_train,X_test_new,y_test)\n",
    "print(\"----\")\n",
    "logreg_weight(X_train_new,y_train,X_test_new,y_test)\n",
    "print(\"============end=============\")\n",
    "\n",
    "\n",
    "print(\"==========svm===============\")\n",
    "clf = svm.SVC(kernel='rbf')\n",
    "clf.fit(X_train_new,y_train)\n",
    "\n",
    "\n",
    "y_pred = clf.predict(X_test_new)\n",
    " \n",
    "print('Testing accuracy %s' % accuracy_score(y_test, y_pred))\n",
    "print('Testing F1 score: {}'.format(f1_score(y_test, y_pred, average='weighted')))\n",
    "print(f'Area Under Curve: {roc_auc_score(y_test, y_pred)}')\n",
    "print(f'Recall score: {recall_score(y_test,y_pred,average=None)}')\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#using the original normalization method can help svm achieve accuracy about 91.7% (without *10000)\n",
    "#using the second normalization method can help weighted logistics regression achieve accuracy about 91.7%(without *10000)\n",
    "#standerscaler do not have significant imporvement \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1086,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing accuracy 0.8912280701754386\n",
      "Testing F1 score: 0.8931320706830367\n",
      "Area Under Curve: 0.8873002523128679\n",
      "Recall score: [0.87804878 0.89655172]\n",
      "----\n",
      "Testing accuracy 0.8771929824561403\n",
      "Testing F1 score: 0.8812860380756499\n",
      "Area Under Curve: 0.8956205695061876\n",
      "Recall score: [0.93902439 0.85221675]\n",
      "============end=============\n",
      "==========svm===============\n",
      "Testing accuracy 0.8912280701754386\n",
      "Testing F1 score: 0.8918002052575011\n",
      "Area Under Curve: 0.8727622251591973\n",
      "Recall score: [0.82926829 0.91625616]\n"
     ]
    }
   ],
   "source": [
    "#try to normalize the input feature\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "X_train_new=[]\n",
    "X_test_new=[]\n",
    "\n",
    "y_train, X_train = vec_for_learning(model_dbow_chi_5, train_tagged)\n",
    "y_test, X_test = vec_for_learning(model_dbow_chi_5,test_tagged)\n",
    "\n",
    "for i in range(len(X_train)):\n",
    "    aa=(np.append(X_train[i],float(df.loc[i]['sympt_count'])))\n",
    "    aa=(np.append(aa,float(df.loc[i]['m_usr_score_hygiene'])))\n",
    "    aa=(np.append(aa,float(df.loc[i]['m_usr_score_value'])))\n",
    "    aa=(np.append(aa,float(df.loc[i]['score_hygiene_diff'])))        \n",
    "    aa=(np.append(aa,float(df.loc[i]['score_value_diff'])))\n",
    "    #aa=normalize(aa)\n",
    "    #scaler = StandardScaler().fit(aa)\n",
    "    #aa=scaler.transform(aa)\n",
    "    X_train_new.append(aa)\n",
    "    \n",
    "X_train_new=np.array(X_train_new)\n",
    "X_train_new_scaler=StandardScaler().fit(X_train_new)\n",
    "X_train_new=X_train_new_scaler.transform(X_train_new)\n",
    "X_train_new=tuple(X_train_new)\n",
    "\n",
    "\n",
    "for i in range(len(X_test)):\n",
    "    bb=(np.append(X_test[i],float(df_test.loc[i]['sympt_count'])))\n",
    "    bb=(np.append(bb,float(df_test.loc[i]['m_usr_score_hygiene'])))\n",
    "    bb=(np.append(bb,float(df_test.loc[i]['m_usr_score_value'])))\n",
    "    bb=(np.append(bb,float(df_test.loc[i]['score_hygiene_diff'])))        \n",
    "    bb=(np.append(bb,float(df_test.loc[i]['score_value_diff'])))\n",
    "    #bb=scaler.transform(bb)\n",
    "    #bb=normalize(bb)\n",
    "    X_test_new.append(bb)\n",
    "    #\n",
    "    \n",
    "    #bb=scaler.fit(bb)\n",
    "X_test_new=np.array(X_test_new)\n",
    "X_test_new_scaler=StandardScaler().fit(X_test_new)\n",
    "X_test_new=X_test_new_scaler.transform(X_test_new)\n",
    "X_test_new=tuple(X_test_new)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "logreg(X_train_new,y_train,X_test_new,y_test)\n",
    "print(\"----\")\n",
    "logreg_weight(X_train_new,y_train,X_test_new,y_test)\n",
    "print(\"============end=============\")\n",
    "\n",
    "\n",
    "print(\"==========svm===============\")\n",
    "clf = svm.SVC(kernel='rbf')\n",
    "clf.fit(X_train_new,y_train)\n",
    "\n",
    "\n",
    "y_pred = clf.predict(X_test_new)\n",
    " \n",
    "print('Testing accuracy %s' % accuracy_score(y_test, y_pred))\n",
    "print('Testing F1 score: {}'.format(f1_score(y_test, y_pred, average='weighted')))\n",
    "print(f'Area Under Curve: {roc_auc_score(y_test, y_pred)}')\n",
    "print(f'Recall score: {recall_score(y_test,y_pred,average=None)}')\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1077,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing accuracy 0.9017543859649123\n",
      "Testing F1 score: 0.9021030448003583\n",
      "Area Under Curve: 0.8837858945091914\n",
      "Recall score: [0.84146341 0.92610837]\n",
      "----\n",
      "Testing accuracy 0.9017543859649123\n",
      "Testing F1 score: 0.9038635915631776\n",
      "Area Under Curve: 0.9055929352396973\n",
      "Recall score: [0.91463415 0.89655172]\n",
      "============end=============\n"
     ]
    }
   ],
   "source": [
    "X_train_new=[]\n",
    "X_test_new=[]\n",
    "\n",
    "y_train, X_train = vec_for_learning(model_dbow_chi_5, train_tagged)\n",
    "y_test, X_test = vec_for_learning(model_dbow_chi_5,test_tagged)\n",
    "\n",
    "for i in range(len(X_train)):\n",
    "    aa=(np.append(X_train[i],float(df.loc[i]['sympt_count'])))\n",
    "    aa=(np.append(aa,float(df.loc[i]['m_usr_score_hygiene'])))\n",
    "    aa=(np.append(aa,float(df.loc[i]['m_usr_score_value'])))\n",
    "    aa=(np.append(aa,float(df.loc[i]['score_hygiene_diff'])))        \n",
    "    aa=(np.append(aa,float(df.loc[i]['score_value_diff'])))\n",
    "    X_train_new.append(aa)\n",
    "X_train_new=tuple(X_train_new)\n",
    "\n",
    "for i in range(len(X_test)):\n",
    "    bb=(np.append(X_test[i],float(df_test.loc[i]['sympt_count'])))\n",
    "    bb=(np.append(bb,float(df_test.loc[i]['m_usr_score_hygiene'])))\n",
    "    bb=(np.append(bb,float(df_test.loc[i]['m_usr_score_value'])))\n",
    "    bb=(np.append(bb,float(df_test.loc[i]['score_hygiene_diff'])))        \n",
    "    bb=(np.append(bb,float(df_test.loc[i]['score_value_diff'])))\n",
    "    X_test_new.append(bb)\n",
    "X_test_new=tuple(X_test_new)\n",
    "\n",
    "\n",
    "logreg(X_train_new,y_train,X_test_new,y_test)\n",
    "print(\"----\")\n",
    "logreg_weight(X_train_new,y_train,X_test_new,y_test)\n",
    "print(\"============end=============\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 937,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1399/1399 [00:00<00:00, 959893.88it/s]\n",
      "100%|██████████| 1399/1399 [00:00<00:00, 3124510.81it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing accuracy 0.7157894736842105\n",
      "Testing F1 score: 0.6377633672463892\n",
      "Area Under Curve: 0.5315391084945332\n",
      "Recall score: [0.09756098 0.96551724]\n",
      "Testing accuracy 0.5824561403508772\n",
      "Testing F1 score: 0.6021945184875839\n",
      "Area Under Curve: 0.5978613480716088\n",
      "Recall score: [0.63414634 0.56157635]\n"
     ]
    }
   ],
   "source": [
    "model_dbow_chi_1=train_dbow(train_tagged)\n",
    "model_dbow_chi_1.save('model_dbow_chi_1')\n",
    "y_train, X_train = vec_for_learning(model_dbow_chi_1, train_tagged)\n",
    "y_test, X_test = vec_for_learning(model_dbow_chi_1, test_tagged)\n",
    "logreg(X_train,y_train,X_test,y_test)\n",
    "logreg_weight(X_train,y_train,X_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 939,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing accuracy 0.43157894736842106\n",
      "Testing F1 score: 0.44142477195752905\n",
      "Area Under Curve: 0.5028535383876006\n",
      "Recall score: [0.67073171 0.33497537]\n",
      "----\n",
      "Testing accuracy 0.3508771929824561\n",
      "Testing F1 score: 0.31125043941132996\n",
      "Area Under Curve: 0.48618286675477596\n",
      "Recall score: [0.80487805 0.16748768]\n",
      "============end=============\n"
     ]
    }
   ],
   "source": [
    "X_train_new=[]\n",
    "X_test_new=[]\n",
    "\n",
    "y_train, X_train = vec_for_learning(model_dbow_chi_1, train_tagged)\n",
    "y_test, X_test = vec_for_learning(model_dbow_chi_1,test_tagged)\n",
    "\n",
    "for i in range(len(X_train)):\n",
    "    aa=(np.append(X_train[i],float(df.loc[i]['sympt_count'])))\n",
    "    aa=(np.append(aa,float(df.loc[i]['m_usr_score_hygiene'])))\n",
    "    aa=(np.append(aa,float(df.loc[i]['m_usr_score_value'])))\n",
    "    aa=(np.append(aa,float(df.loc[i]['score_hygiene_diff'])))        \n",
    "    aa=(np.append(aa,float(df.loc[i]['score_value_diff'])))\n",
    "    X_train_new.append(aa)\n",
    "X_train_new=tuple(X_train_new)\n",
    "\n",
    "for i in range(len(X_test)):\n",
    "    bb=(np.append(X_test[i],float(df.loc[i]['sympt_count'])))\n",
    "    bb=(np.append(bb,float(df.loc[i]['m_usr_score_hygiene'])))\n",
    "    bb=(np.append(bb,float(df.loc[i]['m_usr_score_value'])))\n",
    "    bb=(np.append(bb,float(df.loc[i]['score_hygiene_diff'])))        \n",
    "    bb=(np.append(bb,float(df.loc[i]['score_value_diff'])))\n",
    "    X_test_new.append(bb)\n",
    "X_test_new=tuple(X_test_new)\n",
    "\n",
    "\n",
    "logreg(X_train_new,y_train,X_test_new,y_test)\n",
    "print(\"----\")\n",
    "logreg_weight(X_train_new,y_train,X_test_new,y_test)\n",
    "print(\"============end=============\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 923,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1399/1399 [00:00<00:00, 932437.84it/s]\n",
      "100%|██████████| 1399/1399 [00:00<00:00, 3059348.96it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing accuracy 0.7508771929824561\n",
      "Testing F1 score: 0.7521875668800833\n",
      "Area Under Curve: 0.70154992190316\n",
      "Recall score: [0.58536585 0.81773399]\n",
      "Testing accuracy 0.7263157894736842\n",
      "Testing F1 score: 0.736135477582846\n",
      "Area Under Curve: 0.7170191036885738\n",
      "Recall score: [0.69512195 0.73891626]\n"
     ]
    }
   ],
   "source": [
    "####dmm--only chinese-vector size=25\n",
    "model_dmm_chi_25=train_dmm(train_tagged)\n",
    "model_dmm_chi_25.save('model_dmm_chi_25')\n",
    "y_train, X_train = vec_for_learning(model_dmm_chi_25, train_tagged)\n",
    "y_test, X_test = vec_for_learning(model_dmm_chi_25, test_tagged)\n",
    "logreg(X_train,y_train,X_test,y_test)\n",
    "logreg_weight(X_train,y_train,X_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 925,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing accuracy 0.8105263157894737\n",
      "Testing F1 score: 0.8111987292578339\n",
      "Area Under Curve: 0.772497897392767\n",
      "Recall score: [0.68292683 0.86206897]\n",
      "-----\n",
      "Testing accuracy 0.8070175438596491\n",
      "Testing F1 score: 0.8098498601594915\n",
      "Area Under Curve: 0.7809383635708278\n",
      "Recall score: [0.7195122  0.84236453]\n"
     ]
    }
   ],
   "source": [
    "####dbow+dmm--new model-chi vector size=25\n",
    "new_model_chi_25=concat_model(model_dbow_chi_25,model_dmm_chi_25)\n",
    "y_train, X_train = get_vectors(new_model_chi_25, train_tagged)\n",
    "y_test, X_test = get_vectors(new_model_chi_25, test_tagged)\n",
    "logreg(X_train,y_train,X_test,y_test)\n",
    "print(\"-----\")\n",
    "logreg_weight(X_train,y_train,X_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 927,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing accuracy 0.8385964912280702\n",
      "Testing F1 score: 0.8385964912280702\n",
      "Area Under Curve: 0.8031058512555569\n",
      "Recall score: [0.7195122  0.88669951]\n",
      "----\n",
      "Testing accuracy 0.8105263157894737\n",
      "Testing F1 score: 0.8166683278319449\n",
      "Area Under Curve: 0.812477472065361\n",
      "Recall score: [0.81707317 0.80788177]\n",
      "============end=============\n"
     ]
    }
   ],
   "source": [
    "X_train_new=[]\n",
    "X_test_new=[]\n",
    "\n",
    "y_train, X_train = vec_for_learning(model_dbow_chi_25, train_tagged)\n",
    "y_test, X_test = vec_for_learning(model_dbow_chi_25,test_tagged)\n",
    "\n",
    "for i in range(len(X_train)):\n",
    "    aa=(np.append(X_train[i],float(df.loc[i]['sympt_count']*100)))\n",
    "    aa=(np.append(aa,float(df.loc[i]['m_usr_score_hygiene']*100)))\n",
    "    aa=(np.append(aa,float(df.loc[i]['m_usr_score_value']*100)))\n",
    "    aa=(np.append(aa,float(df.loc[i]['score_hygiene_diff']*100)))        \n",
    "    aa=(np.append(aa,float(df.loc[i]['score_value_diff']*100)))\n",
    "    X_train_new.append(aa)\n",
    "X_train_new=tuple(X_train_new)\n",
    "\n",
    "for i in range(len(X_test)):\n",
    "    bb=(np.append(X_test[i],float(df.loc[i]['sympt_count']*100)))\n",
    "    bb=(np.append(bb,float(df.loc[i]['m_usr_score_hygiene']*100)))\n",
    "    bb=(np.append(bb,float(df.loc[i]['m_usr_score_value']*100)))\n",
    "    bb=(np.append(bb,float(df.loc[i]['score_hygiene_diff']*100)))        \n",
    "    bb=(np.append(bb,float(df.loc[i]['score_value_diff']*100)))\n",
    "    X_test_new.append(bb)\n",
    "X_test_new=tuple(X_test_new)\n",
    "\n",
    "logreg(X_train_new,y_train,X_test_new,y_test)\n",
    "print(\"----\")\n",
    "logreg_weight(X_train_new,y_train,X_test_new,y_test)\n",
    "print(\"============end=============\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 894,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing accuracy 0.6526315789473685\n",
      "Testing F1 score: 0.6688792731911665\n",
      "Area Under Curve: 0.668929472545957\n",
      "Recall score: [0.70731707 0.63054187]\n",
      "----\n",
      "Testing accuracy 0.6350877192982456\n",
      "Testing F1 score: 0.6523381180223287\n",
      "Area Under Curve: 0.6566142016099964\n",
      "Recall score: [0.70731707 0.60591133]\n",
      "============end=============\n"
     ]
    }
   ],
   "source": [
    "X_train_new=[]\n",
    "X_test_new=[]\n",
    "\n",
    "y_train, X_train = vec_for_learning(model_dmm_chi_25, train_tagged)\n",
    "y_test, X_test = vec_for_learning(model_dmm_chi_25,test_tagged)\n",
    "\n",
    "for i in range(len(X_train)):\n",
    "    aa=(np.append(X_train[i],float(df.loc[i]['sympt_count']*100)))\n",
    "    aa=(np.append(aa,float(df.loc[i]['m_usr_score_hygiene']*100)))\n",
    "    aa=(np.append(aa,float(df.loc[i]['m_usr_score_value']*100)))\n",
    "    aa=(np.append(aa,float(df.loc[i]['score_hygiene_diff']*100)))        \n",
    "    aa=(np.append(aa,float(df.loc[i]['score_value_diff']*100)))\n",
    "    X_train_new.append(aa)\n",
    "X_train_new=tuple(X_train_new)\n",
    "\n",
    "for i in range(len(X_test)):\n",
    "    bb=(np.append(X_test[i],float(df.loc[i]['sympt_count']*100)))\n",
    "    bb=(np.append(bb,float(df.loc[i]['m_usr_score_hygiene']*100)))\n",
    "    bb=(np.append(bb,float(df.loc[i]['m_usr_score_value']*100)))\n",
    "    bb=(np.append(bb,float(df.loc[i]['score_hygiene_diff']*100)))        \n",
    "    bb=(np.append(bb,float(df.loc[i]['score_value_diff']*100)))\n",
    "    X_test_new.append(bb)\n",
    "X_test_new=tuple(X_test_new)\n",
    "\n",
    "logreg(X_train_new,y_train,X_test_new,y_test)\n",
    "print(\"----\")\n",
    "logreg_weight(X_train_new,y_train,X_test_new,y_test)\n",
    "print(\"============end=============\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 896,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/yanniyang/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing accuracy 0.656140350877193\n",
      "Testing F1 score: 0.6716125737207449\n",
      "Area Under Curve: 0.6604890063678962\n",
      "Recall score: [0.67073171 0.65024631]\n",
      "----\n",
      "Testing accuracy 0.6280701754385964\n",
      "Testing F1 score: 0.6452415956091345\n",
      "Area Under Curve: 0.633515559293524\n",
      "Recall score: [0.64634146 0.62068966]\n",
      "============end=============\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/yanniyang/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "X_train_new=[]\n",
    "X_test_new=[]\n",
    "\n",
    "y_train, X_train = vec_for_learning(new_model_chi_25, train_tagged)\n",
    "y_test, X_test = vec_for_learning(new_model_chi_25,test_tagged)\n",
    "\n",
    "for i in range(len(X_train)):\n",
    "    aa=(np.append(X_train[i],float(df.loc[i]['sympt_count']*100)))\n",
    "    aa=(np.append(aa,float(df.loc[i]['m_usr_score_hygiene']*100)))\n",
    "    aa=(np.append(aa,float(df.loc[i]['m_usr_score_value']*100)))\n",
    "    aa=(np.append(aa,float(df.loc[i]['score_hygiene_diff']*100)))        \n",
    "    aa=(np.append(aa,float(df.loc[i]['score_value_diff']*100)))\n",
    "    X_train_new.append(aa)\n",
    "X_train_new=tuple(X_train_new)\n",
    "\n",
    "for i in range(len(X_test)):\n",
    "    bb=(np.append(X_test[i],float(df.loc[i]['sympt_count']*100)))\n",
    "    bb=(np.append(bb,float(df.loc[i]['m_usr_score_hygiene']*100)))\n",
    "    bb=(np.append(bb,float(df.loc[i]['m_usr_score_value']*100)))\n",
    "    bb=(np.append(bb,float(df.loc[i]['score_hygiene_diff']*100)))        \n",
    "    bb=(np.append(bb,float(df.loc[i]['score_value_diff']*100)))\n",
    "    X_test_new.append(bb)\n",
    "X_test_new=tuple(X_test_new)\n",
    "\n",
    "\n",
    "logreg(X_train_new,y_train,X_test_new,y_test)\n",
    "print(\"----\")\n",
    "logreg_weight(X_train_new,y_train,X_test_new,y_test)\n",
    "print(\"============end=============\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "################TEXT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "90"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### real symptom from train data\n",
    "real_sentences = ['第二天起来就开始肚子痛', '我们两人都肚泻了', '即刻肚痛又肚屙屙左3次',\n",
    "                  '一路走一路肚痛火都黎番到屋企要食喇x丸到今日个肚仲系唔','5点几就开始肚痛肚all到依家所以唔怕有肠胃炎都可以去试下既一碗小面',\n",
    "                 '食完同行既有一个发烧一个肚屙一个肚屙加发烧','我都顶你地唔顶走人返到屋企仲要肚屙试问自己要求亦不算高','最惨系食完肠胃炎',\n",
    "                 '同埋我地有3个人食完都胃痛兼肚屙','其他食左鳗鱼饭嘅都肚屙到想死','我自己亦都开始发烧肚屙想呕','第二日同友人相继出现肚屙',\n",
    "                 '我同朋友一齐食这个一齐肠胃炎了','第二日就肠胃炎','食完又屙又呕','重点系有位朋友食完即刻肚屙','而其他4-5位朋友食完都有唔舒服同肠胃炎',\n",
    "                 '本人怀疑食完鱼生寿司肚屙','但返到屋企即刻肚屙','食完仲要肚屙','仲要肚屙','我同男朋友都有d肚屙','当晚即刻肚屙',\n",
    "                 '因为人生第一次肠胃炎就系食呢间餐厅嗰包','吃完胃痛左几个','肚子痛了一晚上','朋友还拉肚子了','食完系个个都有屙','行返屋企半路上开始有啲胃痛',\n",
    "                 '胃痛想呕朋友吃完晚上回家','个个都出现肚屙肚泻','我仲发埋烧及呕左','但食完我同我男朋友都系屋企肚屙左成晚','朋友食完即时肚屙',\n",
    "                 '返到屋企仲要肠胃炎','肚屙又心跳快','食完我番到公司肚屙','我朋友下午还拉肚子了','医生话我系肠胃炎重发埋烧添','重点系我22号零晨胃痛痛醒了',\n",
    "                 '食完会胃痛','食到佢有胃痛','但回家和友人都肚屙','我在酒店呕咗三次','仲要朋友食完既晚上肚痛添','我今朝屙左3次','仲要食到肚痛',\n",
    "                 '食完返到去已经呕左2次','而且最重要的是我最近两次来吃我都拉肚子了','我同朋友食完都肚泻','朋友仲搞到肠胃炎','朋友吃了当晚肚子痛',\n",
    "                 '同行友人讲返原来佢都肚屙','我果晚半夜肚痛痛醒左','但系第二朝我同女友都轻微肚泻','跟住个肚好肚痛','食完肚疼','最惨系食完一小时就肚痛',\n",
    "                 '野食唔热都算食完同行几个朋友都肚柯隔左好耐比多次机会佢点知','因为都系一次但点解要上黎写劣平系因为我同我老公食完都肚痛','食完肚痛及疴咗两次',\n",
    "                 '无奈食完无耐行商场既时候竟然肚柯','部份亲友咁岩有人当晚肚痛','最夸张是回家肚痛要去厕所','第二日起身肚痛','食甘耐嘢未试过甘样肚痛',\n",
    "                 '但味道太一般般当晚返到屋企肚柯都冇谂过关餐饭事直到第二日奶奶话柯左几次','有人返到屋企就肚痛','食完仲有小小肚痛','食完夜晚反到屋企肚柯',\n",
    "                 '全部人就食物中毒又痀又呕又发烧','男朋友食完表示肚痛','食完我女朋友寻日就呕左成晚','第二日就发烧','值得推介但食完有点肚痛赠送左',\n",
    "                 '但无人会想食完肚柯架','友人肚泻了很多次','胃抽筋屙呕了很多次','点知个一晚就已经肚痛','食完个个都肚痛','佢食完仲觉得有少少肚痛',\n",
    "                 '返到屋企既肚痛','肚痛要去厕所','结果都系食完肚痛','不嗜辣的朋友回到家也肚子痛','但系我反完屋企就搞肚痛','但系食完未走已经肚屙',\n",
    "                 '我就出现肠胃炎症状','竟然发现同朋友一样有肚屙既情况','只是之後那天就开始胃痛','我同同行朋友加埋肚屙左五次','但系返到屋企之後当晚就即刻搞肚痛',\n",
    "                 '就夜晚开始肚屙','3个人之後很快肚子痛','我返到屋企亦痾左水数次','一人肚泻呕吐','另一人也出现肚泻','我老婆食完仲肚痛','跟住嗰两日肠胃炎',\n",
    "                  '食完冇几耐就肚痛','去到黄昏我地两个都肚痛','有成10个同事都有肚痾嘅情况出现','今次食完同女朋友都肚胀又痾','但食完佢碗粉就会肚痛',\n",
    "                  '两个人肚痾同呕左几日','不过我朋友食完话有阵怪味重肚痛']\n",
    "\n",
    "fake_sentences = ['希望有改善其实我都怕食生野肚痛','我怕肚痛','食完都无肚痛','起码到而家都冇肚痛','从来未试过肚痛','唔怕食到肚痛','好容易肚痛','食咁多次都无肚泻',\n",
    "                 '因为他很易肚痛','食过咁多次都无肚痛','免得肚柯','起码我次次食完都无试过肚痛','其实我哋有惊食到肚痛㗎','觉得会肚痛','猪大肠清得几乾净唔怕食到肚痛',\n",
    "                 '否则食完肚痛就无谓啦','原本会觉得好似争先咁唔系咁新鲜惊食咗会肚痛','容易肚痛','但最重要都系食左冇肚泻','但可能是怕未煮至全煮易令客人肚痛吧',\n",
    "                 '可能系担心人食咁生会肚痛','返到屋企无肚痛','最惊食完沙律会肚痛','食完无肚痛','不过食完冇肚痛','食呢间既蚝冇肚痛','食完无肚痛','总之食完唔肚痛就算',\n",
    "                 '其他生腌蟹我又怕肚痛','担心会肚痛','食左咁多次都无肚痛','因为怕食完肚痛所以就冇食','一阵食到人肚痛就唔好','真系食左惊肚痛','今晚唔好肚痛',\n",
    "                 '吾惊肚痛啦叫左韭菜猪红','如果我今晚肚痛我实告硬佢','随手拾返又吾洗手就拿熟食希望食完吾肚痛啦','未到75度希望唔会肚柯啦','但可以过下蚝瘾食完又吾会肚痛',\n",
    "                 '无肚屙无肚痛','喎返到屋企都冇肚痛','也从不肚痛','食完都惊肚痛','唔怕食到肚痛','玻璃肠既我第二日都冇肚痛','无咁易肚痛呀','害怕我食到肚痛',\n",
    "                 '仲要饮完冇肚痛呢吓好重要','希望今晚唔会肚痛啦','不要吃到肚痛就','不过我怕会肚痛','开头我都惊好易肚痛','食咁多次都冇肚痛','好味食完系无屙同肚痛嫁今次',\n",
    "                 '唔怕会食到肚痛','有点刺激又唔会肚痛','食完都惊肚痛','所以唔会整到我肚痛','食完第2日唔肚痛我已经好感恩','好彩第二日无肚痛','我食完两日都冇肚柯',\n",
    "                 '好彩之後冇肚痛','唔会怕食左会肚痛','最重要系唔会肚痾','是要看看有冇肚泻现象','完全无肚痛','我们之後都冇肚痛的现象','兼要有事後肚痛的心理准备',\n",
    "                 '唔知佢会唔会肚痛','弟日都没有肚痛','都唔会肚痛','暂时无事无肚痛','惊肚痛都冇饮','平时钟意食蚝既我因为好怕食到唔乾净既蚝会肚痛','不过起码食完无肚痛',\n",
    "                 '但系又惊肚痛','惊会肚痛','呢晚食咗两只结果系无肚痛','所以食完无肚痛','下价刺身食完又惊肚泻','而且一路食一落觉得自己会肚痾','食完都冇肚痛等等问题出现',\n",
    "                 '唔知会唔会肚痾','吃完没肚痛','老实讲一路食一路惊今晚痾','好怕会肚痾','未吃光看已经有吃後会肚痛的感觉','好大机会会死到人肚痾','唔乾净我惊食左肚痛']\n",
    "\n",
    "len(fake_sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Building prefix dict from the default dictionary ...\n",
      "Loading model from cache /tmp/jieba.cache\n",
      "Loading model cost 0.583 seconds.\n",
      "Prefix dict has been built successfully.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>第二天 起来 就 开始 肚子痛</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>我们 两人 都 肚泻 了</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>即刻 肚痛 又 肚 屙 屙 左 3 次</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>一路 走 一路 肚痛 火 都 黎番 到 屋企 要食 喇 x 丸 到 今日 个 肚仲系 唔</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5 点 几 就 开始 肚痛 肚 all 到 依家 所以 唔 怕 有 肠胃炎 都 可以 去 试...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>食完 同行 既有 一个 发烧 一个 肚 屙 一个 肚 屙 加 发烧</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>我 都 顶 你 地 唔 顶 走 人 返到 屋企 仲要 肚 屙 试问 自己 要求 亦 不算 高</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>最惨 系食 完 肠胃炎</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>同埋 我 地 有 3 个人 食完 都 胃痛 兼肚 屙</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>其他 食 左 鳗鱼 饭 嘅 都 肚 屙 到 想 死</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              review  label\n",
       "0                                    第二天 起来 就 开始 肚子痛      0\n",
       "1                                       我们 两人 都 肚泻 了      0\n",
       "2                                即刻 肚痛 又 肚 屙 屙 左 3 次      0\n",
       "3       一路 走 一路 肚痛 火 都 黎番 到 屋企 要食 喇 x 丸 到 今日 个 肚仲系 唔      0\n",
       "4  5 点 几 就 开始 肚痛 肚 all 到 依家 所以 唔 怕 有 肠胃炎 都 可以 去 试...      0\n",
       "5                  食完 同行 既有 一个 发烧 一个 肚 屙 一个 肚 屙 加 发烧      0\n",
       "6     我 都 顶 你 地 唔 顶 走 人 返到 屋企 仲要 肚 屙 试问 自己 要求 亦 不算 高      0\n",
       "7                                        最惨 系食 完 肠胃炎      0\n",
       "8                         同埋 我 地 有 3 个人 食完 都 胃痛 兼肚 屙      0\n",
       "9                          其他 食 左 鳗鱼 饭 嘅 都 肚 屙 到 想 死      0"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "real_test_sen=pd.DataFrame(real_sentences,columns=['review'])\n",
    "fake_test_sen=pd.DataFrame(fake_sentences,columns=['review'])\n",
    "\n",
    "real_test_sen['review']=real_test_sen['review'].apply(lambda x: \" \".join([w for w in list(jieba.cut(x))]))\n",
    "real_test_sen['label']=0\n",
    "fake_test_sen['review']=fake_test_sen['review'].apply(lambda x: \" \".join([w for w in list(jieba.cut(x))]))\n",
    "fake_test_sen['label']=1\n",
    "real_test_sen.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "second_test=pd.concat([real_test_sen,fake_test_sen],ignore_index=True)\n",
    "second_test.index=range((second_test.shape)[0])\n",
    "second_test['review'].apply(lambda x: len(x.split(' '))).sum()\n",
    "second_tagged=second_test.apply(\n",
    "    lambda r: TaggedDocument(words=tokenize_text(r['review']), tags=[r.label]), axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing accuracy 0.5408163265306123\n",
      "Testing F1 score: 0.3796458980943371\n"
     ]
    }
   ],
   "source": [
    "##using second text to test the model trained by the whole real and fake data \n",
    "y_train, X_train = vec_for_learning(model_dbow, train_tagged)\n",
    "y_test, X_test = vec_for_learning(model_dbow, second_tagged)\n",
    "logreg(X_train,y_train,X_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing accuracy 0.5663265306122449\n",
      "Testing F1 score: 0.4681078006115338\n"
     ]
    }
   ],
   "source": [
    "y_train, X_train = vec_for_learning(model_dmm, train_tagged)\n",
    "y_test, X_test = vec_for_learning(model_dmm, second_tagged)\n",
    "logreg(X_train,y_train,X_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing accuracy 0.5969387755102041\n",
      "Testing F1 score: 0.5110660496367756\n"
     ]
    }
   ],
   "source": [
    "new_model=concat_model(model_dbow,model_dmm)\n",
    "y_train, X_train = get_vectors(new_model, train_tagged)\n",
    "y_test, X_test = get_vectors(new_model, second_tagged)\n",
    "logreg(X_train,y_train,X_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "###using second text for training and testing\n",
    "sec_train, sec_test = train_test_split(second_test, test_size=0.3, random_state=42)\n",
    "sec_train.index=range((sec_train.shape)[0])\n",
    "sec_test.index=range((sec_test.shape)[0])\n",
    "sec_train['review'].apply(lambda x: len(x.split(' '))).sum()\n",
    "sec_test['review'].apply(lambda x: len(x.split(' '))).sum()\n",
    "sec_train_tagged=sec_train.apply(\n",
    "    lambda r: TaggedDocument(words=tokenize_text(r['review']), tags=[r.label]), axis=1)\n",
    "sec_test_tagged=sec_test.apply(\n",
    "    lambda r: TaggedDocument(words=tokenize_text(r['review']), tags=[r.label]), axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 137/137 [00:00<00:00, 453170.07it/s]\n",
      "100%|██████████| 137/137 [00:00<00:00, 293023.79it/s]\n",
      "100%|██████████| 137/137 [00:00<00:00, 535027.61it/s]\n",
      "100%|██████████| 137/137 [00:00<00:00, 534529.91it/s]\n",
      "100%|██████████| 137/137 [00:00<00:00, 538033.38it/s]\n",
      "100%|██████████| 137/137 [00:00<00:00, 532055.23it/s]\n",
      "100%|██████████| 137/137 [00:00<00:00, 575194.84it/s]\n",
      "100%|██████████| 137/137 [00:00<00:00, 603592.07it/s]\n",
      "100%|██████████| 137/137 [00:00<00:00, 538033.38it/s]\n",
      "100%|██████████| 137/137 [00:00<00:00, 529115.70it/s]\n",
      "100%|██████████| 137/137 [00:00<00:00, 611297.50it/s]\n",
      "100%|██████████| 137/137 [00:00<00:00, 453527.74it/s]\n",
      "100%|██████████| 137/137 [00:00<00:00, 529115.70it/s]\n",
      "100%|██████████| 137/137 [00:00<00:00, 533042.35it/s]\n",
      "100%|██████████| 137/137 [00:00<00:00, 539548.97it/s]\n",
      "100%|██████████| 137/137 [00:00<00:00, 538537.63it/s]\n",
      "100%|██████████| 137/137 [00:00<00:00, 527173.99it/s]\n",
      "100%|██████████| 137/137 [00:00<00:00, 1056286.12it/s]\n",
      "100%|██████████| 137/137 [00:00<00:00, 457499.72it/s]\n",
      "100%|██████████| 137/137 [00:00<00:00, 533042.35it/s]\n",
      "100%|██████████| 137/137 [00:00<00:00, 532055.23it/s]\n",
      "100%|██████████| 137/137 [00:00<00:00, 571192.49it/s]\n",
      "100%|██████████| 137/137 [00:00<00:00, 536025.79it/s]\n",
      "100%|██████████| 137/137 [00:00<00:00, 531071.76it/s]\n",
      "100%|██████████| 137/137 [00:00<00:00, 581598.83it/s]\n",
      "100%|██████████| 137/137 [00:00<00:00, 537027.71it/s]\n",
      "100%|██████████| 137/137 [00:00<00:00, 537530.07it/s]\n",
      "100%|██████████| 137/137 [00:00<00:00, 540056.06it/s]\n",
      "100%|██████████| 137/137 [00:00<00:00, 459328.26it/s]\n",
      "100%|██████████| 137/137 [00:00<00:00, 538033.38it/s]\n",
      "100%|██████████| 137/137 [00:00<00:00, 477258.84it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing accuracy 0.576271186440678\n",
      "Testing F1 score: 0.576271186440678\n"
     ]
    }
   ],
   "source": [
    "####second-dbow\n",
    "model_dbow_sec=train_dbow(sec_train_tagged)\n",
    "model_dbow_sec.save('model_dbow_sec')\n",
    "y_train_sec, X_train_sec = vec_for_learning(model_dbow_sec, sec_train_tagged)\n",
    "y_test_sec, X_test_sec = vec_for_learning(model_dbow_sec, sec_test_tagged)\n",
    "logreg(X_train_sec,y_train_sec,X_test_sec,y_test_sec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing accuracy 0.45964912280701753\n",
      "Testing F1 score: 0.47758373840652585\n"
     ]
    }
   ],
   "source": [
    "#####second-dbow-test \"all_real_fake\"\n",
    "y_train_sec, X_train_sec = vec_for_learning(model_dbow_sec, sec_train_tagged)\n",
    "y_test, X_test = get_vectors(model_dbow_sec, test_tagged)\n",
    "logreg(X_train_sec,y_train_sec,X_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 137/137 [00:00<00:00, 439311.66it/s]\n",
      "100%|██████████| 137/137 [00:00<00:00, 488622.15it/s]\n",
      "100%|██████████| 137/137 [00:00<00:00, 540564.11it/s]\n",
      "100%|██████████| 137/137 [00:00<00:00, 537027.71it/s]\n",
      "100%|██████████| 137/137 [00:00<00:00, 528628.93it/s]\n",
      "100%|██████████| 137/137 [00:00<00:00, 258024.09it/s]\n",
      "100%|██████████| 137/137 [00:00<00:00, 451745.01it/s]\n",
      "100%|██████████| 137/137 [00:00<00:00, 517209.40it/s]\n",
      "100%|██████████| 137/137 [00:00<00:00, 501413.31it/s]\n",
      "100%|██████████| 137/137 [00:00<00:00, 571192.49it/s]\n",
      "100%|██████████| 137/137 [00:00<00:00, 512138.72it/s]\n",
      "100%|██████████| 137/137 [00:00<00:00, 557342.04it/s]\n",
      "100%|██████████| 137/137 [00:00<00:00, 561700.54it/s]\n",
      "100%|██████████| 137/137 [00:00<00:00, 540056.06it/s]\n",
      "100%|██████████| 137/137 [00:00<00:00, 586945.50it/s]\n",
      "100%|██████████| 137/137 [00:00<00:00, 520488.81it/s]\n",
      "100%|██████████| 137/137 [00:00<00:00, 517209.40it/s]\n",
      "100%|██████████| 137/137 [00:00<00:00, 522856.82it/s]\n",
      "100%|██████████| 137/137 [00:00<00:00, 527173.99it/s]\n",
      "100%|██████████| 137/137 [00:00<00:00, 525246.48it/s]\n",
      "100%|██████████| 137/137 [00:00<00:00, 486553.47it/s]\n",
      "100%|██████████| 137/137 [00:00<00:00, 525246.48it/s]\n",
      "100%|██████████| 137/137 [00:00<00:00, 562250.14it/s]\n",
      "100%|██████████| 137/137 [00:00<00:00, 497075.82it/s]\n",
      "100%|██████████| 137/137 [00:00<00:00, 571192.49it/s]\n",
      "100%|██████████| 137/137 [00:00<00:00, 433675.21it/s]\n",
      "100%|██████████| 137/137 [00:00<00:00, 586945.50it/s]\n",
      "100%|██████████| 137/137 [00:00<00:00, 526208.47it/s]\n",
      "100%|██████████| 137/137 [00:00<00:00, 406091.62it/s]\n",
      "100%|██████████| 137/137 [00:00<00:00, 504494.86it/s]\n",
      "100%|██████████| 137/137 [00:00<00:00, 415187.61it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing accuracy 0.8135593220338984\n",
      "Testing F1 score: 0.8129136400322841\n"
     ]
    }
   ],
   "source": [
    "####second-dmm\n",
    "model_dmm_sec=train_dmm(sec_train_tagged)\n",
    "model_dmm_sec.save('model_dmm_sec')\n",
    "y_train_sec, X_train_sec = vec_for_learning(model_dmm_sec, sec_train_tagged)\n",
    "y_test_sec, X_test_sec = vec_for_learning(model_dmm_sec, sec_test_tagged)\n",
    "y_pred=logreg(X_train_sec,y_train_sec,X_test_sec,y_test_sec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing accuracy 0.4842105263157895\n",
      "Testing F1 score: 0.4937460337462026\n"
     ]
    }
   ],
   "source": [
    "#####second-dmm-test \"all_real_fake\"\n",
    "y_train_sec, X_train_sec = vec_for_learning(model_dmm_sec, sec_train_tagged)\n",
    "y_test, X_test = get_vectors(model_dmm_sec, test_tagged)\n",
    "logreg(X_train_sec,y_train_sec,X_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "index_list=[]\n",
    "for i in range(0,len(y_pred)):\n",
    "    if y_pred[i] != y_test_sec[i]:\n",
    "        index_list.append(i)\n",
    "    else:\n",
    "        continue\n",
    "false_det=[]\n",
    "for j in range(0,len(index_list)):\n",
    "    false_det.append(sec_test_tagged[index_list[j]])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[TaggedDocument(words=['但', '无人', '会想食', '完肚', '柯架'], tags=[0]),\n",
       " TaggedDocument(words=['不要', '吃', '到', '肚痛', '就'], tags=[1]),\n",
       " TaggedDocument(words=['其他', '食', '左', '鳗鱼', '饭', '嘅', '都', '肚', '屙', '到', '想', '死'], tags=[0]),\n",
       " TaggedDocument(words=['好容易', '肚痛'], tags=[1]),\n",
       " TaggedDocument(words=['最惊食', '完', '沙律', '会肚痛'], tags=[1]),\n",
       " TaggedDocument(words=['食', '完仲有', '小小', '肚痛'], tags=[0]),\n",
       " TaggedDocument(words=['觉得', '会肚痛'], tags=[1]),\n",
       " TaggedDocument(words=['惊会', '肚痛'], tags=[1]),\n",
       " TaggedDocument(words=['食甘耐', '嘢', '未试过', '甘样', '肚痛'], tags=[0]),\n",
       " TaggedDocument(words=['有点', '刺激', '又', '唔', '会', '肚痛'], tags=[1]),\n",
       " TaggedDocument(words=['最', '重要', '系', '唔', '会', '肚', '痾'], tags=[1])]"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "false_det"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing accuracy 0.847457627118644\n",
      "Testing F1 score: 0.847457627118644\n"
     ]
    }
   ],
   "source": [
    "new_model_sec=concat_model(model_dbow_sec,model_dmm_sec)\n",
    "y_train_new, X_train_new = get_vectors(new_model_sec, sec_train_tagged)\n",
    "y_test_new, X_test_new = get_vectors(new_model_sec, sec_test_tagged)\n",
    "y_pred=logreg(X_train_new,y_train_new,X_test_new,y_test_new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "index_list=[]\n",
    "for i in range(0,len(y_pred)):\n",
    "    if y_pred[i] != y_test_new[i]:\n",
    "        index_list.append(i)\n",
    "    else:\n",
    "        continue\n",
    "false_det=[]\n",
    "for j in range(0,len(index_list)):\n",
    "    false_det.append(sec_test_tagged[index_list[j]])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[TaggedDocument(words=['食', '咁', '多次', '都', '无肚泻'], tags=[1]),\n",
       " TaggedDocument(words=['但', '无人', '会想食', '完肚', '柯架'], tags=[0]),\n",
       " TaggedDocument(words=['不要', '吃', '到', '肚痛', '就'], tags=[1]),\n",
       " TaggedDocument(words=['而且', '一路', '食一落', '觉得', '自己', '会肚', '痾'], tags=[1]),\n",
       " TaggedDocument(words=['我们', '之後都', '冇', '肚痛', '的', '现象'], tags=[1]),\n",
       " TaggedDocument(words=['食', '完仲有', '小小', '肚痛'], tags=[0]),\n",
       " TaggedDocument(words=['一人', '肚泻', '呕吐'], tags=[0]),\n",
       " TaggedDocument(words=['食完', '肚疼'], tags=[0]),\n",
       " TaggedDocument(words=['食甘耐', '嘢', '未试过', '甘样', '肚痛'], tags=[0]),\n",
       " TaggedDocument(words=['食完', '第', '2', '日', '唔', '肚痛', '我', '已经', '好', '感恩'], tags=[1]),\n",
       " TaggedDocument(words=['但', '味道', '太', '一般般', '当晚', '返到', '屋企', '肚柯', '都', '冇', '谂', '过关', '餐饭', '事', '直到', '第二日', '奶奶', '话', '柯', '左', '几次'], tags=[0]),\n",
       " TaggedDocument(words=['但', '最', '重要', '都', '系食', '左', '冇', '肚泻'], tags=[1])]"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "false_det"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "######using all data to train Doc2Vec model:\n",
    "#lr = LogisticRegression(penalty='l2',solver='newton-cg',multi_class='multinomial')\n",
    "\n",
    "kl_review = pd.read_csv('kl_reviews_cn.csv',encoding='utf-8',low_memory=False)\n",
    "hki_review = pd.read_csv('hki_reviews_cn.csv',encoding='utf-8',low_memory=False)\n",
    "nt_review = pd.read_csv('nt_reviews_cn.csv',encoding='utf-8',low_memory=False)\n",
    "oi_review = pd.read_csv('oi_reviews_cn.csv',encoding='utf-8',low_memory=False)\n",
    "\n",
    "all_review = pd.concat([kl_review,hki_review,nt_review,oi_review])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "all_review.dropna(subset=['rev_cmt'])\n",
    "## detect the language function\n",
    "def language_detect(s):\n",
    "    if bool(re.match('^(?=.*[a-zA-Z])', s))  == False:\n",
    "        language_output='NA'\n",
    "    else:\n",
    "        language = langdetect.detect(s)\n",
    "        if language == 'en':\n",
    "            language_output = 'en'\n",
    "        else:\n",
    "            if hanzidentifier.is_simplified(s):\n",
    "                language_output = 's_cn'\n",
    "            else:\n",
    "                language_output = 't_cn'\n",
    "    return language_output\n",
    "\n",
    "all_review['language'] = all_review['rev_cmt'].apply(language_detect)\n",
    "\n",
    "### segment the dataframe according to the language\n",
    "all_review_en = all_review.loc[all_review['language'] == 'en']\n",
    "all_review_s_cn = all_review.loc[(all_review['language'] == 's_cn')]\n",
    "all_review_t_cn = all_review.loc[(all_review['language'] == 't_cn')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-161-d4c0f62fe78f>:20: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  all_review_t_cn['clean_rev_cmt'] = all_review_t_cn['rev_cmt'].apply(remove_punctuation)\n",
      "<ipython-input-161-d4c0f62fe78f>:21: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  all_review_t_cn['clean_rev_cmt'] = all_review_t_cn['rev_cmt'].apply(remove_punctuation)\n",
      "<ipython-input-161-d4c0f62fe78f>:23: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  all_review_t_cn['cut_review'] = all_review_t_cn['clean_rev_cmt'].apply(lambda x: \" \".join([w for w in list(cantoseg.cut(x))]))\n",
      "<ipython-input-161-d4c0f62fe78f>:24: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  all_review_t_cn['cut_review'] = all_review_t_cn['clean_rev_cmt'].apply(lambda x: \" \".join([w for w in list(cantoseg.cut(x))]))\n"
     ]
    }
   ],
   "source": [
    "#### 定义删除除字母,数字，汉字以外的所有符号的function\n",
    "def remove_punctuation(line):\n",
    "    line = str(line)\n",
    "    if line.strip()=='':\n",
    "        return ''\n",
    "    rule = re.compile(u\"[^a-zA-Z0-9\\u4E00-\\u9FA5]\")\n",
    "    line = rule.sub('',line)\n",
    "    return line\n",
    "\"\"\"\n",
    "#### simplified chinese\n",
    "#### clean comments\n",
    "all_review_s_cn['clean_rev_cmt'] = all_review_s_cn['rev_cmt'].apply(remove_punctuation)\n",
    "all_review_s_cn['clean_rev_cmt'] = all_review_s_cn['rev_cmt'].apply(remove_punctuation)\n",
    "#### segment word\n",
    "all_review_s_cn['cut_review'] = all_review_s_cn['clean_rev_cmt'].apply(lambda x: \" \".join([w for w in list(jieba.cut(x))]))\n",
    "all_review_s_cn['cut_review'] = all_review_s_cn['clean_rev_cmt'].apply(lambda x: \" \".join([w for w in list(jieba.cut(x))]))\n",
    "\"\"\"\n",
    "#### cantonese\n",
    "#### clean comments\n",
    "all_review_t_cn['clean_rev_cmt'] = all_review_t_cn['rev_cmt'].apply(remove_punctuation)\n",
    "all_review_t_cn['clean_rev_cmt'] = all_review_t_cn['rev_cmt'].apply(remove_punctuation)\n",
    "#### segment word\n",
    "all_review_t_cn['cut_review'] = all_review_t_cn['clean_rev_cmt'].apply(lambda x: \" \".join([w for w in list(cantoseg.cut(x))]))\n",
    "all_review_t_cn['cut_review'] = all_review_t_cn['clean_rev_cmt'].apply(lambda x: \" \".join([w for w in list(cantoseg.cut(x))]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(399438, 18)"
      ]
     },
     "execution_count": 167,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_review_t_cn.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(361604, 18)"
      ]
     },
     "execution_count": 163,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_review_s_cn.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(43643, 16)"
      ]
     },
     "execution_count": 164,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_review_en.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_review_cn=all_review_t_cn.append(all_review_s_cn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_review_cn.index=range((all_review_cn.shape)[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review_id</th>\n",
       "      <th>rtr_id</th>\n",
       "      <th>usr_id</th>\n",
       "      <th>usr_name</th>\n",
       "      <th>usr_num_cmt</th>\n",
       "      <th>usr_date_publish</th>\n",
       "      <th>usr_score_taste</th>\n",
       "      <th>usr_score_decor</th>\n",
       "      <th>usr_score_service</th>\n",
       "      <th>usr_score_hygiene</th>\n",
       "      <th>usr_score_value</th>\n",
       "      <th>usr_date_visit</th>\n",
       "      <th>usr_eat_way</th>\n",
       "      <th>usr_per_price</th>\n",
       "      <th>rev_cmt</th>\n",
       "      <th>language</th>\n",
       "      <th>clean_rev_cmt</th>\n",
       "      <th>cut_review</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>100051</td>\n",
       "      <td>4014</td>\n",
       "      <td>20109</td>\n",
       "      <td>美食焚化炉</td>\n",
       "      <td>2.4K</td>\n",
       "      <td>2006-03-18</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>$110</td>\n",
       "      <td>原本一个二人(6/3)饭局,点知一个下午,变成五人网聚,论地点唔难搵,但门面就唔及红磡店,不...</td>\n",
       "      <td>t_cn</td>\n",
       "      <td>原本一个二人63饭局点知一个下午变成五人网聚论地点唔难搵但门面就唔及红磡店不过笔者食野求好味...</td>\n",
       "      <td>原本 一个 二人 63 饭局 点 知 一个 下午 变成 五 人 网聚 论 地点 唔 难 搵 ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>100176</td>\n",
       "      <td>3119</td>\n",
       "      <td>23980</td>\n",
       "      <td>Raymond 仔</td>\n",
       "      <td>307</td>\n",
       "      <td>2006-03-19</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>$40</td>\n",
       "      <td>20060312 1530久闻这间荣华的上海菜出名,虽然个\"朶\"唔及另一同名食肆响,但我对佢...</td>\n",
       "      <td>t_cn</td>\n",
       "      <td>200603121530久闻这间荣华的上海菜出名虽然个朶唔及另一同名食肆响但我对佢有兴趣多o...</td>\n",
       "      <td>200603 121 530 久闻 这 间 荣华 的 上海 菜 出名 虽然 个 朶 唔 及 ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   review_id  rtr_id  usr_id   usr_name usr_num_cmt usr_date_publish  \\\n",
       "0     100051    4014   20109      美食焚化炉        2.4K       2006-03-18   \n",
       "1     100176    3119   23980  Raymond 仔         307       2006-03-19   \n",
       "\n",
       "  usr_score_taste usr_score_decor usr_score_service usr_score_hygiene  \\\n",
       "0               4               2                 4                 3   \n",
       "1               5               3                 4                 3   \n",
       "\n",
       "  usr_score_value usr_date_visit usr_eat_way usr_per_price  \\\n",
       "0               4           None        None         $110    \n",
       "1               5           None        None          $40    \n",
       "\n",
       "                                             rev_cmt language  \\\n",
       "0  原本一个二人(6/3)饭局,点知一个下午,变成五人网聚,论地点唔难搵,但门面就唔及红磡店,不...     t_cn   \n",
       "1  20060312 1530久闻这间荣华的上海菜出名,虽然个\"朶\"唔及另一同名食肆响,但我对佢...     t_cn   \n",
       "\n",
       "                                       clean_rev_cmt  \\\n",
       "0  原本一个二人63饭局点知一个下午变成五人网聚论地点唔难搵但门面就唔及红磡店不过笔者食野求好味...   \n",
       "1  200603121530久闻这间荣华的上海菜出名虽然个朶唔及另一同名食肆响但我对佢有兴趣多o...   \n",
       "\n",
       "                                          cut_review  \n",
       "0  原本 一个 二人 63 饭局 点 知 一个 下午 变成 五 人 网聚 论 地点 唔 难 搵 ...  \n",
       "1  200603 121 530 久闻 这 间 荣华 的 上海 菜 出名 虽然 个 朶 唔 及 ...  "
      ]
     },
     "execution_count": 193,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_review_cn.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [],
   "source": [
    "cn_symptom_train = pd.read_csv('all_real_fake_symptom_train.csv')\n",
    "cn_symptom_test = pd.read_csv('all_real_fake_symptom_test.csv')\n",
    "cn_symptom = pd.concat([cn_symptom_train,cn_symptom_test], ignore_index=True)\n",
    "cn_symptom.index=range((cn_symptom.shape)[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1686, 29)"
      ]
     },
     "execution_count": 178,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cn_symptom.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review_id</th>\n",
       "      <th>rtr_id</th>\n",
       "      <th>usr_id</th>\n",
       "      <th>usr_name</th>\n",
       "      <th>usr_num_cmt</th>\n",
       "      <th>usr_date_publish</th>\n",
       "      <th>usr_score_taste</th>\n",
       "      <th>usr_score_decor</th>\n",
       "      <th>usr_score_service</th>\n",
       "      <th>usr_score_hygiene</th>\n",
       "      <th>...</th>\n",
       "      <th>language</th>\n",
       "      <th>clean_rev_cmt</th>\n",
       "      <th>cut_review</th>\n",
       "      <th>label</th>\n",
       "      <th>sympt_count</th>\n",
       "      <th>tend_count</th>\n",
       "      <th>m_usr_score_hygiene</th>\n",
       "      <th>m_usr_score_value</th>\n",
       "      <th>score_hygiene_diff</th>\n",
       "      <th>score_value_diff</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2233930</td>\n",
       "      <td>37556</td>\n",
       "      <td>98626</td>\n",
       "      <td>VIANNAKIT</td>\n",
       "      <td>222</td>\n",
       "      <td>2012-05-04</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>s_cn</td>\n",
       "      <td>又来到我们最爱的平价饭堂哈哈这次点了两款没有吃过的菜式试试看第一款卡邦尼杂菌烩饭浓浓的卡邦尼...</td>\n",
       "      <td>又 来到 我们 最爱 的 平价 饭堂 哈哈 这次 点 了 两款 没有 吃 过 的 菜式 试试...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.617021</td>\n",
       "      <td>3.659574</td>\n",
       "      <td>-2.617021</td>\n",
       "      <td>0.340426</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2282733</td>\n",
       "      <td>211</td>\n",
       "      <td>593313</td>\n",
       "      <td>water姐</td>\n",
       "      <td>2</td>\n",
       "      <td>2013-02-05</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>s_cn</td>\n",
       "      <td>见佢张poster写26810再有85折咁平既自助晚餐一於同朋友试试其实咁既价钱预左唔会有太...</td>\n",
       "      <td>见 佢 张 poster 写 26810 再有 85 折 咁 平 既 自助 晚餐 一 於 同...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>-2.000000</td>\n",
       "      <td>-2.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows × 29 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  review_id rtr_id  usr_id   usr_name usr_num_cmt usr_date_publish  \\\n",
       "0   2233930  37556   98626  VIANNAKIT         222       2012-05-04   \n",
       "1   2282733    211  593313     water姐           2       2013-02-05   \n",
       "\n",
       "  usr_score_taste usr_score_decor  usr_score_service  usr_score_hygiene  ...  \\\n",
       "0               4               3                  4                  1  ...   \n",
       "1               1               1                  3                  1  ...   \n",
       "\n",
       "   language                                      clean_rev_cmt  \\\n",
       "0      s_cn  又来到我们最爱的平价饭堂哈哈这次点了两款没有吃过的菜式试试看第一款卡邦尼杂菌烩饭浓浓的卡邦尼...   \n",
       "1      s_cn  见佢张poster写26810再有85折咁平既自助晚餐一於同朋友试试其实咁既价钱预左唔会有太...   \n",
       "\n",
       "                                          cut_review label sympt_count  \\\n",
       "0  又 来到 我们 最爱 的 平价 饭堂 哈哈 这次 点 了 两款 没有 吃 过 的 菜式 试试...   0.0         3.0   \n",
       "1  见 佢 张 poster 写 26810 再有 85 折 咁 平 既 自助 晚餐 一 於 同...   0.0         3.0   \n",
       "\n",
       "  tend_count m_usr_score_hygiene m_usr_score_value  score_hygiene_diff  \\\n",
       "0        0.0            3.617021          3.659574           -2.617021   \n",
       "1        3.0            3.000000          3.000000           -2.000000   \n",
       "\n",
       "  score_value_diff  \n",
       "0         0.340426  \n",
       "1        -2.000000  \n",
       "\n",
       "[2 rows x 29 columns]"
      ]
     },
     "execution_count": 181,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cn_symptom.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [],
   "source": [
    "del_id = cn_symptom['usr_id'].values.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "all_review_cn3=all_review_cn[~all_review_cn['usr_id'].isin(del_id)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(741042, 18)"
      ]
     },
     "execution_count": 198,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_review_cn3.shape#original:761042"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [],
   "source": [
    "##now is the eng data.\n",
    "real_eng_symptom = pd.read_csv('eng_real_symptom_final.csv')\n",
    "fake_eng_symptom = pd.read_csv('eng_fake_symptom_final.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [],
   "source": [
    "eng_symptom = real_eng_symptom.append(fake_eng_symptom)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [],
   "source": [
    "del_eng_id= eng_symptom['usr_id'].values.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_review_en3 = all_review_en[~all_review_en['usr_id'].isin(del_eng_id)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review_id</th>\n",
       "      <th>rtr_id</th>\n",
       "      <th>usr_id</th>\n",
       "      <th>usr_name</th>\n",
       "      <th>usr_num_cmt</th>\n",
       "      <th>usr_date_publish</th>\n",
       "      <th>usr_score_taste</th>\n",
       "      <th>usr_score_decor</th>\n",
       "      <th>usr_score_service</th>\n",
       "      <th>usr_score_hygiene</th>\n",
       "      <th>usr_score_value</th>\n",
       "      <th>usr_date_visit</th>\n",
       "      <th>usr_eat_way</th>\n",
       "      <th>usr_per_price</th>\n",
       "      <th>rev_cmt</th>\n",
       "      <th>language</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>110814</td>\n",
       "      <td>574</td>\n",
       "      <td>32456</td>\n",
       "      <td>zoolook</td>\n",
       "      <td>178</td>\n",
       "      <td>2006-06-11</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>$210</td>\n",
       "      <td>次次黎食都系肉眼扒+凯撒鸡沙拉(虽然d鸡肉好鬼鞋)+molten chocolate cak...</td>\n",
       "      <td>en</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>111547</td>\n",
       "      <td>12751</td>\n",
       "      <td>37105</td>\n",
       "      <td>am418</td>\n",
       "      <td>2</td>\n",
       "      <td>2006-06-17</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>$26</td>\n",
       "      <td>Won't be go there again forever......Went ther...</td>\n",
       "      <td>en</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   review_id  rtr_id  usr_id usr_name usr_num_cmt usr_date_publish  \\\n",
       "0     110814     574   32456  zoolook         178       2006-06-11   \n",
       "1     111547   12751   37105    am418           2       2006-06-17   \n",
       "\n",
       "  usr_score_taste usr_score_decor usr_score_service usr_score_hygiene  \\\n",
       "0               5               5                 4                 5   \n",
       "1               2               1                 1                 1   \n",
       "\n",
       "  usr_score_value usr_date_visit usr_eat_way usr_per_price  \\\n",
       "0               3           None        None         $210    \n",
       "1               1           None        None          $26    \n",
       "\n",
       "                                             rev_cmt language  \n",
       "0  次次黎食都系肉眼扒+凯撒鸡沙拉(虽然d鸡肉好鬼鞋)+molten chocolate cak...       en  \n",
       "1  Won't be go there again forever......Went ther...       en  "
      ]
     },
     "execution_count": 214,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "##need to segment the all_review_en3 and label all three frames \n",
    "all_review_en3.index=range((all_review_en3.shape)[0])\n",
    "all_review_en3.head(2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 297,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 对于英文的评论1. remove punctuation(eng) + lower 2. canseg to segment 3. remove the \" \" 4. label\n",
    "# 5. send with other reviews to doc2vec \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 290,
   "metadata": {},
   "outputs": [],
   "source": [
    "import string\n",
    "def eng_remove_punctuation(text):\n",
    "    remove = str.maketrans('','',string.punctuation) \n",
    "    without_punctuation = text.translate(remove)\n",
    "    return without_punctuation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 291,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-291-a14e60ad31b1>:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  all_review_en3['clean_rev_cmt'] = all_review_en3['rev_cmt'].apply(eng_remove_punctuation)\n",
      "<ipython-input-291-a14e60ad31b1>:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  all_review_en3['cut_review'] = all_review_en3['clean_rev_cmt'].apply(lambda x: \" \".join([w for w in list(word_tokenize(x))]))\n"
     ]
    }
   ],
   "source": [
    "#如果中英文掺杂，先去标点符号，转小写，分割，去空格\n",
    "#整个英文文档，去标点符号，转小写，nltk分词，\n",
    "\n",
    "all_review_en3['clean_rev_cmt'] = all_review_en3['rev_cmt'].apply(eng_remove_punctuation)\n",
    "all_review_en3['cut_review'] = all_review_en3['clean_rev_cmt'].apply(lambda x: \" \".join([w for w in list(word_tokenize(x))]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 292,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(35470, 18)"
      ]
     },
     "execution_count": 292,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_review_en3.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 293,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review_id</th>\n",
       "      <th>rtr_id</th>\n",
       "      <th>usr_id</th>\n",
       "      <th>usr_name</th>\n",
       "      <th>usr_num_cmt</th>\n",
       "      <th>usr_date_publish</th>\n",
       "      <th>usr_score_taste</th>\n",
       "      <th>usr_score_decor</th>\n",
       "      <th>usr_score_service</th>\n",
       "      <th>usr_score_hygiene</th>\n",
       "      <th>usr_score_value</th>\n",
       "      <th>usr_date_visit</th>\n",
       "      <th>usr_eat_way</th>\n",
       "      <th>usr_per_price</th>\n",
       "      <th>rev_cmt</th>\n",
       "      <th>language</th>\n",
       "      <th>clean_rev_cmt</th>\n",
       "      <th>cut_review</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>110814</td>\n",
       "      <td>574</td>\n",
       "      <td>32456</td>\n",
       "      <td>zoolook</td>\n",
       "      <td>178</td>\n",
       "      <td>2006-06-11</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>$210</td>\n",
       "      <td>次次黎食都系肉眼扒+凯撒鸡沙拉(虽然d鸡肉好鬼鞋)+molten chocolate cak...</td>\n",
       "      <td>en</td>\n",
       "      <td>次次黎食都系肉眼扒凯撒鸡沙拉虽然d鸡肉好鬼鞋molten chocolate cake这是无...</td>\n",
       "      <td>次次黎食都系肉眼扒凯撒鸡沙拉虽然d鸡肉好鬼鞋molten chocolate cake这是无...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>111547</td>\n",
       "      <td>12751</td>\n",
       "      <td>37105</td>\n",
       "      <td>am418</td>\n",
       "      <td>2</td>\n",
       "      <td>2006-06-17</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>$26</td>\n",
       "      <td>Won't be go there again forever......Went ther...</td>\n",
       "      <td>en</td>\n",
       "      <td>Wont be go there again foreverWent there last ...</td>\n",
       "      <td>Wont be go there again foreverWent there last ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   review_id  rtr_id  usr_id usr_name usr_num_cmt usr_date_publish  \\\n",
       "0     110814     574   32456  zoolook         178       2006-06-11   \n",
       "1     111547   12751   37105    am418           2       2006-06-17   \n",
       "\n",
       "  usr_score_taste usr_score_decor usr_score_service usr_score_hygiene  \\\n",
       "0               5               5                 4                 5   \n",
       "1               2               1                 1                 1   \n",
       "\n",
       "  usr_score_value usr_date_visit usr_eat_way usr_per_price  \\\n",
       "0               3           None        None         $210    \n",
       "1               1           None        None          $26    \n",
       "\n",
       "                                             rev_cmt language  \\\n",
       "0  次次黎食都系肉眼扒+凯撒鸡沙拉(虽然d鸡肉好鬼鞋)+molten chocolate cak...       en   \n",
       "1  Won't be go there again forever......Went ther...       en   \n",
       "\n",
       "                                       clean_rev_cmt  \\\n",
       "0  次次黎食都系肉眼扒凯撒鸡沙拉虽然d鸡肉好鬼鞋molten chocolate cake这是无...   \n",
       "1  Wont be go there again foreverWent there last ...   \n",
       "\n",
       "                                          cut_review  \n",
       "0  次次黎食都系肉眼扒凯撒鸡沙拉虽然d鸡肉好鬼鞋molten chocolate cake这是无...  \n",
       "1  Wont be go there again foreverWent there last ...  "
      ]
     },
     "execution_count": 293,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_review_en3.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 295,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wont be go there again foreverWent there last time i didnt expect its a good restaurant at lease it should fullfill a normal standardHowever this experience its really shit me out1 Very dirty the bench the table and the floor are full of grease with a very disgusting smell2 The food a not worth of this price 3 The taste is lower than normal standard I order 柱侯牛腩饭but it really di\n"
     ]
    }
   ],
   "source": [
    "print(all_review_en3.loc[1]['cut_review'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 298,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_review_final3=all_review_cn3.append(all_review_en3)\n",
    "all_review_final3.index=range((all_review_final3.shape)[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 305,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_review_final3['label']=2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 306,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(776512, 19)"
      ]
     },
     "execution_count": 306,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_review_final3.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 307,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review_id</th>\n",
       "      <th>rtr_id</th>\n",
       "      <th>usr_id</th>\n",
       "      <th>usr_name</th>\n",
       "      <th>usr_num_cmt</th>\n",
       "      <th>usr_date_publish</th>\n",
       "      <th>usr_score_taste</th>\n",
       "      <th>usr_score_decor</th>\n",
       "      <th>usr_score_service</th>\n",
       "      <th>usr_score_hygiene</th>\n",
       "      <th>usr_score_value</th>\n",
       "      <th>usr_date_visit</th>\n",
       "      <th>usr_eat_way</th>\n",
       "      <th>usr_per_price</th>\n",
       "      <th>rev_cmt</th>\n",
       "      <th>language</th>\n",
       "      <th>clean_rev_cmt</th>\n",
       "      <th>cut_review</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>100176</td>\n",
       "      <td>3119</td>\n",
       "      <td>23980</td>\n",
       "      <td>Raymond 仔</td>\n",
       "      <td>307</td>\n",
       "      <td>2006-03-19</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>$40</td>\n",
       "      <td>20060312 1530久闻这间荣华的上海菜出名,虽然个\"朶\"唔及另一同名食肆响,但我对佢...</td>\n",
       "      <td>t_cn</td>\n",
       "      <td>200603121530久闻这间荣华的上海菜出名虽然个朶唔及另一同名食肆响但我对佢有兴趣多o...</td>\n",
       "      <td>200603 121 530 久闻 这 间 荣华 的 上海 菜 出名 虽然 个 朶 唔 及 ...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>100196</td>\n",
       "      <td>3119</td>\n",
       "      <td>29112</td>\n",
       "      <td>landly</td>\n",
       "      <td>60</td>\n",
       "      <td>2006-03-19</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>$50</td>\n",
       "      <td>再去荣华食饭６个人，叫了两个３人餐有东坡肉，是甜甜的，也不太油腻，挺美味～炒三鲜，是虾，火腿...</td>\n",
       "      <td>t_cn</td>\n",
       "      <td>再去荣华食饭个人叫了两个人餐有东坡肉是甜甜的也不太油腻挺美味炒三鲜是虾火腿和肉时菜狮子头同茶...</td>\n",
       "      <td>再 去 荣华 食饭 个人 叫 了 两个 人餐 有 东坡肉 是 甜甜的 也 不 太 油腻 挺 ...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   review_id  rtr_id  usr_id   usr_name usr_num_cmt usr_date_publish  \\\n",
       "0     100176    3119   23980  Raymond 仔         307       2006-03-19   \n",
       "1     100196    3119   29112     landly          60       2006-03-19   \n",
       "\n",
       "  usr_score_taste usr_score_decor usr_score_service usr_score_hygiene  \\\n",
       "0               5               3                 4                 3   \n",
       "1               4               4                 5                 3   \n",
       "\n",
       "  usr_score_value usr_date_visit usr_eat_way usr_per_price  \\\n",
       "0               5           None        None          $40    \n",
       "1               4           None        None          $50    \n",
       "\n",
       "                                             rev_cmt language  \\\n",
       "0  20060312 1530久闻这间荣华的上海菜出名,虽然个\"朶\"唔及另一同名食肆响,但我对佢...     t_cn   \n",
       "1  再去荣华食饭６个人，叫了两个３人餐有东坡肉，是甜甜的，也不太油腻，挺美味～炒三鲜，是虾，火腿...     t_cn   \n",
       "\n",
       "                                       clean_rev_cmt  \\\n",
       "0  200603121530久闻这间荣华的上海菜出名虽然个朶唔及另一同名食肆响但我对佢有兴趣多o...   \n",
       "1  再去荣华食饭个人叫了两个人餐有东坡肉是甜甜的也不太油腻挺美味炒三鲜是虾火腿和肉时菜狮子头同茶...   \n",
       "\n",
       "                                          cut_review  label  \n",
       "0  200603 121 530 久闻 这 间 荣华 的 上海 菜 出名 虽然 个 朶 唔 及 ...      2  \n",
       "1  再 去 荣华 食饭 个人 叫 了 两个 人餐 有 东坡肉 是 甜甜的 也 不 太 油腻 挺 ...      2  "
      ]
     },
     "execution_count": 307,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_review_final3.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 308,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_3=all_review_final3[['cut_review','label']]\n",
    "df_3 = df_3[pd.notnull(df_3['cut_review'])]\n",
    "df_3 = df_3[pd.notnull(df_3['label'])]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 359,
   "metadata": {},
   "outputs": [],
   "source": [
    "df123=df_3.append(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 361,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "122945417"
      ]
     },
     "execution_count": 361,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_3['cut_review'].apply(lambda x: len(x.split(' '))).sum()\n",
    "df123['cut_review'].apply(lambda x: len(x.split(' '))).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 313,
   "metadata": {},
   "outputs": [],
   "source": [
    "df3_tagged = df123.apply(\n",
    "    lambda r: TaggedDocument(words=tokenize_text(r['cut_review']), tags=[r.label]), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 362,
   "metadata": {},
   "outputs": [],
   "source": [
    "df123_tagged = df123.apply(\n",
    "    lambda r: TaggedDocument(words=tokenize_text(r['cut_review']), tags=[r.label]), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 325,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TaggedDocument(words=['after', 'a', 'leisurely', 'hike', 'a', 'circular', 'route', 'which', 'takes', 'in', 'mo', 'tat', 'wan', 'yung', 'shue', 'ha', 'and', 'back', 'to', 'so', 'kwu', 'wan', 'we', 'decided', 'on', 'lunch', 'at', 'lamma', 'rainbow', 'a', 'long', 'established', 'restaurant', 'on', 'the', 'seafronta', 'good', 'crowd', 'of', 'people', 'eatingeven', 'during', 'lunch', 'with', 'a', 'lively', 'atmosphereyou', 'can', 'choose', 'seafood', 'from', 'the', 'fish', 'tanks', 'cooked', 'to', 'the', 'way', 'you', 'want', 'at', 'market', 'price', 'or', 'choose', 'from', 'the', 'a', 'la', 'carte', 'menu', 'we', 'opted', 'for', 'the', 'latterhot', 'favourites', 'for', 'this', 'place', 'include', 'sweet', 'sour', 'porkjuicy', 'chunks', 'of', 'pork'], tags=[2])"
      ]
     },
     "execution_count": 325,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df3_tagged.values[776401]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 326,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 776512/776512 [00:00<00:00, 2925253.38it/s]\n",
      "100%|██████████| 776512/776512 [00:00<00:00, 3310467.58it/s]\n",
      "100%|██████████| 776512/776512 [00:00<00:00, 3442214.93it/s]\n",
      "100%|██████████| 776512/776512 [00:00<00:00, 3476607.25it/s]\n",
      "100%|██████████| 776512/776512 [00:00<00:00, 3399261.25it/s]\n",
      "100%|██████████| 776512/776512 [00:00<00:00, 3374666.11it/s]\n",
      "100%|██████████| 776512/776512 [00:00<00:00, 3411105.97it/s]\n",
      "100%|██████████| 776512/776512 [00:00<00:00, 3380434.96it/s]\n",
      "100%|██████████| 776512/776512 [00:00<00:00, 3174424.11it/s]\n",
      "100%|██████████| 776512/776512 [00:00<00:00, 3373715.29it/s]\n",
      "100%|██████████| 776512/776512 [00:00<00:00, 3416946.40it/s]\n",
      "100%|██████████| 776512/776512 [00:00<00:00, 3351651.77it/s]\n",
      "100%|██████████| 776512/776512 [00:00<00:00, 3274445.67it/s]\n",
      "100%|██████████| 776512/776512 [00:00<00:00, 3369185.27it/s]\n",
      "100%|██████████| 776512/776512 [00:00<00:00, 3434700.62it/s]\n",
      "100%|██████████| 776512/776512 [00:00<00:00, 3345832.86it/s]\n",
      "100%|██████████| 776512/776512 [00:00<00:00, 3327167.21it/s]\n",
      "100%|██████████| 776512/776512 [00:00<00:00, 3363826.43it/s]\n",
      "100%|██████████| 776512/776512 [00:00<00:00, 3427334.46it/s]\n",
      "100%|██████████| 776512/776512 [00:00<00:00, 3380368.30it/s]\n",
      "100%|██████████| 776512/776512 [00:00<00:00, 3445415.75it/s]\n",
      "100%|██████████| 776512/776512 [00:00<00:00, 3432868.78it/s]\n",
      "100%|██████████| 776512/776512 [00:00<00:00, 3330457.22it/s]\n",
      "100%|██████████| 776512/776512 [00:00<00:00, 3397006.34it/s]\n",
      "100%|██████████| 776512/776512 [00:00<00:00, 3441792.97it/s]\n",
      "100%|██████████| 776512/776512 [00:00<00:00, 3411534.73it/s]\n",
      "100%|██████████| 776512/776512 [00:00<00:00, 3384583.73it/s]\n",
      "100%|██████████| 776512/776512 [00:00<00:00, 3368317.65it/s]\n",
      "100%|██████████| 776512/776512 [00:00<00:00, 3404537.94it/s]\n",
      "100%|██████████| 776512/776512 [00:00<00:00, 3318694.94it/s]\n",
      "100%|██████████| 776512/776512 [00:00<00:00, 3379877.18it/s]\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'model_dbow_def' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-326-010092405c7c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mmodel_dbow_df3\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrain_dbow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf3_tagged\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mmodel_dbow_def\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'model_dbow_all_reviews'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'model_dbow_def' is not defined"
     ]
    }
   ],
   "source": [
    "model_dbow_df3=train_dbow(df3_tagged)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 327,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_dbow_df3.save('model_dbow_all_reviews')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 363,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 777911/777911 [00:00<00:00, 2881747.51it/s]\n",
      "100%|██████████| 777911/777911 [00:00<00:00, 3410557.63it/s]\n",
      "100%|██████████| 777911/777911 [00:00<00:00, 3413658.44it/s]\n",
      "100%|██████████| 777911/777911 [00:00<00:00, 3278522.29it/s]\n",
      "100%|██████████| 777911/777911 [00:00<00:00, 3331752.50it/s]\n",
      "100%|██████████| 777911/777911 [00:00<00:00, 3322459.95it/s]\n",
      "100%|██████████| 777911/777911 [00:00<00:00, 3327501.82it/s]\n",
      "100%|██████████| 777911/777911 [00:00<00:00, 3482041.99it/s]\n",
      "100%|██████████| 777911/777911 [00:00<00:00, 3375698.84it/s]\n",
      "100%|██████████| 777911/777911 [00:00<00:00, 3426539.25it/s]\n",
      "100%|██████████| 777911/777911 [00:00<00:00, 3372439.99it/s]\n",
      "100%|██████████| 777911/777911 [00:00<00:00, 3338058.42it/s]\n",
      "100%|██████████| 777911/777911 [00:00<00:00, 3264267.40it/s]\n",
      "100%|██████████| 777911/777911 [00:00<00:00, 3227556.75it/s]\n",
      "100%|██████████| 777911/777911 [00:00<00:00, 3278512.41it/s]\n",
      "100%|██████████| 777911/777911 [00:00<00:00, 3294850.82it/s]\n",
      "100%|██████████| 777911/777911 [00:00<00:00, 3331915.81it/s]\n",
      "100%|██████████| 777911/777911 [00:00<00:00, 2996573.62it/s]\n",
      "100%|██████████| 777911/777911 [00:00<00:00, 3354638.51it/s]\n",
      "100%|██████████| 777911/777911 [00:00<00:00, 3169741.13it/s]\n",
      "100%|██████████| 777911/777911 [00:00<00:00, 3074862.69it/s]\n",
      "100%|██████████| 777911/777911 [00:00<00:00, 3058875.30it/s]\n",
      "100%|██████████| 777911/777911 [00:00<00:00, 3252264.39it/s]\n",
      "100%|██████████| 777911/777911 [00:00<00:00, 2959829.98it/s]\n",
      "100%|██████████| 777911/777911 [00:00<00:00, 3097364.96it/s]\n",
      "100%|██████████| 777911/777911 [00:00<00:00, 2958037.49it/s]\n",
      "100%|██████████| 777911/777911 [00:00<00:00, 3140981.67it/s]\n",
      "100%|██████████| 777911/777911 [00:00<00:00, 3098835.82it/s]\n",
      "100%|██████████| 777911/777911 [00:00<00:00, 3089873.54it/s]\n",
      "100%|██████████| 777911/777911 [00:00<00:00, 3281021.29it/s]\n"
     ]
    }
   ],
   "source": [
    "model_dbow_df123=train_dbow(df123_tagged)\n",
    "model_dbow_df123.save('model_dbow_all_reviews_123')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 518,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 777911/777911 [00:00<00:00, 1805242.46it/s]\n",
      "100%|██████████| 777911/777911 [00:00<00:00, 3195194.49it/s]\n",
      "100%|██████████| 777911/777911 [00:00<00:00, 3154446.30it/s]\n",
      "100%|██████████| 777911/777911 [00:00<00:00, 3157162.86it/s]\n",
      "100%|██████████| 777911/777911 [00:00<00:00, 3110498.97it/s]\n",
      "100%|██████████| 777911/777911 [00:00<00:00, 3262054.73it/s]\n",
      "100%|██████████| 777911/777911 [00:00<00:00, 3335806.00it/s]\n",
      "100%|██████████| 777911/777911 [00:00<00:00, 3300022.78it/s]\n",
      "100%|██████████| 777911/777911 [00:00<00:00, 3296019.09it/s]\n",
      "100%|██████████| 777911/777911 [00:00<00:00, 3225629.52it/s]\n",
      "100%|██████████| 777911/777911 [00:00<00:00, 3328971.85it/s]\n",
      "100%|██████████| 777911/777911 [00:00<00:00, 3132219.26it/s]\n",
      "100%|██████████| 777911/777911 [00:00<00:00, 3302116.83it/s]\n",
      "100%|██████████| 777911/777911 [00:00<00:00, 3213408.35it/s]\n",
      "100%|██████████| 777911/777911 [00:00<00:00, 3218007.00it/s]\n",
      "100%|██████████| 777911/777911 [00:00<00:00, 3230886.98it/s]\n",
      "100%|██████████| 777911/777911 [00:00<00:00, 3273039.83it/s]\n",
      "100%|██████████| 777911/777911 [00:00<00:00, 3191775.03it/s]\n",
      "100%|██████████| 777911/777911 [00:00<00:00, 3117983.59it/s]\n",
      "100%|██████████| 777911/777911 [00:00<00:00, 3107921.29it/s]\n",
      "100%|██████████| 777911/777911 [00:00<00:00, 3162702.03it/s]\n",
      "100%|██████████| 777911/777911 [00:00<00:00, 3323749.46it/s]\n",
      "100%|██████████| 777911/777911 [00:00<00:00, 3174499.68it/s]\n",
      "100%|██████████| 777911/777911 [00:00<00:00, 3308374.70it/s]\n",
      "100%|██████████| 777911/777911 [00:00<00:00, 3077882.21it/s]\n",
      "100%|██████████| 777911/777911 [00:00<00:00, 3263137.85it/s]\n",
      "100%|██████████| 777911/777911 [00:00<00:00, 3174987.76it/s]\n",
      "100%|██████████| 777911/777911 [00:00<00:00, 3182171.72it/s]\n",
      "100%|██████████| 777911/777911 [00:00<00:00, 3346034.52it/s]\n",
      "100%|██████████| 777911/777911 [00:00<00:00, 3255051.45it/s]\n",
      "100%|██████████| 777911/777911 [00:00<00:00, 3261689.51it/s]\n"
     ]
    }
   ],
   "source": [
    "model_dmm_df123=train_dmm(df123_tagged)\n",
    "model_dmm_df123.save('model_dmm_all_reviews_123')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 521,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing accuracy 0.712280701754386\n",
      "Testing F1 score: 0.7142744922006508\n",
      "Area Under Curve: 0.6562837919019584\n",
      "Recall score: [0.52439024 0.78817734]\n"
     ]
    }
   ],
   "source": [
    "y_train, X_train = vec_for_learning(model_dmm_df123, train_tagged)\n",
    "y_test, X_test = vec_for_learning(model_dmm_df123,test_tagged)\n",
    "logreg(X_train,y_train,X_test,y_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 580,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing accuracy 0.777262180974478\n",
      "Testing F1 score: 0.7694847498821139\n",
      "Area Under Curve: 0.642780478565566\n",
      "Recall score: [0.40425532 0.88130564]\n"
     ]
    }
   ],
   "source": [
    "####test the two csv data with eng reviews\n",
    "y_train, X_train = vec_for_learning(model_dmm_df123, df_en_tagged)\n",
    "y_test, X_test = vec_for_learning(model_dmm_df123,df_test_en_tagged)\n",
    "logreg(X_train,y_train,X_test,y_test)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 583,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing accuracy 0.6960556844547564\n",
      "Testing F1 score: 0.7115838332380247\n",
      "Area Under Curve: 0.621535450470358\n",
      "Recall score: [0.4893617 0.7537092]\n"
     ]
    }
   ],
   "source": [
    "##test the concat model for both chi reviews and eng reviews\n",
    "new_model_123=concat_model(model_dbow_df123,model_dmm_df123)\n",
    "\n",
    "y_train, X_train = get_vectors(new_model_123, df_en_tagged)\n",
    "y_test, X_test = get_vectors(new_model_123,df_test_en_tagged)\n",
    "logreg(X_train,y_train,X_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 586,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing accuracy 0.6947368421052632\n",
      "Testing F1 score: 0.6963425115291163\n",
      "Area Under Curve: 0.633065000600745\n",
      "Recall score: [0.48780488 0.77832512]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "y_train, X_train = get_vectors(new_model_123, train_tagged)\n",
    "y_test, X_test = get_vectors(new_model_123,test_tagged)\n",
    "logreg(X_train,y_train,X_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 587,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1545/1545 [00:00<00:00, 839730.42it/s]\n",
      "100%|██████████| 1545/1545 [00:00<00:00, 3200098.61it/s]\n",
      "100%|██████████| 1545/1545 [00:00<00:00, 1674037.63it/s]\n",
      "100%|██████████| 1545/1545 [00:00<00:00, 1130727.57it/s]\n",
      "100%|██████████| 1545/1545 [00:00<00:00, 1113436.37it/s]\n",
      "100%|██████████| 1545/1545 [00:00<00:00, 1376130.75it/s]\n",
      "100%|██████████| 1545/1545 [00:00<00:00, 2763411.38it/s]\n",
      "100%|██████████| 1545/1545 [00:00<00:00, 2609826.69it/s]\n",
      "100%|██████████| 1545/1545 [00:00<00:00, 1026810.28it/s]\n",
      "100%|██████████| 1545/1545 [00:00<00:00, 1578611.37it/s]\n",
      "100%|██████████| 1545/1545 [00:00<00:00, 3269525.57it/s]\n",
      "100%|██████████| 1545/1545 [00:00<00:00, 1265911.25it/s]\n",
      "100%|██████████| 1545/1545 [00:00<00:00, 1151012.38it/s]\n",
      "100%|██████████| 1545/1545 [00:00<00:00, 1117661.21it/s]\n",
      "100%|██████████| 1545/1545 [00:00<00:00, 1710266.48it/s]\n",
      "100%|██████████| 1545/1545 [00:00<00:00, 1714338.54it/s]\n",
      "100%|██████████| 1545/1545 [00:00<00:00, 1666289.45it/s]\n",
      "100%|██████████| 1545/1545 [00:00<00:00, 1721168.57it/s]\n",
      "100%|██████████| 1545/1545 [00:00<00:00, 1846210.74it/s]\n",
      "100%|██████████| 1545/1545 [00:00<00:00, 3090223.98it/s]\n",
      "100%|██████████| 1545/1545 [00:00<00:00, 3139631.63it/s]\n",
      "100%|██████████| 1545/1545 [00:00<00:00, 2714788.30it/s]\n",
      "100%|██████████| 1545/1545 [00:00<00:00, 1904820.60it/s]\n",
      "100%|██████████| 1545/1545 [00:00<00:00, 2780008.44it/s]\n",
      "100%|██████████| 1545/1545 [00:00<00:00, 3007053.22it/s]\n",
      "100%|██████████| 1545/1545 [00:00<00:00, 3056697.96it/s]\n",
      "100%|██████████| 1545/1545 [00:00<00:00, 2036517.81it/s]\n",
      "100%|██████████| 1545/1545 [00:00<00:00, 1841488.97it/s]\n",
      "100%|██████████| 1545/1545 [00:00<00:00, 1659037.30it/s]\n",
      "100%|██████████| 1545/1545 [00:00<00:00, 1476463.81it/s]\n",
      "100%|██████████| 1545/1545 [00:00<00:00, 1197597.43it/s]\n",
      "100%|██████████| 1545/1545 [00:00<00:00, 2837215.27it/s]\n",
      "100%|██████████| 1545/1545 [00:00<00:00, 3206432.30it/s]\n",
      "100%|██████████| 1545/1545 [00:00<00:00, 1135283.76it/s]\n",
      "100%|██████████| 1545/1545 [00:00<00:00, 1328999.11it/s]\n",
      "100%|██████████| 1545/1545 [00:00<00:00, 1124449.02it/s]\n",
      "100%|██████████| 1545/1545 [00:00<00:00, 1098152.80it/s]\n",
      "100%|██████████| 1545/1545 [00:00<00:00, 1109433.26it/s]\n",
      "100%|██████████| 1545/1545 [00:00<00:00, 1125620.93it/s]\n",
      "100%|██████████| 1545/1545 [00:00<00:00, 1129741.92it/s]\n",
      "100%|██████████| 1545/1545 [00:00<00:00, 1112480.63it/s]\n",
      "100%|██████████| 1545/1545 [00:00<00:00, 1124253.93it/s]\n",
      "100%|██████████| 1545/1545 [00:00<00:00, 1026322.41it/s]\n",
      "100%|██████████| 1545/1545 [00:00<00:00, 1137276.18it/s]\n",
      "100%|██████████| 1545/1545 [00:00<00:00, 1392692.82it/s]\n",
      "100%|██████████| 1545/1545 [00:00<00:00, 1100390.50it/s]\n",
      "100%|██████████| 1545/1545 [00:00<00:00, 1094073.89it/s]\n",
      "100%|██████████| 1545/1545 [00:00<00:00, 1108863.74it/s]\n",
      "100%|██████████| 1545/1545 [00:00<00:00, 1102637.35it/s]\n",
      "100%|██████████| 1545/1545 [00:00<00:00, 1093151.09it/s]\n",
      "100%|██████████| 1545/1545 [00:00<00:00, 1074303.66it/s]\n",
      "100%|██████████| 1545/1545 [00:00<00:00, 1126012.11it/s]\n",
      "100%|██████████| 1545/1545 [00:00<00:00, 1125425.44it/s]\n",
      "100%|██████████| 1545/1545 [00:00<00:00, 1105270.28it/s]\n",
      "100%|██████████| 1545/1545 [00:00<00:00, 1128758.00it/s]\n",
      "100%|██████████| 1545/1545 [00:00<00:00, 1126795.28it/s]\n",
      "100%|██████████| 1545/1545 [00:00<00:00, 1133298.30it/s]\n",
      "100%|██████████| 1545/1545 [00:00<00:00, 1307018.89it/s]\n",
      "100%|██████████| 1545/1545 [00:00<00:00, 1106969.54it/s]\n",
      "100%|██████████| 1545/1545 [00:00<00:00, 1471100.95it/s]\n",
      "100%|██████████| 1545/1545 [00:00<00:00, 1137675.51it/s]\n",
      "100%|██████████| 1545/1545 [00:00<00:00, 1130727.57it/s]\n"
     ]
    }
   ],
   "source": [
    "###training dbow/dmm model using csv data and eng reviews\n",
    "model_dbow_df_en=train_dbow(df_en_tagged)\n",
    "model_dbow_df_en.save('model_dbow_df_en')\n",
    "\n",
    "model_dmm_df_en=train_dmm(df_en_tagged)\n",
    "model_dmm_df_en.save('model_dmm_df_en')\n",
    "\n",
    "new_model_en = concat_model(model_dbow_df_en,model_dmm_df_en)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 827,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1545/1545 [00:00<00:00, 871345.93it/s]\n",
      "100%|██████████| 1545/1545 [00:00<00:00, 2885218.02it/s]\n",
      "100%|██████████| 1545/1545 [00:00<00:00, 1211252.28it/s]\n",
      "100%|██████████| 1545/1545 [00:00<00:00, 1031714.64it/s]\n",
      "100%|██████████| 1545/1545 [00:00<00:00, 1122112.50it/s]\n",
      "100%|██████████| 1545/1545 [00:00<00:00, 1776857.60it/s]\n",
      "100%|██████████| 1545/1545 [00:00<00:00, 1141885.41it/s]\n",
      "100%|██████████| 1545/1545 [00:00<00:00, 1121918.23it/s]\n",
      "100%|██████████| 1545/1545 [00:00<00:00, 1148767.89it/s]\n",
      "100%|██████████| 1545/1545 [00:00<00:00, 1890373.30it/s]\n",
      "100%|██████████| 1545/1545 [00:00<00:00, 1133893.21it/s]\n",
      "100%|██████████| 1545/1545 [00:00<00:00, 1132704.02it/s]\n",
      "100%|██████████| 1545/1545 [00:00<00:00, 1310189.99it/s]\n",
      "100%|██████████| 1545/1545 [00:00<00:00, 1123669.10it/s]\n",
      "100%|██████████| 1545/1545 [00:00<00:00, 1111717.22it/s]\n",
      "100%|██████████| 1545/1545 [00:00<00:00, 1081475.25it/s]\n",
      "100%|██████████| 1545/1545 [00:00<00:00, 389411.67it/s]\n",
      "100%|██████████| 1545/1545 [00:00<00:00, 1141081.12it/s]\n",
      "100%|██████████| 1545/1545 [00:00<00:00, 1148157.28it/s]\n",
      "100%|██████████| 1545/1545 [00:00<00:00, 1132308.17it/s]\n",
      "100%|██████████| 1545/1545 [00:00<00:00, 1140880.23it/s]\n",
      "100%|██████████| 1545/1545 [00:00<00:00, 1136279.10it/s]\n",
      "100%|██████████| 1545/1545 [00:00<00:00, 1123863.98it/s]\n",
      "100%|██████████| 1545/1545 [00:00<00:00, 1144103.05it/s]\n",
      "100%|██████████| 1545/1545 [00:00<00:00, 1125816.48it/s]\n",
      "100%|██████████| 1545/1545 [00:00<00:00, 2598315.83it/s]\n",
      "100%|██████████| 1545/1545 [00:00<00:00, 1224064.92it/s]\n",
      "100%|██████████| 1545/1545 [00:00<00:00, 1146735.03it/s]\n",
      "100%|██████████| 1545/1545 [00:00<00:00, 1127383.38it/s]\n",
      "100%|██████████| 1545/1545 [00:00<00:00, 1507023.18it/s]\n",
      "100%|██████████| 1545/1545 [00:00<00:00, 3100574.01it/s]\n"
     ]
    }
   ],
   "source": [
    "model_dmm_df_en_5=train_dmm(df_en_tagged)\n",
    "model_dmm_df_en_5.save('model_dmm_df_en_5')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 828,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing accuracy 0.5591647331786543\n",
      "Testing F1 score: 0.5942352538330294\n",
      "Area Under Curve: 0.49564366437275087\n",
      "Recall score: [0.38297872 0.60830861]\n",
      "----\n",
      "Testing accuracy 0.5104408352668214\n",
      "Testing F1 score: 0.5511764215166722\n",
      "Area Under Curve: 0.5450312519729781\n",
      "Recall score: [0.60638298 0.48367953]\n",
      "============end=============\n"
     ]
    }
   ],
   "source": [
    "y_train, X_train = vec_for_learning(model_dmm_df_en_5, df_en_tagged)\n",
    "y_test, X_test = vec_for_learning(model_dmm_df_en_2,df_test_en_tagged)\n",
    "\n",
    "logreg(X_train,y_train,X_test,y_test)\n",
    "print(\"----\")\n",
    "logreg_weight(X_train,y_train,X_test,y_test)\n",
    "print(\"============end=============\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 847,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing accuracy 0.7052631578947368\n",
      "Testing F1 score: 0.7082538699690402\n",
      "Area Under Curve: 0.6513576835275743\n",
      "Recall score: [0.52439024 0.77832512]\n",
      "----\n",
      "Testing accuracy 0.7017543859649122\n",
      "Testing F1 score: 0.7126904547139071\n",
      "Area Under Curve: 0.688874204012976\n",
      "Recall score: [0.65853659 0.71921182]\n",
      "============end=============\n"
     ]
    }
   ],
   "source": [
    "#test the result with only chi reviews\n",
    "y_train, X_train = vec_for_learning(model_dmm, train_tagged)\n",
    "y_test, X_test = vec_for_learning(model_dmm,test_tagged)\n",
    "\n",
    "logreg(X_train,y_train,X_test,y_test)\n",
    "print(\"----\")\n",
    "logreg_weight(X_train,y_train,X_test,y_test)\n",
    "print(\"============end=============\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 843,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing accuracy 0.6526315789473685\n",
      "Testing F1 score: 0.668748092268783\n",
      "Area Under Curve: 0.6652949657575393\n",
      "Recall score: [0.69512195 0.63546798]\n",
      "----\n",
      "Testing accuracy 0.6491228070175439\n",
      "Testing F1 score: 0.6655873833988611\n",
      "Area Under Curve: 0.6664664183587647\n",
      "Recall score: [0.70731707 0.62561576]\n",
      "============end=============\n"
     ]
    }
   ],
   "source": [
    "X_train_new=[]\n",
    "X_test_new=[]\n",
    "\n",
    "y_train, X_train = vec_for_learning(model_dmm_df_en_25, train_tagged)\n",
    "y_test, X_test = vec_for_learning(model_dmm_df_en_25,test_tagged)\n",
    "\n",
    "for i in range(len(X_train)):\n",
    "    aa=(np.append(X_train[i],float(df.loc[i]['sympt_count']*100)))\n",
    "    aa=(np.append(aa,float(df.loc[i]['m_usr_score_hygiene']*100)))\n",
    "    aa=(np.append(aa,float(df.loc[i]['m_usr_score_value']*100)))\n",
    "    aa=(np.append(aa,float(df.loc[i]['score_hygiene_diff']*100)))        \n",
    "    aa=(np.append(aa,float(df.loc[i]['score_value_diff']*100)))\n",
    "    X_train_new.append(aa)\n",
    "X_train_new=tuple(X_train_new)\n",
    "\n",
    "for i in range(len(X_test)):\n",
    "    bb=(np.append(X_test[i],float(df.loc[i]['sympt_count']*100)))\n",
    "    bb=(np.append(bb,float(df.loc[i]['m_usr_score_hygiene']*100)))\n",
    "    bb=(np.append(bb,float(df.loc[i]['m_usr_score_value']*100)))\n",
    "    bb=(np.append(bb,float(df.loc[i]['score_hygiene_diff']*100)))        \n",
    "    bb=(np.append(bb,float(df.loc[i]['score_value_diff']*100)))\n",
    "    X_test_new.append(bb)\n",
    "X_test_new=tuple(X_test_new)\n",
    "\n",
    "logreg(X_train_new,y_train,X_test_new,y_test)\n",
    "print(\"----\")\n",
    "logreg_weight(X_train_new,y_train,X_test_new,y_test)\n",
    "print(\"============end=============\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 786,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "sympt_count                  3\n",
       "m_usr_score_hygiene    3.61702\n",
       "Name: 0, dtype: object"
      ]
     },
     "execution_count": 786,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.loc[0,['sympt_count','m_usr_score_hygiene']]\n",
    "X_train_new.append(np.append(X_train[1],float(df.loc[1]['m_usr_score_hygiene'])))\n",
    "X_train_new=tuple(X_train_new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 708,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cut_review</th>\n",
       "      <th>label</th>\n",
       "      <th>sympt_count</th>\n",
       "      <th>m_usr_score_hygiene</th>\n",
       "      <th>m_usr_score_value</th>\n",
       "      <th>score_hygiene_diff</th>\n",
       "      <th>score_value_diff</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>又 来到 我们 最爱 的 平价 饭堂 哈哈 这次 点 了 两款 没有 吃 过 的 菜式 试试...</td>\n",
       "      <td>0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.617021</td>\n",
       "      <td>3.659574</td>\n",
       "      <td>-2.617021</td>\n",
       "      <td>0.340426</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>见 佢 张 poster 写 26810 再有 85 折 咁 平 既 自助 晚餐 一 於 同...</td>\n",
       "      <td>0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>-2.000000</td>\n",
       "      <td>-2.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          cut_review  label  sympt_count  \\\n",
       "0  又 来到 我们 最爱 的 平价 饭堂 哈哈 这次 点 了 两款 没有 吃 过 的 菜式 试试...      0          3.0   \n",
       "1  见 佢 张 poster 写 26810 再有 85 折 咁 平 既 自助 晚餐 一 於 同...      0          3.0   \n",
       "\n",
       "   m_usr_score_hygiene  m_usr_score_value  score_hygiene_diff  \\\n",
       "0             3.617021           3.659574           -2.617021   \n",
       "1             3.000000           3.000000           -2.000000   \n",
       "\n",
       "   score_value_diff  \n",
       "0          0.340426  \n",
       "1         -2.000000  "
      ]
     },
     "execution_count": 708,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 720,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "cut_review             又 来到 我们 最爱 的 平价 饭堂 哈哈 这次 点 了 两款 没有 吃 过 的 菜式 试试...\n",
       "label                                                                  0\n",
       "sympt_count                                                            3\n",
       "m_usr_score_hygiene                                              3.61702\n",
       "m_usr_score_value                                                3.65957\n",
       "score_hygiene_diff                                              -2.61702\n",
       "score_value_diff                                                0.340426\n",
       "Name: 0, dtype: object"
      ]
     },
     "execution_count": 720,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.loc[0]['sympt_count']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 610,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\ndef logreg_multi(X_train,y_train,X_test,y_test):\\n    \\n    #logreg = LogisticRegression(penalty=\\'l2\\',solver=\\'newton-cg\\',multi_class=\\'multinomial\\')#???\\n    logreg = LogisticRegression(n_jobs=1, C=1e5, max_iter=10000,multi_class=\\'multinomial\\')\\n    logreg.fit(X_train, y_train)\\n    y_pred = logreg.predict(X_test)\\n \\n    print(\\'Testing accuracy %s\\' % accuracy_score(y_test, y_pred))\\n    print(\\'Testing F1 score: {}\\'.format(f1_score(y_test, y_pred, average=\\'weighted\\')))\\n\\n    \\n    lr = LogisticRegression(penalty=\\'l2\\',solver=\\'newton-cg\\',multi_class=\\'multinomial\\')\\n    lr.fit(X_train,y_train)\\n    \\n    print(\"训练集的准确率：%.3f\" %lr.score(X_train, y_train))\\n    print(\"测试集的准确率：%.3f\" %lr.score(X_test, y_test))\\n    \\n    y_hat = lr.predict(X_test)\\n    accuracy = metrics.accuracy_score(y_test, y_hat) #错误率，也就是np.average(y_test==y_hat)\\n    print(\"模型正确率：%.3f\" %accuracy)\\n    return lr \\n    '"
      ]
     },
     "execution_count": 610,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "def logreg_multi(X_train,y_train,X_test,y_test):\n",
    "    \n",
    "    #logreg = LogisticRegression(penalty='l2',solver='newton-cg',multi_class='multinomial')#???\n",
    "    logreg = LogisticRegression(n_jobs=1, C=1e5, max_iter=10000,multi_class='multinomial')\n",
    "    logreg.fit(X_train, y_train)\n",
    "    y_pred = logreg.predict(X_test)\n",
    " \n",
    "    print('Testing accuracy %s' % accuracy_score(y_test, y_pred))\n",
    "    print('Testing F1 score: {}'.format(f1_score(y_test, y_pred, average='weighted')))\n",
    "\n",
    "    \n",
    "    lr = LogisticRegression(penalty='l2',solver='newton-cg',multi_class='multinomial')\n",
    "    lr.fit(X_train,y_train)\n",
    "    \n",
    "    print(\"训练集的准确率：%.3f\" %lr.score(X_train, y_train))\n",
    "    print(\"测试集的准确率：%.3f\" %lr.score(X_test, y_test))\n",
    "    \n",
    "    y_hat = lr.predict(X_test)\n",
    "    accuracy = metrics.accuracy_score(y_test, y_hat) #错误率，也就是np.average(y_test==y_hat)\n",
    "    print(\"模型正确率：%.3f\" %accuracy)\n",
    "    return lr \n",
    "    \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 517,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing accuracy 0.5894736842105263\n",
      "Testing F1 score: 0.6015776542092333\n",
      "Area Under Curve: 0.5373663342544756\n",
      "Recall score: [0.41463415 0.66009852]\n",
      "hhh\n"
     ]
    }
   ],
   "source": [
    "y_train, X_train = vec_for_learning(model_dbow_df123, train_tagged)\n",
    "y_test, X_test = vec_for_learning(model_dbow_df123,test_tagged)\n",
    "logreg(X_train,y_train,X_test,y_test)\n",
    "print(\"hhh\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 486,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_df_train,X_df_train = vec_for_learning(model_dbow_df123,df_tagged)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 470,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test, X_test = vec_for_learning(model_dbow_df123,test_tagged)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 487,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing accuracy 0.656140350877193\n",
      "Testing F1 score: 0.6294786329098112\n"
     ]
    }
   ],
   "source": [
    "logreg(X_df_train,y_df_train,X_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 402,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "训练集的准确率：0.998\n",
      "测试集的准确率：0.000\n",
      "模型正确率：0.000\n"
     ]
    }
   ],
   "source": [
    "lr=logreg_multi(X_train,y_train,X_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 449,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/yanniyang/anaconda3/lib/python3.8/site-packages/joblib/externals/loky/process_executor.py:688: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best score: 0.3334204708503012 with param: {'class_weight': {0: 1900, 1: 1900, 2: 10}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/yanniyang/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "# define weight hyperparameter\n",
    "w = [{0:1898,1:1898,2:1},{0:2000,1:2000,2:1}, {0:3000,1:3000,2:1}, \n",
    "     {0:1500,1:1500,2:1}, {0:1000,1:1000,2:1}, {0:1900,1:1000,2:1}, {0:1900,1:1900,2:10}, \n",
    "     {0:1900,1:1900,2:100}, {0:1900,1:1900,2:1000}, {0:1900,1:1900,2:10000}, {0:3000,1:3000,2:1000}, \n",
    "     {0:3000,1:3000,2:100}, {0:3000,1:3000,2:10}, {0:2000,1:2000,2:10}, \n",
    "     {0:2000,1:2000,2:100}, {0:1000,1:1000,2:10}, {0:1000,1:1000,2:100}, \n",
    "     {0:1000,1:1000,2:100}, {0:1000,1:1000,2:1000}, {0:500,1:500,2:1000} ]\n",
    "hyperparam_grid = {\"class_weight\": w}\n",
    "\n",
    "# define model\n",
    "lg3 = LogisticRegression(random_state=13,multi_class='multinomial')\n",
    "# define evaluation procedure\n",
    "grid = GridSearchCV(lg3,hyperparam_grid,scoring=\"f1_macro\", cv=100, n_jobs=-1, refit=True)\n",
    "grid.fit(X_train,y_train)\n",
    "print(f'Best score: {grid.best_score_} with param: {grid.best_params_}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 451,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/yanniyang/anaconda3/lib/python3.8/site-packages/joblib/externals/loky/process_executor.py:688: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36mretrieve\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    939\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'supports_timeout'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 940\u001b[0;31m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_output\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    941\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36mwrap_future_result\u001b[0;34m(future, timeout)\u001b[0m\n\u001b[1;32m    541\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 542\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfuture\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    543\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mCfTimeoutError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/concurrent/futures/_base.py\u001b[0m in \u001b[0;36mresult\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    433\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 434\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_condition\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    435\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/threading.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    301\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 302\u001b[0;31m                 \u001b[0mwaiter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0macquire\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    303\u001b[0m                 \u001b[0mgotit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: ",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-451-0dcb49cd2d58>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;31m# define evaluation procedure\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0mgrid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mGridSearchCV\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlg4\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mhyperparam_grid\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mscoring\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"f1_macro\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcv\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrefit\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m \u001b[0mgrid\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'Best score: {grid.best_score_} with param: {grid.best_params_}'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36minner_f\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     70\u001b[0m                           FutureWarning)\n\u001b[1;32m     71\u001b[0m         \u001b[0mkwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0marg\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0marg\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 72\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     73\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0minner_f\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     74\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, groups, **fit_params)\u001b[0m\n\u001b[1;32m    734\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mresults\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    735\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 736\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_run_search\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mevaluate_candidates\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    737\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    738\u001b[0m         \u001b[0;31m# For multi-metric evaluation, store the best_index_, best_params_ and\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36m_run_search\u001b[0;34m(self, evaluate_candidates)\u001b[0m\n\u001b[1;32m   1186\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_run_search\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mevaluate_candidates\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1187\u001b[0m         \u001b[0;34m\"\"\"Search all candidates in param_grid\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1188\u001b[0;31m         \u001b[0mevaluate_candidates\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mParameterGrid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparam_grid\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1189\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1190\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36mevaluate_candidates\u001b[0;34m(candidate_params)\u001b[0m\n\u001b[1;32m    706\u001b[0m                               n_splits, n_candidates, n_candidates * n_splits))\n\u001b[1;32m    707\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 708\u001b[0;31m                 out = parallel(delayed(_fit_and_score)(clone(base_estimator),\n\u001b[0m\u001b[1;32m    709\u001b[0m                                                        \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    710\u001b[0m                                                        \u001b[0mtrain\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtest\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1059\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1060\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mretrieval_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1061\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mretrieve\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1062\u001b[0m             \u001b[0;31m# Make sure that we get a last message telling us we are done\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1063\u001b[0m             \u001b[0melapsed_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_start_time\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36mretrieve\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    960\u001b[0m                     \u001b[0;31m# scheduling.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    961\u001b[0m                     \u001b[0mensure_ready\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_managed_backend\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 962\u001b[0;31m                     \u001b[0mbackend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mabort_everything\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mensure_ready\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mensure_ready\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    963\u001b[0m                 \u001b[0;32mraise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    964\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36mabort_everything\u001b[0;34m(self, ensure_ready)\u001b[0m\n\u001b[1;32m    559\u001b[0m         \"\"\"Shutdown the workers and restart a new one with the same parameters\n\u001b[1;32m    560\u001b[0m         \"\"\"\n\u001b[0;32m--> 561\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_workers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mterminate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkill_workers\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    562\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_workers\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    563\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/joblib/executor.py\u001b[0m in \u001b[0;36mterminate\u001b[0;34m(self, kill_workers)\u001b[0m\n\u001b[1;32m     72\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     73\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mterminate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkill_workers\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 74\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshutdown\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkill_workers\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mkill_workers\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     75\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mkill_workers\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     76\u001b[0m             \u001b[0;31m# When workers are killed in such a brutal manner, they cannot\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/joblib/externals/loky/process_executor.py\u001b[0m in \u001b[0;36mshutdown\u001b[0;34m(self, wait, kill_workers)\u001b[0m\n\u001b[1;32m   1169\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1170\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mexecutor_manager_thread\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mwait\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1171\u001b[0;31m             \u001b[0mexecutor_manager_thread\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1172\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1173\u001b[0m         \u001b[0;31m# To reduce the risk of opening too many files, remove references to\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/threading.py\u001b[0m in \u001b[0;36mjoin\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m   1009\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1010\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1011\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_wait_for_tstate_lock\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1012\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1013\u001b[0m             \u001b[0;31m# the behavior of a negative timeout isn't documented, but\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/threading.py\u001b[0m in \u001b[0;36m_wait_for_tstate_lock\u001b[0;34m(self, block, timeout)\u001b[0m\n\u001b[1;32m   1025\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlock\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# already determined that the C code is done\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1026\u001b[0m             \u001b[0;32massert\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_is_stopped\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1027\u001b[0;31m         \u001b[0;32melif\u001b[0m \u001b[0mlock\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0macquire\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mblock\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1028\u001b[0m             \u001b[0mlock\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelease\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1029\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# define hyperparameters\n",
    "w = [{0:1898,1:1898,2:1},{0:2000,1:2000,2:1}, {0:3000,1:3000,2:1}, \n",
    "     {0:1500,1:1500,2:1}, {0:1000,1:1000,2:1}, {0:1900,1:1000,2:1}, {0:1900,1:1900,2:10}, \n",
    "     {0:1900,1:1900,2:100}, {0:1900,1:1900,2:1000}, {0:1900,1:1900,2:10000}, {0:3000,1:3000,2:1000}, \n",
    "     {0:3000,1:3000,2:100}, {0:3000,1:3000,2:10}, {0:2000,1:2000,2:10}, \n",
    "     {0:2000,1:2000,2:100}, {0:1000,1:1000,2:10}, {0:1000,1:1000,2:100}, \n",
    "     {0:1000,1:1000,2:100}, {0:1000,1:1000,2:1000}, {0:500,1:500,2:1000} ]\n",
    "crange = np.arange(0.5, 20.0, 0.5)\n",
    "hyperparam_grid = {\"class_weight\": w\n",
    "                   ,\"penalty\": [\"l1\", \"l2\"]\n",
    "                   ,\"C\": crange\n",
    "                   ,\"fit_intercept\": [True, False]  }\n",
    "# logistic model classifier\n",
    "lg4 = LogisticRegression(random_state=13,multi_class='multinomial')\n",
    "# define evaluation procedure\n",
    "grid = GridSearchCV(lg4,hyperparam_grid,scoring=\"f1_macro\", cv=100, n_jobs=-1, refit=True)\n",
    "grid.fit(X_train,y_train)\n",
    "print(f'Best score: {grid.best_score_} with param: {grid.best_params_}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 450,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "训练集的准确率：0.994\n",
      "测试集的准确率：0.004\n",
      "模型正确率：0.004\n",
      "Area Under Curve: 0.49507389162561577\n",
      "Recall score: [0.         0.00492611 0.        ]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/yanniyang/anaconda3/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "w={0:776512,1:776512,2:409}\n",
    "#put the content in function here to see the detail message\n",
    "lr = LogisticRegression(penalty='l2',solver='newton-cg',multi_class='multinomial',class_weight=w)\n",
    "lr.fit(X_train,y_train)\n",
    "\n",
    "print(\"训练集的准确率：%.3f\" %lr.score(X_train, y_train))\n",
    "print(\"测试集的准确率：%.3f\" %lr.score(X_test, y_test))\n",
    "\n",
    "y_pred = lr.predict(X_test)\n",
    "accuracy = metrics.accuracy_score(y_test, y_pred) #错误率，也就是np.average(y_test==y_hat)\n",
    "print(\"模型正确率：%.3f\" %accuracy)\n",
    "print(f'Area Under Curve: {roc_auc_score(y_test, y_pred)}')\n",
    "#print(f'Area Under Curve_weighted: {roc_auc_score(y_test, y_pred,average=weighted)}')\n",
    "print(f'Recall score: {recall_score(y_test,y_pred,average=None)}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 417,
   "metadata": {},
   "outputs": [],
   "source": [
    "index_list=[]\n",
    "for i in range(0,len(y_hat)):\n",
    "    if y_hat[i] != y_test[i]:\n",
    "        index_list.append(i)\n",
    "    else:\n",
    "        continue\n",
    "false_det=[]\n",
    "for j in range(0,len(index_list)):\n",
    "    false_det.append(X_test[index_list[j]])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 394,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "26"
      ]
     },
     "execution_count": 394,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(false_det)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 496,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(0, 776512), (1, 776512), (2, 776512)]\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "from imblearn import over_sampling \n",
    "ros = over_sampling.RandomOverSampler(random_state=0)\n",
    "X_resampled,y_resampled = ros.fit_resample(X_train,y_train)\n",
    "\n",
    "from collections import Counter\n",
    "print(sorted(Counter(y_resampled).items()))\n",
    "\n",
    "\n",
    "X_resampled, y_resampled = SMOTE().fit_resample(X_train, y_train)\n",
    "print(sorted(Counter(y_resampled).items()))\n",
    "\"\"\"\n",
    "from imblearn.over_sampling import SMOTE, ADASYN,BorderlineSMOTE\n",
    "\n",
    "X_resampled, y_resampled = BorderlineSMOTE().fit_resample(X_train, y_train)\n",
    "print(sorted(Counter(y_resampled).items()))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 500,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(0, 409), (1, 409), (2, 409)]\n"
     ]
    }
   ],
   "source": [
    "from imblearn.under_sampling import ClusterCentroids\n",
    "cc = ClusterCentroids(random_state=0)\n",
    "X_under_sampled, y_under_resampled = cc.fit_resample(X_train, y_train)\n",
    "print(sorted(Counter(y_under_resampled).items()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 501,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/yanniyang/anaconda3/lib/python3.8/site-packages/scipy/optimize/linesearch.py:327: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "/home/yanniyang/anaconda3/lib/python3.8/site-packages/sklearn/utils/optimize.py:204: UserWarning: Line Search failed\n",
      "  warnings.warn('Line Search failed')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "训练集的准确率：0.962\n",
      "测试集的准确率：0.070\n",
      "模型正确率：0.070\n",
      "Area Under Curve: 0.4995194040610357\n",
      "Recall score: [0.         0.09852217 0.        ]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/yanniyang/anaconda3/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "#after random over sampling--accuracy = 33% and the AUC is around the 52%\n",
    "#after SMOTE oversampling-- accuracy =31.2%, AUC = 49.9%\n",
    "#after ASASYN oversampling-- accuracy =31.2% AUC=58.6%\n",
    "#ASASYN+weight=1900/1900/1, accuracy=50.9% and AUC=0.4625\n",
    "#put the content in function here to see the detail message\n",
    "#using Borderling SMOTE and the accuracy =0.07 while AUC=0.4995 \n",
    "w={0:776512,1:776512,2:409}\n",
    "lr = LogisticRegression(penalty='l2',solver='newton-cg',multi_class='multinomial',class_weight='balanced')\n",
    "lr.fit(X_resampled,y_resampled)\n",
    "\n",
    "print(\"训练集的准确率：%.3f\" %lr.score(X_resampled, y_resampled))\n",
    "print(\"测试集的准确率：%.3f\" %lr.score(X_test, y_test))\n",
    "\n",
    "y_pred = lr.predict(X_test)\n",
    "accuracy = metrics.accuracy_score(y_test, y_pred) #错误率，也就是np.average(y_test==y_hat)\n",
    "print(\"模型正确率：%.3f\" %accuracy)\n",
    "print(f'Area Under Curve: {roc_auc_score(y_test, y_pred)}')\n",
    "#print(f'Area Under Curve_weighted: {roc_auc_score(y_test, y_pred,average=weighted)}')\n",
    "print(f'Recall score: {recall_score(y_test,y_pred,average=None)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###test only use two symptom csv file and the newly trained models to see the accuracy \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
